{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set (139000, 28, 28) (139000,)\n",
      "validation set (10000, 28, 28) (10000,)\n",
      "test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file= 'banglaIsolated_clean.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save=pickle.load(f)\n",
    "    train_dataset=save['train_dataset']\n",
    "    train_labels=save['train_labels']\n",
    "    valid_dataset=save['valid_dataset_clean']\n",
    "    valid_labels=save['valid_labels']\n",
    "    test_dataset=save['test_dataset_clean']\n",
    "    test_labels=save['test_labels']\n",
    "    del save #hint to help gc to free up memory \n",
    "    print('training set', train_dataset.shape,train_labels.shape)\n",
    "    print('validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('test set', test_dataset.shape,test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set (139000, 28, 28, 1) (139000, 10)\n",
      "validation set (10000, 28, 28, 1) (10000, 10)\n",
      "test set (10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size=28\n",
    "num_labels=10\n",
    "num_channels=1 \n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset=dataset.reshape((-1,image_size,image_size,num_channels)).astype(np.float32)\n",
    "    # Map 1 to [0.0,1.0,0.0....], 2 to [0.0,0.0,1.0.....]\n",
    "    labels=(np.arange(num_labels) ==labels[:,None]).astype(np.float32)\n",
    "    return dataset,labels\n",
    "train_dataset, train_labels= reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels=reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels =reformat(test_dataset, test_labels)\n",
    "print( 'training set', train_dataset.shape,train_labels.shape)\n",
    "print('validation set', valid_dataset.shape,valid_labels.shape)\n",
    "print('test set', test_dataset.shape,test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_dir='conv2_Hidden_1layer_log'\n",
    "def accuracy(predictions, labels):\n",
    "    return(100.0 * np.sum(np.argmax(predictions, 1)== np.argmax(labels, 1))/ predictions.shape[0])\n",
    "def variable_summaries(var):\n",
    "  \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "  with tf.name_scope('summaries'):\n",
    "    mean = tf.reduce_mean(var)\n",
    "    tf.summary.scalar('mean', mean)\n",
    "    with tf.name_scope('stddev'):\n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "    tf.summary.scalar('stddev', stddev)\n",
    "    tf.summary.scalar('max', tf.reduce_max(var))\n",
    "    tf.summary.scalar('min', tf.reduce_min(var))\n",
    "    tf.summary.histogram('histogram', var)\n",
    "if tf.gfile.Exists(log_dir):\n",
    "    tf.gfile.DeleteRecursively(log_dir)\n",
    "    tf.gfile.MakeDirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "patch_size=5\n",
    "depth=16\n",
    "num_hidden=64\n",
    "\n",
    "sess=tf.InteractiveSession()\n",
    "graph=tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    #input data\n",
    "    tf_train_dataset=tf.placeholder(tf.float32, \n",
    "                                    shape=(batch_size,image_size,image_size,num_channels))\n",
    "    tf_train_labels=tf.placeholder(tf.float32, shape=(batch_size,num_labels))\n",
    "    tf_valid_dataset=tf.constant(valid_dataset)\n",
    "    tf_test_dataset=tf.constant(test_dataset)\n",
    "    \n",
    "    #variables\n",
    "    with tf.name_scope('layer1_weights'):\n",
    "        layer1_weights=tf.Variable(tf.truncated_normal\n",
    "                               ([patch_size,patch_size,num_channels,depth],stddev=0.1))\n",
    "        variable_summaries(layer1_weights)\n",
    "    with tf.name_scope('layer1_biases'):\n",
    "        layer1_biases=tf.Variable(tf.zeros([depth]))\n",
    "        variable_summaries(layer1_biases)\n",
    "        \n",
    "    with tf.name_scope('layer2_weights'):\n",
    "        layer2_weights=tf.Variable(tf.truncated_normal\n",
    "                               ([patch_size,patch_size,depth,depth],stddev=0.1))\n",
    "        variable_summaries(layer2_weights)\n",
    "    with tf.name_scope('layer2_biases'):\n",
    "        layer2_biases=tf.Variable(tf.constant(1.0,shape=[depth]))\n",
    "        variable_summaries(layer2_biases)\n",
    "    \n",
    "    with tf.name_scope('layer3_weights'):\n",
    "        layer3_weights=tf.Variable(tf.truncated_normal\n",
    "                               ([image_size//4*image_size//4*depth,num_hidden],stddev=0.1))\n",
    "        ##variable_summaries(layer3_weights)\n",
    "    with tf.name_scope('layer3_biases'):\n",
    "        layer3_biases=tf.Variable(tf.constant(1.0,shape=[num_hidden]))\n",
    "        variable_summaries(layer3_biases)\n",
    "    \n",
    "    with tf.name_scope('layer4_weights'):\n",
    "        layer4_weights=tf.Variable(tf.truncated_normal\n",
    "                               ([num_hidden,num_labels],stddev=0.1))\n",
    "        variable_summaries(layer4_weights)\n",
    "    with tf.name_scope('layer4_biases'):\n",
    "        layer4_biases=tf.Variable(tf.constant(1.0,shape=[num_labels]))\n",
    "        variable_summaries(layer4_biases)\n",
    "    \n",
    "    #Model\n",
    "    def model(data):\n",
    "        with tf.name_scope('conv1'):\n",
    "            conv=tf.nn.conv2d(data,layer1_weights,[1,2,2,1], padding='SAME')\n",
    "            hidden=tf.nn.relu(conv+layer1_biases)\n",
    "        with tf.name_scope('conv2'):\n",
    "            conv=tf.nn.conv2d(hidden,layer2_weights,[1,2,2,1], padding='SAME')\n",
    "            hidden=tf.nn.relu(conv+layer2_biases)\n",
    "        with tf.name_scope('reshaping_data'):\n",
    "            shape=hidden.get_shape().as_list()\n",
    "            reshape=tf.reshape(hidden,[shape[0],shape[1]*shape[2]*shape[3]])\n",
    "            ##image_summ = tf.summary.image('conv2_images', reshape)\n",
    "        with tf.name_scope('fullyConnected1'):\n",
    "            hidden=tf.nn.relu(tf.matmul(reshape, layer3_weights)+layer3_biases)\n",
    "        with tf.name_scope('fullyConnected2'):\n",
    "            return tf.matmul(hidden, layer4_weights)+ layer4_biases\n",
    "    \n",
    "    #training computation\n",
    "    \n",
    "    logits=model(tf_train_dataset)\n",
    "    with tf.name_scope('softmax-crossEntropy'):\n",
    "        loss=tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels,logits=logits))\n",
    "        tf.summary.scalar('cross_entropy',loss)\n",
    "    \n",
    "    #optimizer\n",
    "    \n",
    "    with tf.name_scope('train'):\n",
    "        optimizer=tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "    \n",
    "    #Predictions for the training , validation, and test data\n",
    "    \n",
    "    train_prediction= tf.nn.softmax(logits)\n",
    "    valid_prediction= tf.nn.softmax(model(tf_valid_dataset))\n",
    "    test_prediction= tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "train_dir=log_dir+'/train'\n",
    "test_dir=log_dir+'/test'\n",
    "\n",
    "\n",
    "\n",
    "def dir_maker(path_dir):\n",
    "    if not (os.path.isdir(path_dir)):\n",
    "        os.makedirs(path_dir)\n",
    "    if(os.path.isdir(path_dir)):\n",
    "        dir_list=os.listdir(path_dir)\n",
    "        c=0\n",
    "        for current_dir in dir_list:\n",
    "            if(current_dir==str(c)):\n",
    "                print(current_dir)\n",
    "            c=c+1\n",
    "        os.makedirs(path_dir+'/'+str(c))\n",
    "        path_dir=path_dir+'/'+str(c)\n",
    "        return path_dir\n",
    "train_dir=dir_maker(train_dir)\n",
    "test_dir=dir_maker(test_dir)\n",
    "print(os.listdir(train_dir))\n",
    "print(os.listdir(test_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss a step 0: 0.378617\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 50: 0.109442\n",
      "Minibatch Accuracy: 6.2%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 100: 0.148380\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 150: 5.883938\n",
      "Minibatch Accuracy: 6.2%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 200: 20.452019\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 250: 35.337952\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 300: 233.863037\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 350: 2.607666\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 400: 185.215820\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 450: 3604.144531\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 500: 75199.343750\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 550: 269761.187500\n",
      "Minibatch Accuracy: 6.2%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 600: 218465.750000\n",
      "Minibatch Accuracy: 6.2%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 650: 3196539.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 700: 6289944.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 750: 11251424.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 800: 42224192.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 850: 132611072.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 900: 0.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 950: 7039504384.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1000: 0.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1050: 48422354944.000000\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 1100: 130262892544.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 1150: 686570864640.000000\n",
      "Minibatch Accuracy: 6.2%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 1200: 6441247178752.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 1250: 4282241777664.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 1300: 7514347274240.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 1350: 86892557107200.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 1400: 570706664357888.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 1450: 3719765948366848.000000\n",
      "Minibatch Accuracy: 6.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1500: 4086360734433280.000000\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 1550: 17318081231585280.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 1600: 82435609414598656.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 1650: 568032445920706560.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 1700: 4483517047489167360.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 1750: 0.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 1800: 45524144252065415168.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 1850: 31547574652241969152.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1900: 840111326113877196800.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 1950: 1610781086623375294464.000000\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 2000: 0.000000\n",
      "Minibatch Accuracy: 12.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 2050: 32670498805630808096768.000000\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 2100: 30163272835479615045632.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 2150: 364572370615946799218688.000000\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 2200: 0.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 2250: 1076007805191515000537088.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 2300: 1497700374716515350478848.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 2350: 198290360834777178987036672.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 2400: 618034843505129358020837376.000000\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 2450: 0.000000\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 2500: 2938823109619437609387294720.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 2550: 18377636962599237227942772736.000000\n",
      "Minibatch Accuracy: 6.2%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 2600: 0.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 2650: 0.000000\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 2700: 236710093332183621665818673152.000000\n",
      "Minibatch Accuracy: 6.2%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 2750: 4822409930146034236419634888704.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 2800: 23482581319269947604895463899136.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 2850: 15387865487700870493931248287744.000000\n",
      "Minibatch Accuracy: 12.5%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 2900: 355280357808386507242925902004224.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 2950: 195420595631570487505438300438528.000000\n",
      "Minibatch Accuracy: 6.2%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 3000: 0.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 3050: 2952586028898774786056403204177920.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 3100: 45442580260656539056178629418418176.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 3150: 94607616508883273749852327799422976.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 3200: 631931113204723668965165153923366912.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss a step 3250: 1792124556614856349383744699458650112.000000\n",
      "Minibatch Accuracy: 0.0%\n",
      "Validation accuracy: 89.3%\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Nan in summary histogram for: layer1_biases/summaries/histogram\n\t [[Node: layer1_biases/summaries/histogram = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](layer1_biases/summaries/histogram/tag, layer1_biases/Variable/read)]]\n\nCaused by op u'layer1_biases/summaries/histogram', defined at:\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-bbc1691f187d>\", line 25, in <module>\n    variable_summaries(layer1_biases)\n  File \"<ipython-input-4-894b85d30e76>\", line 14, in variable_summaries\n    tf.summary.histogram('histogram', var)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/tensorflow/python/summary/summary.py\", line 209, in histogram\n    tag=scope.rstrip('/'), values=values, name=scope)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 139, in _histogram_summary\n    name=name)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Nan in summary histogram for: layer1_biases/summaries/histogram\n\t [[Node: layer1_biases/summaries/histogram = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](layer1_biases/summaries/histogram/tag, layer1_biases/Variable/read)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-085a7875eb5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mbatch_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtf_train_dataset\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf_train_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_prediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Minibatch loss a step %d: %f'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Nan in summary histogram for: layer1_biases/summaries/histogram\n\t [[Node: layer1_biases/summaries/histogram = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](layer1_biases/summaries/histogram/tag, layer1_biases/Variable/read)]]\n\nCaused by op u'layer1_biases/summaries/histogram', defined at:\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-bbc1691f187d>\", line 25, in <module>\n    variable_summaries(layer1_biases)\n  File \"<ipython-input-4-894b85d30e76>\", line 14, in variable_summaries\n    tf.summary.histogram('histogram', var)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/tensorflow/python/summary/summary.py\", line 209, in histogram\n    tag=scope.rstrip('/'), values=values, name=scope)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 139, in _histogram_summary\n    name=name)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/somanianurmahal/.conda/envs/eyeCon/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Nan in summary histogram for: layer1_biases/summaries/histogram\n\t [[Node: layer1_biases/summaries/histogram = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](layer1_biases/summaries/histogram/tag, layer1_biases/Variable/read)]]\n"
     ]
    }
   ],
   "source": [
    "num_steps=10001\n",
    "\n",
    "with tf.Session(graph=graph)as session:\n",
    "    merged = tf.summary.merge_all()\n",
    "    \n",
    "    train_writer = tf.summary.FileWriter(train_dir,sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(test_dir)\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        offset=(step*batch_size)% (train_labels.shape[0]-batch_size)\n",
    "        batch_data=train_dataset[offset:(offset+batch_size),:,:,:]\n",
    "        batch_labels=train_labels[offset:(offset+batch_size),:]\n",
    "        feed_dict={tf_train_dataset : batch_data,tf_train_labels: batch_labels}\n",
    "        _,summary, l, predictions =session.run([optimizer,merged,loss,train_prediction],feed_dict=feed_dict)\n",
    "        if(step%50==0):\n",
    "            print('Minibatch loss a step %d: %f' %(step,l))\n",
    "            print('Minibatch Accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "            print('Validation accuracy: %.1f%%'%accuracy(valid_prediction.eval(),valid_labels))\n",
    "    print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convulation using maxpooling operation(nn.max_pool()) of stride of 2 and kernel size 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "patch_size=5\n",
    "depth=16\n",
    "num_hidden=64\n",
    "\n",
    "graph=tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    #input data\n",
    "    tf_train_dataset=tf.placeholder(tf.float32, \n",
    "                                    shape=(batch_size,image_size,image_size,num_channels))\n",
    "    tf_train_labels=tf.placeholder(tf.float32, shape=(batch_size,num_labels))\n",
    "    tf_valid_dataset=tf.constant(valid_dataset)\n",
    "    tf_test_dataset=tf.constant(test_dataset)\n",
    "    \n",
    "    #variables\n",
    "    layer1_weights=tf.Variable(tf.truncated_normal\n",
    "                               ([patch_size,patch_size,num_channels,depth],stddev=0.1))\n",
    "    layer1_biases=tf.Variable(tf.zeros([depth]))\n",
    "    \n",
    "    layer2_weights=tf.Variable(tf.truncated_normal\n",
    "                               ([patch_size,patch_size,depth,depth],stddev=0.1))\n",
    "    layer2_biases=tf.Variable(tf.constant(1.0,shape=[depth]))\n",
    "    \n",
    "    \n",
    "    layer3_weights=tf.Variable(tf.truncated_normal\n",
    "                               ([image_size//4*image_size//4*depth,num_hidden],stddev=0.1))\n",
    "    layer3_biases=tf.Variable(tf.constant(1.0,shape=[num_hidden]))\n",
    "    \n",
    "    \n",
    "    layer4_weights=tf.Variable(tf.truncated_normal\n",
    "                               ([num_hidden,num_labels],stddev=0.1))\n",
    "    layer4_biases=tf.Variable(tf.constant(1.0,shape=[num_labels]))\n",
    "    \n",
    "    #Model\n",
    "    def model(data):\n",
    "        #1st conv layer with pooling\n",
    "        conv_1=tf.nn.conv2d(data,layer1_weights,[1,1,1,1], padding='SAME')\n",
    "        hidden_1=tf.nn.relu(conv_1+layer1_biases)\n",
    "        pool_1=tf.nn.max_pool(hidden_1,[1,2,2,1],[1,2,2,1], padding='SAME')\n",
    "        \n",
    "         #2nd conv layer with pooling\n",
    "        conv_2=tf.nn.conv2d(pool_1,layer2_weights,[1,1,1,1], padding='SAME')\n",
    "        hidden_2=tf.nn.relu(conv_2+layer2_biases)\n",
    "        pool_2=tf.nn.max_pool(hidden_2,[1,2,2,1],[1,2,2,1], padding='SAME')\n",
    "        \n",
    "         #fully connected layer\n",
    "        shape=pool_2.get_shape().as_list()\n",
    "        reshape=tf.reshape(pool_2,[shape[0],shape[1]*shape[2]*shape[3]])\n",
    "        hidden=tf.nn.relu(tf.matmul(reshape, layer3_weights)+layer3_biases)\n",
    "        return tf.matmul(hidden, layer4_weights)+ layer4_biases\n",
    "    \n",
    "    #training computation\n",
    "    \n",
    "    logits=model(tf_train_dataset)\n",
    "    loss=tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels,logits=logits))\n",
    "    \n",
    "    #optimizer\n",
    "    \n",
    "    optimizer=tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "    \n",
    "    #Predictions for the training , validation, and test data\n",
    "    \n",
    "    train_prediction= tf.nn.softmax(logits)\n",
    "    valid_prediction= tf.nn.softmax(model(tf_valid_dataset))\n",
    "    test_prediction= tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss a step 0: 3.003009\n",
      "Minibatch Accuracy: 6.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss a step 50: 2.212623\n",
      "Minibatch Accuracy: 18.8%\n",
      "Validation accuracy: 22.5%\n",
      "Minibatch loss a step 100: 1.873110\n",
      "Minibatch Accuracy: 56.2%\n",
      "Validation accuracy: 64.0%\n",
      "Minibatch loss a step 150: 1.151364\n",
      "Minibatch Accuracy: 62.5%\n",
      "Validation accuracy: 74.0%\n",
      "Minibatch loss a step 200: 0.864053\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 76.9%\n",
      "Minibatch loss a step 250: 0.878512\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss a step 300: 0.861306\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss a step 350: 0.286721\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss a step 400: 0.684663\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss a step 450: 1.018541\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss a step 500: 0.296469\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss a step 550: 0.641579\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 81.9%\n",
      "Minibatch loss a step 600: 0.649679\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss a step 650: 0.781651\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 82.4%\n",
      "Minibatch loss a step 700: 0.450979\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 83.0%\n",
      "Minibatch loss a step 750: 1.052706\n",
      "Minibatch Accuracy: 56.2%\n",
      "Validation accuracy: 83.7%\n",
      "Minibatch loss a step 800: 0.688352\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 83.6%\n",
      "Minibatch loss a step 850: 0.592277\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 83.7%\n",
      "Minibatch loss a step 900: 0.885100\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 84.3%\n",
      "Minibatch loss a step 950: 0.466930\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 83.0%\n",
      "Minibatch loss a step 1000: 0.247674\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 83.3%\n",
      "Minibatch loss a step 1050: 0.270038\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 82.5%\n",
      "Minibatch loss a step 1100: 0.322728\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 84.2%\n",
      "Minibatch loss a step 1150: 0.448804\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 84.5%\n",
      "Minibatch loss a step 1200: 0.400132\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss a step 1250: 0.407326\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 84.8%\n",
      "Minibatch loss a step 1300: 0.339660\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 84.4%\n",
      "Minibatch loss a step 1350: 0.384069\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 84.9%\n",
      "Minibatch loss a step 1400: 0.482854\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 84.2%\n",
      "Minibatch loss a step 1450: 0.502703\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 84.7%\n",
      "Minibatch loss a step 1500: 0.329028\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss a step 1550: 0.839681\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss a step 1600: 0.271553\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 84.8%\n",
      "Minibatch loss a step 1650: 0.841444\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 85.1%\n",
      "Minibatch loss a step 1700: 0.791353\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 84.2%\n",
      "Minibatch loss a step 1750: 0.056849\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss a step 1800: 0.625778\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss a step 1850: 0.040640\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss a step 1900: 0.905807\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss a step 1950: 0.342043\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss a step 2000: 0.982745\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss a step 2050: 0.850094\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss a step 2100: 0.386307\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss a step 2150: 0.021638\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss a step 2200: 0.771716\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss a step 2250: 0.842482\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss a step 2300: 0.719025\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss a step 2350: 0.152305\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss a step 2400: 0.504649\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss a step 2450: 0.331371\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss a step 2500: 0.333301\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss a step 2550: 0.339062\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss a step 2600: 0.725228\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss a step 2650: 0.211158\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss a step 2700: 0.316759\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss a step 2750: 0.380918\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss a step 2800: 0.684317\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss a step 2850: 0.474821\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss a step 2900: 0.798109\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss a step 2950: 0.061450\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss a step 3000: 0.450254\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss a step 3050: 0.668155\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss a step 3100: 0.196934\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss a step 3150: 0.349893\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss a step 3200: 0.419402\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss a step 3250: 0.216585\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss a step 3300: 0.510315\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss a step 3350: 0.170956\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss a step 3400: 0.193297\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss a step 3450: 0.179509\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss a step 3500: 0.424015\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss a step 3550: 0.740680\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss a step 3600: 0.386130\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss a step 3650: 0.350773\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss a step 3700: 0.166730\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss a step 3750: 0.630190\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss a step 3800: 0.564314\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss a step 3850: 0.443560\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss a step 3900: 0.354403\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss a step 3950: 0.432873\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss a step 4000: 0.851336\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss a step 4050: 0.789729\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss a step 4100: 0.515935\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss a step 4150: 0.210180\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss a step 4200: 0.252431\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss a step 4250: 0.388201\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss a step 4300: 0.201336\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss a step 4350: 0.646825\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss a step 4400: 0.404517\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss a step 4450: 0.594803\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss a step 4500: 0.136694\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss a step 4550: 0.299809\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss a step 4600: 0.680829\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss a step 4650: 0.316954\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss a step 4700: 0.492077\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss a step 4750: 0.115291\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss a step 4800: 0.866716\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss a step 4850: 0.760916\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss a step 4900: 0.232131\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss a step 4950: 0.261000\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss a step 5000: 0.150619\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss a step 5050: 0.652745\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss a step 5100: 0.055051\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss a step 5150: 0.483077\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss a step 5200: 0.470431\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss a step 5250: 0.392656\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss a step 5300: 0.236383\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss a step 5350: 0.118554\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss a step 5400: 0.561852\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss a step 5450: 0.463083\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss a step 5500: 0.398436\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss a step 5550: 0.215859\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss a step 5600: 0.471473\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss a step 5650: 0.065227\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss a step 5700: 0.481338\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss a step 5750: 1.257472\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss a step 5800: 0.539979\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss a step 5850: 0.196809\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss a step 5900: 0.672569\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss a step 5950: 0.461768\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss a step 6000: 0.301309\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss a step 6050: 0.871265\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss a step 6100: 0.160511\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss a step 6150: 0.121970\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss a step 6200: 0.316890\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss a step 6250: 0.429035\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss a step 6300: 0.397547\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss a step 6350: 0.465448\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss a step 6400: 0.346501\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss a step 6450: 0.081637\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss a step 6500: 0.185298\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss a step 6550: 0.330198\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss a step 6600: 0.571836\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss a step 6650: 0.595937\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss a step 6700: 0.814040\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss a step 6750: 0.411030\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss a step 6800: 0.429160\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss a step 6850: 0.630666\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss a step 6900: 1.023913\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss a step 6950: 0.805691\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss a step 7000: 0.406107\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss a step 7050: 0.271723\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss a step 7100: 0.704097\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss a step 7150: 0.279100\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss a step 7200: 0.471293\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss a step 7250: 0.764270\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss a step 7300: 0.437891\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss a step 7350: 0.531363\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss a step 7400: 0.159981\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss a step 7450: 0.369235\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss a step 7500: 0.209557\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss a step 7550: 0.105002\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss a step 7600: 0.336519\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss a step 7650: 0.390906\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss a step 7700: 0.542022\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss a step 7750: 0.385262\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss a step 7800: 0.190926\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss a step 7850: 0.295190\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss a step 7900: 0.963099\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss a step 7950: 0.218528\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss a step 8000: 0.475013\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss a step 8050: 0.031044\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss a step 8100: 0.713894\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss a step 8150: 0.728638\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss a step 8200: 0.101293\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss a step 8250: 0.537755\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss a step 8300: 0.298310\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss a step 8350: 0.581763\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss a step 8400: 0.489128\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss a step 8450: 0.784184\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss a step 8500: 0.110386\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss a step 8550: 0.304949\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8600: 0.420967\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8650: 0.270456\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss a step 8700: 0.267968\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss a step 8750: 0.380390\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss a step 8800: 0.562327\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss a step 8850: 0.087717\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8900: 0.013431\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss a step 8950: 0.156052\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss a step 9000: 0.228479\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss a step 9050: 0.685932\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss a step 9100: 0.060179\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss a step 9150: 0.285763\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss a step 9200: 0.180853\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss a step 9250: 0.666255\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss a step 9300: 0.445903\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss a step 9350: 0.570814\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss a step 9400: 0.054248\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss a step 9450: 0.635755\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss a step 9500: 0.383941\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss a step 9550: 0.068292\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss a step 9600: 0.187101\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.4%\n",
      "Minibatch loss a step 9650: 0.412991\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss a step 9700: 0.245654\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss a step 9750: 0.638207\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss a step 9800: 0.396564\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss a step 9850: 0.601796\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss a step 9900: 0.084476\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss a step 9950: 0.154194\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.2%\n",
      "Minibatch loss a step 10000: 0.229965\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 88.6%\n",
      "Test accuracy: 94.6%\n"
     ]
    }
   ],
   "source": [
    "num_steps=10001\n",
    "\n",
    "with tf.Session(graph=graph)as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        offset=(step*batch_size)% (train_labels.shape[0]-batch_size)\n",
    "        batch_data=train_dataset[offset:(offset+batch_size),:,:,:]\n",
    "        batch_labels=train_labels[offset:(offset+batch_size),:]\n",
    "        feed_dict={tf_train_dataset : batch_data,tf_train_labels: batch_labels}\n",
    "        _, l, predictions =session.run([optimizer,loss,train_prediction],feed_dict=feed_dict)\n",
    "        if(step%50==0):\n",
    "            print('Minibatch loss a step %d: %f' %(step,l))\n",
    "            print('Minibatch Accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "            print('Validation accuracy: %.1f%%'%accuracy(valid_prediction.eval(),valid_labels))\n",
    "    print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conv with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "image_size=28\n",
    "#create image size function based on input, filter size, padding and stride\n",
    "#2 convolutions only with 2 pooling\n",
    "def output_size_pool(input_size, conv_filter_size,pool_filter_size, padding, conv_stride, pool_stride):\n",
    "    if padding =='same':\n",
    "        padding=-1.00\n",
    "    elif padding=='valid':\n",
    "        padding=0.00\n",
    "    else:\n",
    "        return None\n",
    "    #after convolution 1\n",
    "    output_1=(((input_size-conv_filter_size-2*padding)/ conv_stride)+1.00)\n",
    "    #after pool 1\n",
    "    output_2=(((output_1-pool_filter_size-2*padding)/pool_stride)+1.00)\n",
    "    #After convolution 2\n",
    "    output_3=(((output_2-conv_filter_size-2*padding)/conv_stride)+1.00)\n",
    "    #after pool 2\n",
    "    output_4=(((output_3-pool_filter_size-2*padding)/pool_stride)+1.00)\n",
    "    return int(output_4)\n",
    "final_image_size=output_size_pool(\n",
    "    input_size=image_size,conv_filter_size=5,pool_filter_size=2,\n",
    "    padding='valid', conv_stride=1, pool_stride=2)\n",
    "print(final_image_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "patch_size=5\n",
    "depth=32\n",
    "num_hidden=64\n",
    "beta=0.001\n",
    "\n",
    "graph=tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    #input data\n",
    "    tf_train_dataset=tf.placeholder(tf.float32, \n",
    "                                    shape=(batch_size,image_size,image_size,num_channels))\n",
    "    tf_train_labels=tf.placeholder(tf.float32, shape=(batch_size,num_labels))\n",
    "    tf_valid_dataset=tf.constant(valid_dataset)\n",
    "    tf_test_dataset=tf.constant(test_dataset)\n",
    "    \n",
    "    #variables\n",
    "    layer1_weights=tf.Variable(tf.truncated_normal\n",
    "                               ([patch_size,patch_size,num_channels,depth],stddev=0.1))\n",
    "    layer1_biases=tf.Variable(tf.zeros([depth]))\n",
    "    \n",
    "    layer2_weights=tf.Variable(tf.truncated_normal\n",
    "                               ([patch_size,patch_size,depth,depth],stddev=0.1))\n",
    "    layer2_biases=tf.Variable(tf.constant(1.0,shape=[depth]))\n",
    "    \n",
    "    final_image_size=output_size_pool(input_size=image_size,\n",
    "                                      conv_filter_size=5,pool_filter_size=2,padding='valid',\n",
    "                                      conv_stride=1,pool_stride=2)\n",
    "    \n",
    "    \n",
    "    layer3_weights=tf.Variable(tf.truncated_normal\n",
    "                               ([final_image_size*final_image_size*depth,num_hidden],stddev=0.1))\n",
    "    layer3_biases=tf.Variable(tf.constant(1.0,shape=[num_hidden]))\n",
    "    \n",
    "    \n",
    "    layer4_weights=tf.Variable(tf.truncated_normal\n",
    "                               ([num_hidden,num_hidden],stddev=0.1))\n",
    "    layer4_biases=tf.Variable(tf.constant(1.0,shape=[num_hidden]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    layer5_weights=tf.Variable(tf.truncated_normal\n",
    "                               ([num_hidden,num_labels],stddev=0.1))\n",
    "    layer5_biases=tf.Variable(tf.constant(1.0,shape=[num_labels]))\n",
    "    \n",
    "    #Model\n",
    "    def model(data):\n",
    "        #1st conv layer with pooling\n",
    "        conv_1=tf.nn.conv2d(data,layer1_weights,[1,1,1,1], padding='VALID')\n",
    "        hidden_1=tf.nn.relu(conv_1+layer1_biases)\n",
    "        pool_1=tf.nn.avg_pool(hidden_1,[1,2,2,1],[1,2,2,1], padding='VALID')\n",
    "        \n",
    "         #2nd conv layer with pooling\n",
    "        conv_2=tf.nn.conv2d(pool_1,layer2_weights,[1,1,1,1], padding='VALID')\n",
    "        hidden_2=tf.nn.relu(conv_2+layer2_biases)\n",
    "        pool_2=tf.nn.avg_pool(hidden_2,[1,2,2,1],[1,2,2,1], padding='VALID')\n",
    "        \n",
    "         #1st fully connected layer\n",
    "        shape=pool_2.get_shape().as_list()\n",
    "        reshape=tf.reshape(pool_2,[shape[0],shape[1]*shape[2]*shape[3]])\n",
    "        hidden=tf.nn.relu(tf.matmul(reshape, layer3_weights)+layer3_biases)\n",
    "        keep_prob=0.5\n",
    "        hidden_drop=tf.nn.dropout(hidden,keep_prob)\n",
    "        \n",
    "        #2nd fully connected layer\n",
    "        hidden_2=tf.nn.relu(tf.matmul(hidden_drop, layer4_weights)+layer4_biases)\n",
    "        hidden_2_drop=tf.nn.dropout(hidden_2,keep_prob)\n",
    "        \n",
    "        return tf.matmul(hidden_2_drop, layer5_weights)+ layer5_biases\n",
    "    \n",
    "    #training computation\n",
    "    \n",
    "    logits=model(tf_train_dataset)\n",
    "    loss=tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels,logits=logits))\n",
    "    \n",
    "    #optimizer\n",
    "    global_step=tf.Variable(0)\n",
    "    start_learning_rate=0.05\n",
    "    learning_rate=tf.train.exponential_decay(start_learning_rate, global_step,100000,0.96,\n",
    "                                             staircase=True)\n",
    "    \n",
    "    optimizer=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    #Predictions for the training , validation, and test data\n",
    "    \n",
    "    train_prediction= tf.nn.softmax(logits)\n",
    "    valid_prediction= tf.nn.softmax(model(tf_valid_dataset))\n",
    "    test_prediction= tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss a step 0: 0.470166\n",
      "Minibatch Accuracy: 18.8%\n",
      "Validation accuracy: 6.9%\n",
      "Minibatch loss a step 50: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 100: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 150: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 200: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 250: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 300: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 350: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 400: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 450: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 500: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 550: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 600: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 650: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 700: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 750: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 800: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 850: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 900: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 950: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1000: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1050: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1100: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1150: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1200: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1250: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1300: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1350: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1400: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1450: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1500: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1550: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1600: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1650: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1700: nan\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1750: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1800: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1850: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1900: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 1950: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 2000: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 2050: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 2100: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 2150: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 2200: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 2250: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 2300: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 2350: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 2400: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 2450: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 2500: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 2550: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 2600: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 2650: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 2700: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 2750: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 2800: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 2850: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 2900: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 2950: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 3000: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 3050: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 3100: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 3150: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 3200: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 3250: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 3300: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 3350: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 3400: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 3450: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 3500: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 3550: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 3600: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 3650: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 3700: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 3750: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 3800: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 3850: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 3900: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 3950: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 4000: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 4050: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 4100: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 4150: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 4200: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 4250: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 4300: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 4350: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 4400: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 4450: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 4500: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 4550: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 4600: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 4650: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 4700: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 4750: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 4800: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 4850: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 4900: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 4950: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 5000: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 5050: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 5100: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 5150: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 5200: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 5250: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 5300: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 5350: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 5400: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 5450: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 5500: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 5550: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 5600: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 5650: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 5700: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 5750: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 5800: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 5850: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 5900: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 5950: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 6000: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 6050: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 6100: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 6150: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 6200: nan\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 6250: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 6300: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 6350: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 6400: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 6450: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 6500: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 6550: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 6600: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 6650: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 6700: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 6750: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 6800: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 6850: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 6900: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 6950: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 7000: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 7050: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 7100: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 7150: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 7200: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 7250: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 7300: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 7350: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 7400: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 7450: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 7500: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 7550: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 7600: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 7650: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 7700: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 7750: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 7800: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 7850: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 7900: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 7950: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8000: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8050: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8100: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8150: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8200: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8250: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8300: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8350: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8400: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8450: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8500: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8550: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8600: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8650: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8700: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8750: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8800: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8850: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8900: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 8950: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 9000: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 9050: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 9100: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 9150: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 9200: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 9250: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 9300: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 9350: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 9400: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 9450: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 9500: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 9550: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 9600: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 9650: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 9700: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 9750: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 9800: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 9850: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 9900: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 9950: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 10000: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 10050: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 10100: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 10150: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 10200: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 10250: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 10300: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 10350: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 10400: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 10450: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 10500: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 10550: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 10600: nan\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 10650: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 10700: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 10750: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 10800: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 10850: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 10900: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 10950: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 11000: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 11050: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 11100: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 11150: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 11200: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 11250: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 11300: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 11350: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 11400: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 11450: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 11500: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 11550: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 11600: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 11650: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 11700: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 11750: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 11800: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 11850: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 11900: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 11950: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 12000: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 12050: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 12100: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 12150: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 12200: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 12250: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 12300: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 12350: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 12400: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 12450: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 12500: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 12550: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 12600: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 12650: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 12700: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 12750: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 12800: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 12850: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 12900: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 12950: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 13000: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 13050: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 13100: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 13150: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 13200: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 13250: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 13300: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 13350: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 13400: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 13450: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 13500: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 13550: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 13600: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 13650: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 13700: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 13750: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 13800: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 13850: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 13900: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 13950: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 14000: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 14050: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 14100: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 14150: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 14200: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 14250: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 14300: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 14350: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 14400: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 14450: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 14500: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 14550: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 14600: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 14650: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 14700: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 14750: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 14800: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 14850: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 14900: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 14950: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 15000: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 15050: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 15100: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 15150: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 15200: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 15250: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 15300: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 15350: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 15400: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 15450: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 15500: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 15550: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 15600: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 15650: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 15700: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 15750: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 15800: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 15850: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 15900: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 15950: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 16000: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 16050: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 16100: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 16150: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 16200: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 16250: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 16300: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 16350: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 16400: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 16450: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 16500: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 16550: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 16600: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 16650: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 16700: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 16750: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 16800: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 16850: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 16900: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 16950: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 17000: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 17050: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 17100: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 17150: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 17200: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 17250: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 17300: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 17350: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 17400: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 17450: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 17500: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 17550: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 17600: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 17650: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 17700: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 17750: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 17800: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 17850: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 17900: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 17950: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 18000: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 18050: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 18100: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 18150: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 18200: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 18250: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 18300: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 18350: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 18400: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 18450: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 18500: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 18550: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 18600: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 18650: nan\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 18700: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 18750: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 18800: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 18850: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 18900: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 18950: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 19000: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 19050: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 19100: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 19150: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 19200: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 19250: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 19300: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 19350: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 19400: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 19450: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 19500: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 19550: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 19600: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 19650: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 19700: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 19750: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 19800: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 19850: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 19900: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 19950: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 20000: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 20050: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 20100: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 20150: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 20200: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 20250: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 20300: nan\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 20350: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 20400: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 20450: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 20500: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 20550: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 20600: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 20650: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 20700: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 20750: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 20800: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 20850: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 20900: nan\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 20950: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 21000: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 21050: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 21100: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 21150: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 21200: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 21250: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 21300: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 21350: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 21400: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 21450: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 21500: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 21550: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 21600: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 21650: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 21700: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 21750: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 21800: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 21850: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 21900: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 21950: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 22000: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 22050: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 22100: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 22150: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 22200: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 22250: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 22300: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 22350: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 22400: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 22450: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 22500: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 22550: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 22600: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 22650: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 22700: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 22750: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 22800: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 22850: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 22900: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 22950: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 23000: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 23050: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 23100: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 23150: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 23200: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 23250: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 23300: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 23350: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 23400: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 23450: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 23500: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 23550: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 23600: nan\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 23650: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 23700: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 23750: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 23800: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 23850: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 23900: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 23950: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 24000: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 24050: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 24100: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 24150: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 24200: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 24250: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 24300: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 24350: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 24400: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 24450: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 24500: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 24550: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 24600: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 24650: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 24700: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 24750: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 24800: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 24850: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 24900: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 24950: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 25000: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 25050: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 25100: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 25150: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 25200: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 25250: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 25300: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 25350: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 25400: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 25450: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 25500: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 25550: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 25600: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 25650: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 25700: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 25750: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 25800: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 25850: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 25900: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 25950: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 26000: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 26050: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 26100: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 26150: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 26200: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 26250: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 26300: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 26350: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 26400: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 26450: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 26500: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 26550: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 26600: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 26650: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 26700: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 26750: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 26800: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 26850: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 26900: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 26950: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 27000: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 27050: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 27100: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 27150: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 27200: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 27250: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 27300: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 27350: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 27400: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 27450: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 27500: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 27550: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 27600: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 27650: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 27700: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 27750: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 27800: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 27850: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 27900: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 27950: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 28000: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 28050: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 28100: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 28150: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 28200: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 28250: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 28300: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 28350: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 28400: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 28450: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 28500: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 28550: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 28600: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 28650: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 28700: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 28750: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 28800: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 28850: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 28900: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 28950: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 29000: nan\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 29050: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 29100: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 29150: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 29200: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 29250: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 29300: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 29350: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 29400: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 29450: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 29500: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 29550: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 29600: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 29650: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 29700: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 29750: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 29800: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 29850: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 29900: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 29950: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 30000: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 30050: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 30100: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 30150: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 30200: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 30250: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 30300: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 30350: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 30400: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 30450: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 30500: nan\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 30550: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 30600: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 30650: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 30700: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 30750: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 30800: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 30850: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 30900: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 30950: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 31000: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 31050: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 31100: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 31150: nan\n",
      "Minibatch Accuracy: 62.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 31200: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 31250: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 31300: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 31350: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 31400: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 31450: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 31500: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 31550: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 31600: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 31650: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 31700: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 31750: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 31800: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 31850: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 31900: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 31950: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 32000: nan\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 32050: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 32100: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 32150: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 32200: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 32250: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 32300: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 32350: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 32400: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 32450: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 32500: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 32550: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 32600: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 32650: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 32700: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 32750: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 32800: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 32850: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 32900: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 32950: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 33000: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 33050: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 33100: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 33150: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 33200: nan\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 33250: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 33300: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 33350: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 33400: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 33450: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 33500: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 33550: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 33600: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 33650: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 33700: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 33750: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 33800: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 33850: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 33900: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 33950: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 34000: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 34050: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 34100: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 34150: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 34200: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 34250: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 34300: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 34350: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 34400: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 34450: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 34500: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 34550: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 34600: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 34650: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 34700: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 34750: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 34800: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 34850: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 34900: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 34950: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 35000: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 35050: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 35100: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 35150: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 35200: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 35250: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 35300: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 35350: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 35400: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 35450: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 35500: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 35550: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 35600: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 35650: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 35700: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 35750: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 35800: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 35850: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 35900: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 35950: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 36000: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 36050: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 36100: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 36150: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 36200: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 36250: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 36300: nan\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 36350: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 36400: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 36450: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 36500: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 36550: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 36600: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 36650: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 36700: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 36750: nan\n",
      "Minibatch Accuracy: 50.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 36800: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 36850: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 36900: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 36950: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 37000: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 37050: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 37100: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 37150: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 37200: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 37250: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 37300: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 37350: nan\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 37400: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 37450: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 37500: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 37550: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 37600: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 37650: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 37700: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 37750: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 37800: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 37850: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 37900: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 37950: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 38000: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 38050: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 38100: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 38150: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 38200: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 38250: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 38300: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 38350: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 38400: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 38450: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 38500: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 38550: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 38600: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 38650: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 38700: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 38750: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 38800: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 38850: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 38900: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 38950: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 39000: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 39050: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 39100: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 39150: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 39200: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 39250: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 39300: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 39350: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 39400: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 39450: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 39500: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 39550: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 39600: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 39650: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 39700: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 39750: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 39800: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 39850: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 39900: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 39950: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 40000: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 40050: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 40100: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 40150: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 40200: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 40250: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 40300: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 40350: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 40400: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 40450: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 40500: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 40550: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 40600: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 40650: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 40700: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 40750: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 40800: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 40850: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 40900: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 40950: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 41000: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 41050: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 41100: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 41150: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 41200: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 41250: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 41300: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 41350: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 41400: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 41450: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 41500: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 41550: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 41600: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 41650: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 41700: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 41750: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 41800: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 41850: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 41900: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 41950: nan\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 42000: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 42050: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 42100: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 42150: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 42200: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 42250: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 42300: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 42350: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 42400: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 42450: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 42500: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 42550: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 42600: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 42650: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 42700: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 42750: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 42800: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 42850: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 42900: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 42950: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 43000: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 43050: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 43100: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 43150: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 43200: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 43250: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 43300: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 43350: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 43400: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 43450: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 43500: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 43550: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 43600: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 43650: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 43700: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 43750: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 43800: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 43850: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 43900: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 43950: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 44000: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 44050: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 44100: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 44150: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 44200: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 44250: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 44300: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 44350: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 44400: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 44450: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 44500: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 44550: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 44600: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 44650: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 44700: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 44750: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 44800: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 44850: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 44900: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 44950: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 45000: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 45050: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 45100: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 45150: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 45200: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 45250: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 45300: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 45350: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 45400: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 45450: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 45500: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 45550: nan\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 45600: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 45650: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 45700: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 45750: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 45800: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 45850: nan\n",
      "Minibatch Accuracy: 62.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 45900: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 45950: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 46000: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 46050: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 46100: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 46150: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 46200: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 46250: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 46300: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 46350: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 46400: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 46450: nan\n",
      "Minibatch Accuracy: 62.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 46500: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 46550: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 46600: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 46650: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 46700: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 46750: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 46800: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 46850: nan\n",
      "Minibatch Accuracy: 68.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 46900: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 46950: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 47000: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 47050: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 47100: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 47150: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 47200: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 47250: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 47300: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 47350: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 47400: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 47450: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 47500: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 47550: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 47600: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 47650: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 47700: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 47750: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 47800: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 47850: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 47900: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 47950: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 48000: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 48050: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 48100: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 48150: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 48200: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 48250: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 48300: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 48350: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 48400: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 48450: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 48500: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 48550: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 48600: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 48650: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 48700: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 48750: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 48800: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 48850: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 48900: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 48950: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 49000: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 49050: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 49100: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 49150: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 49200: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 49250: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 49300: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 49350: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 49400: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 49450: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 49500: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 49550: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 49600: nan\n",
      "Minibatch Accuracy: 100.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 49650: nan\n",
      "Minibatch Accuracy: 81.2%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 49700: nan\n",
      "Minibatch Accuracy: 75.0%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 49750: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 49800: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 49850: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 49900: nan\n",
      "Minibatch Accuracy: 87.5%\n",
      "Validation accuracy: 89.3%\n",
      "Minibatch loss a step 49950: nan\n",
      "Minibatch Accuracy: 93.8%\n",
      "Validation accuracy: 89.3%\n",
      "Test accuracy: 89.3%\n"
     ]
    }
   ],
   "source": [
    "num_steps=50000\n",
    "\n",
    "with tf.Session(graph=graph)as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        offset=(step*batch_size)% (train_labels.shape[0]-batch_size)\n",
    "        batch_data=train_dataset[offset:(offset+batch_size),:,:,:]\n",
    "        batch_labels=train_labels[offset:(offset+batch_size),:]\n",
    "        feed_dict={tf_train_dataset : batch_data,tf_train_labels: batch_labels}\n",
    "        _, l, predictions =session.run([optimizer,loss,train_prediction],feed_dict=feed_dict)\n",
    "        if(step%50==0):\n",
    "            print('Minibatch loss a step %d: %f' %(step,l))\n",
    "            print('Minibatch Accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "            print('Validation accuracy: %.1f%%'%accuracy(valid_prediction.eval(),valid_labels))\n",
    "    print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
