{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./notMNIST_large already present - Skipping extraction of ./notMNIST_large.tar.gz\n",
      "['./notMNIST_large/A', './notMNIST_large/B', './notMNIST_large/C', './notMNIST_large/D', './notMNIST_large/E', './notMNIST_large/F', './notMNIST_large/G', './notMNIST_large/H', './notMNIST_large/I', './notMNIST_large/J']\n",
      "./notMNIST_small already present - Skipping extraction of ./notMNIST_small.tar.gz\n",
      "['./notMNIST_small/A', './notMNIST_small/B', './notMNIST_small/C', './notMNIST_small/D', './notMNIST_small/E', './notMNIST_small/F', './notMNIST_small/G', './notMNIST_small/H', './notMNIST_small/I', './notMNIST_small/J']\n"
     ]
    }
   ],
   "source": [
    "num_classes=10\n",
    "np.random.seed(133)\n",
    "data_root='.'\n",
    "train_filename= os.path.join(data_root, 'notMNIST_large.tar.gz') #join os root and extention(dataroot)\n",
    "test_filename= os.path.join(data_root, 'notMNIST_small.tar.gz')\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "    root=os.path.splitext(os.path.splitext(filename)[0])[0] #splits the os root and extension \n",
    "    if os.path.isdir(root)and not force:\n",
    "        print('%s already present - Skipping extraction of %s' %(root, filename))\n",
    "    else:\n",
    "        print('extracting data %s.this may take a while .please wait.' %root)\n",
    "        tar=tarfile.open(filename)\n",
    "        sys.stdout.flush()\n",
    "        tar.extractall(data_root)\n",
    "        tar.close()\n",
    "    data_folders = [\n",
    "        os.path.join(root, d)for d in sorted(os.listdir(root)) #listing all the classes directory\n",
    "        if os.path.isdir(os.path.join(root, d))]\n",
    "    if len(data_folders) !=num_classes: #checks lengths\n",
    "        raise Exception(\n",
    "            'Expected %d folders , one per class. found %d instead.' % (\n",
    "                num_classes,len(data_folders)))\n",
    "    print(data_folders)\n",
    "    return data_folders\n",
    "    \n",
    "    \n",
    "train_folders= maybe_extract(train_filename)\n",
    "test_folders=maybe_extract(test_filename)\n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickling ./notMNIST_large/A.pickle.\n",
      "./notMNIST_large/A\n",
      "couldnot read : ./notMNIST_large/A/SG90IE11c3RhcmQgQlROIFBvc3Rlci50dGY=.png : cannot identify image file './notMNIST_large/A/SG90IE11c3RhcmQgQlROIFBvc3Rlci50dGY=.png' -it's ok , skipping.\n",
      "couldnot read : ./notMNIST_large/A/Um9tYW5hIEJvbGQucGZi.png : cannot identify image file './notMNIST_large/A/Um9tYW5hIEJvbGQucGZi.png' -it's ok , skipping.\n",
      "couldnot read : ./notMNIST_large/A/RnJlaWdodERpc3BCb29rSXRhbGljLnR0Zg==.png : cannot identify image file './notMNIST_large/A/RnJlaWdodERpc3BCb29rSXRhbGljLnR0Zg==.png' -it's ok , skipping.\n",
      "Full dataset tensor: (52909, 28, 28)\n",
      "mean: -0.12825\n",
      "standard deviation: 0.44312\n",
      "pickling ./notMNIST_large/B.pickle.\n",
      "./notMNIST_large/B\n",
      "couldnot read : ./notMNIST_large/B/TmlraXNFRi1TZW1pQm9sZEl0YWxpYy5vdGY=.png : cannot identify image file './notMNIST_large/B/TmlraXNFRi1TZW1pQm9sZEl0YWxpYy5vdGY=.png' -it's ok , skipping.\n",
      "Full dataset tensor: (52911, 28, 28)\n",
      "mean: -0.00756303\n",
      "standard deviation: 0.454491\n",
      "pickling ./notMNIST_large/C.pickle.\n",
      "./notMNIST_large/C\n",
      "Full dataset tensor: (52912, 28, 28)\n",
      "mean: -0.142258\n",
      "standard deviation: 0.439807\n",
      "pickling ./notMNIST_large/D.pickle.\n",
      "./notMNIST_large/D\n",
      "couldnot read : ./notMNIST_large/D/VHJhbnNpdCBCb2xkLnR0Zg==.png : cannot identify image file './notMNIST_large/D/VHJhbnNpdCBCb2xkLnR0Zg==.png' -it's ok , skipping.\n",
      "Full dataset tensor: (52911, 28, 28)\n",
      "mean: -0.0573678\n",
      "standard deviation: 0.455647\n",
      "pickling ./notMNIST_large/E.pickle.\n",
      "./notMNIST_large/E\n",
      "Full dataset tensor: (52912, 28, 28)\n",
      "mean: -0.069899\n",
      "standard deviation: 0.452942\n",
      "pickling ./notMNIST_large/F.pickle.\n",
      "./notMNIST_large/F\n",
      "Full dataset tensor: (52912, 28, 28)\n",
      "mean: -0.125583\n",
      "standard deviation: 0.44709\n",
      "pickling ./notMNIST_large/G.pickle.\n",
      "./notMNIST_large/G\n",
      "Full dataset tensor: (52912, 28, 28)\n",
      "mean: -0.0945814\n",
      "standard deviation: 0.446239\n",
      "pickling ./notMNIST_large/H.pickle.\n",
      "./notMNIST_large/H\n",
      "Full dataset tensor: (52912, 28, 28)\n",
      "mean: -0.0685222\n",
      "standard deviation: 0.454232\n",
      "pickling ./notMNIST_large/I.pickle.\n",
      "./notMNIST_large/I\n",
      "Full dataset tensor: (52912, 28, 28)\n",
      "mean: 0.0307862\n",
      "standard deviation: 0.468899\n",
      "pickling ./notMNIST_large/J.pickle.\n",
      "./notMNIST_large/J\n",
      "Full dataset tensor: (52911, 28, 28)\n",
      "mean: -0.153358\n",
      "standard deviation: 0.443656\n",
      "pickling ./notMNIST_small/A.pickle.\n",
      "./notMNIST_small/A\n",
      "couldnot read : ./notMNIST_small/A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png : cannot identify image file './notMNIST_small/A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png' -it's ok , skipping.\n",
      "Full dataset tensor: (1872, 28, 28)\n",
      "mean: -0.132626\n",
      "standard deviation: 0.445128\n",
      "pickling ./notMNIST_small/B.pickle.\n",
      "./notMNIST_small/B\n",
      "Full dataset tensor: (1873, 28, 28)\n",
      "mean: 0.00535608\n",
      "standard deviation: 0.457115\n",
      "pickling ./notMNIST_small/C.pickle.\n",
      "./notMNIST_small/C\n",
      "Full dataset tensor: (1873, 28, 28)\n",
      "mean: -0.141521\n",
      "standard deviation: 0.44269\n",
      "pickling ./notMNIST_small/D.pickle.\n",
      "./notMNIST_small/D\n",
      "Full dataset tensor: (1873, 28, 28)\n",
      "mean: -0.0492167\n",
      "standard deviation: 0.459759\n",
      "pickling ./notMNIST_small/E.pickle.\n",
      "./notMNIST_small/E\n",
      "Full dataset tensor: (1873, 28, 28)\n",
      "mean: -0.0599148\n",
      "standard deviation: 0.45735\n",
      "pickling ./notMNIST_small/F.pickle.\n",
      "./notMNIST_small/F\n",
      "couldnot read : ./notMNIST_small/F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png : cannot identify image file './notMNIST_small/F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png' -it's ok , skipping.\n",
      "Full dataset tensor: (1872, 28, 28)\n",
      "mean: -0.118185\n",
      "standard deviation: 0.452279\n",
      "pickling ./notMNIST_small/G.pickle.\n",
      "./notMNIST_small/G\n",
      "Full dataset tensor: (1872, 28, 28)\n",
      "mean: -0.0925503\n",
      "standard deviation: 0.449006\n",
      "pickling ./notMNIST_small/H.pickle.\n",
      "./notMNIST_small/H\n",
      "Full dataset tensor: (1872, 28, 28)\n",
      "mean: -0.0586892\n",
      "standard deviation: 0.458759\n",
      "pickling ./notMNIST_small/I.pickle.\n",
      "./notMNIST_small/I\n",
      "Full dataset tensor: (1872, 28, 28)\n",
      "mean: 0.0526451\n",
      "standard deviation: 0.471893\n",
      "pickling ./notMNIST_small/J.pickle.\n",
      "./notMNIST_small/J\n",
      "Full dataset tensor: (1872, 28, 28)\n",
      "mean: -0.151689\n",
      "standard deviation: 0.448014\n"
     ]
    }
   ],
   "source": [
    "image_size=28 #pixel width and height\n",
    "pixel_depth=255.0 #Nurmber of levels per pixel\n",
    "\n",
    "def load_letter(folder, min_num_images):\n",
    "    \"\"\"Load the data for a single letter label\"\"\"\n",
    "    image_files=os.listdir(folder)\n",
    "    dataset=np.ndarray(shape=(len(image_files),image_size, image_size),dtype=np.float32)\n",
    "    print(folder)\n",
    "    num_images=0\n",
    "    for image in image_files:\n",
    "        image_file=os.path.join(folder,image)\n",
    "        try:\n",
    "            image_data=(ndimage.imread(image_file).astype(float) - pixel_depth /2)/pixel_depth\n",
    "            if image_data.shape !=(image_size,image_size):\n",
    "                raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "            dataset[num_images,:,:]=image_data\n",
    "            num_images=num_images + 1\n",
    "        except IOError as e:\n",
    "            print('couldnot read :', image_file , ':', e , '-it\\'s ok , skipping.')\n",
    "    dataset=dataset[0:num_images, :, :]\n",
    "    if num_images < min_num_images:\n",
    "        raise Exception('many fewer images then expected: %d < %d' % (num_images, min_num_images))\n",
    "    print('Full dataset tensor:', dataset.shape)\n",
    "    print('mean:', np.mean(dataset))\n",
    "    print('standard deviation:', np.std(dataset))\n",
    "    return dataset\n",
    "\n",
    "def maybe_pickle(data_folders, min_num_images_per_class, force=False):\n",
    "    dataset_names=[]\n",
    "    for folder in data_folders:\n",
    "        set_filename=folder+ '.pickle'\n",
    "        dataset_names.append(set_filename)\n",
    "        if os.path.exists(set_filename)and not force:\n",
    "            print('%s already present - skipping pickling.' % set_filename)\n",
    "        else:\n",
    "            print('pickling %s.' % set_filename)\n",
    "            dataset=load_letter(folder,min_num_images_per_class)\n",
    "            try:\n",
    "                with open(set_filename, 'wb')as f:\n",
    "                    pickle.dump(dataset,f, pickle.HIGHEST_PROTOCOL)\n",
    "            except Exception as e:\n",
    "                print('Unable to save data to', set_filename, ':',e)\n",
    "    return dataset_names\n",
    "train_datasets=maybe_pickle(train_folders, 45000)\n",
    "test_datasets=maybe_pickle(test_folders, 1800)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
