{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./notMNIST_large already present - Skipping extraction of ./notMNIST_large.tar.gz\n",
      "['./notMNIST_large/A', './notMNIST_large/B', './notMNIST_large/C', './notMNIST_large/D', './notMNIST_large/E', './notMNIST_large/F', './notMNIST_large/G', './notMNIST_large/H', './notMNIST_large/I', './notMNIST_large/J']\n",
      "./notMNIST_small already present - Skipping extraction of ./notMNIST_small.tar.gz\n",
      "['./notMNIST_small/A', './notMNIST_small/B', './notMNIST_small/C', './notMNIST_small/D', './notMNIST_small/E', './notMNIST_small/F', './notMNIST_small/G', './notMNIST_small/H', './notMNIST_small/I', './notMNIST_small/J']\n"
     ]
    }
   ],
   "source": [
    "num_classes=10\n",
    "np.random.seed(133)\n",
    "data_root='.'\n",
    "train_filename= os.path.join(data_root, 'notMNIST_large.tar.gz') #join os root and extention(dataroot)\n",
    "test_filename= os.path.join(data_root, 'notMNIST_small.tar.gz')\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "    root=os.path.splitext(os.path.splitext(filename)[0])[0] #splits the os root and extension \n",
    "    if os.path.isdir(root)and not force:\n",
    "        print('%s already present - Skipping extraction of %s' %(root, filename))\n",
    "    else:\n",
    "        print('extracting data %s.this may take a while .please wait.' %root)\n",
    "        tar=tarfile.open(filename)\n",
    "        sys.stdout.flush()\n",
    "        tar.extractall(data_root)\n",
    "        tar.close()\n",
    "    data_folders = [\n",
    "        os.path.join(root, d)for d in sorted(os.listdir(root)) #listing all the classes directory\n",
    "        if os.path.isdir(os.path.join(root, d))]\n",
    "    if len(data_folders) !=num_classes: #checks lengths\n",
    "        raise Exception(\n",
    "            'Expected %d folders , one per class. found %d instead.' % (\n",
    "                num_classes,len(data_folders)))\n",
    "    print(data_folders)\n",
    "    return data_folders\n",
    "    \n",
    "    \n",
    "train_folders= maybe_extract(train_filename)\n",
    "test_folders=maybe_extract(test_filename)\n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./notMNIST_large/A.pickle already present - skipping pickling.\n",
      "./notMNIST_large/B.pickle already present - skipping pickling.\n",
      "./notMNIST_large/C.pickle already present - skipping pickling.\n",
      "./notMNIST_large/D.pickle already present - skipping pickling.\n",
      "./notMNIST_large/E.pickle already present - skipping pickling.\n",
      "./notMNIST_large/F.pickle already present - skipping pickling.\n",
      "./notMNIST_large/G.pickle already present - skipping pickling.\n",
      "./notMNIST_large/H.pickle already present - skipping pickling.\n",
      "./notMNIST_large/I.pickle already present - skipping pickling.\n",
      "./notMNIST_large/J.pickle already present - skipping pickling.\n",
      "./notMNIST_small/A.pickle already present - skipping pickling.\n",
      "./notMNIST_small/B.pickle already present - skipping pickling.\n",
      "./notMNIST_small/C.pickle already present - skipping pickling.\n",
      "./notMNIST_small/D.pickle already present - skipping pickling.\n",
      "./notMNIST_small/E.pickle already present - skipping pickling.\n",
      "./notMNIST_small/F.pickle already present - skipping pickling.\n",
      "./notMNIST_small/G.pickle already present - skipping pickling.\n",
      "./notMNIST_small/H.pickle already present - skipping pickling.\n",
      "./notMNIST_small/I.pickle already present - skipping pickling.\n",
      "./notMNIST_small/J.pickle already present - skipping pickling.\n"
     ]
    }
   ],
   "source": [
    "image_size=28 #pixel width and height\n",
    "pixel_depth=255.0 #Nurmber of levels per pixel\n",
    "\n",
    "def load_letter(folder, min_num_images):\n",
    "    \"\"\"Load the data for a single letter label\"\"\"\n",
    "    image_files=os.listdir(folder)\n",
    "    dataset=np.ndarray(shape=(len(image_files),image_size, image_size),dtype=np.float32)\n",
    "    print(folder)\n",
    "    num_images=0\n",
    "    for image in image_files:\n",
    "        image_file=os.path.join(folder,image)\n",
    "        try:\n",
    "            image_data=(ndimage.imread(image_file).astype(float) - pixel_depth /2)/pixel_depth\n",
    "            if image_data.shape !=(image_size,image_size):\n",
    "                raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "            dataset[num_images,:,:]=image_data\n",
    "            num_images=num_images + 1\n",
    "        except IOError as e:\n",
    "            print('couldnot read :', image_file , ':', e , '-it\\'s ok , skipping.')\n",
    "    dataset=dataset[0:num_images, :, :]\n",
    "    if num_images < min_num_images:\n",
    "        raise Exception('many fewer images then expected: %d < %d' % (num_images, min_num_images))\n",
    "    print('Full dataset tensor:', dataset.shape)\n",
    "    print('mean:', np.mean(dataset))\n",
    "    print('standard deviation:', np.std(dataset))\n",
    "    return dataset\n",
    "\n",
    "def maybe_pickle(data_folders, min_num_images_per_class, force=False):\n",
    "    dataset_names=[]\n",
    "    for folder in data_folders:\n",
    "        set_filename=folder+ '.pickle'\n",
    "        dataset_names.append(set_filename)\n",
    "        if os.path.exists(set_filename)and not force:\n",
    "            print('%s already present - skipping pickling.' % set_filename)\n",
    "        else:\n",
    "            print('pickling %s.' % set_filename)\n",
    "            dataset=load_letter(folder,min_num_images_per_class)\n",
    "            try:\n",
    "                with open(set_filename, 'wb')as f:\n",
    "                    pickle.dump(dataset,f, pickle.HIGHEST_PROTOCOL)\n",
    "            except Exception as e:\n",
    "                print('Unable to save data to', set_filename, ':',e)\n",
    "    return dataset_names\n",
    "train_datasets=maybe_pickle(train_folders, 45000)#Not MNIST Large\n",
    "test_datasets=maybe_pickle(test_folders, 1800)#Not MNIST SMALL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52909, 28, 28)\n",
      "41480656\n",
      "[[-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.48823529 -0.5\n",
      "  -0.20588236  0.31568629 -0.44901961 -0.49607843 -0.49607843 -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.49215686 -0.5\n",
      "   0.21372549  0.5        -0.14313726 -0.5        -0.48823529 -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.48823529 -0.5        -0.30784315\n",
      "   0.48039216  0.49607843  0.25294119 -0.5        -0.49607843 -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.48823529 -0.5         0.09607843\n",
      "   0.5         0.48823529  0.48431373 -0.31568629 -0.5        -0.49215686\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.49215686 -0.5        -0.4137255   0.43333334\n",
      "   0.49215686  0.48039216  0.5         0.06470589 -0.5        -0.48823529\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.48431373 -0.5        -0.06078431  0.5         0.5\n",
      "   0.49607843  0.5         0.40196079 -0.43725491 -0.49607843 -0.49607843\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.49607843 -0.49607843 -0.47647059  0.32745099  0.5\n",
      "   0.18627451  0.45686275  0.5         0.5        -0.12352941 -0.5\n",
      "  -0.48431373 -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.48431373 -0.5        -0.21372549  0.5         0.43725491\n",
      "  -0.39803922  0.28039217  0.5         0.5         0.26862746 -0.49607843\n",
      "  -0.49607843 -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.49215686 -0.5         0.18235295  0.49607843  0.15490197\n",
      "  -0.5        -0.0372549   0.5         0.48823529  0.49215686 -0.29607844\n",
      "  -0.5        -0.48823529 -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.49215686 -0.5        -0.34705883  0.46470588  0.5        -0.2254902\n",
      "  -0.49607843 -0.37058824  0.45686275  0.49215686  0.5         0.09215686\n",
      "  -0.5        -0.48823529 -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.48823529 -0.5         0.03333334  0.5         0.32352942 -0.48039216\n",
      "  -0.49215686 -0.5         0.18235295  0.5         0.49607843  0.41764706\n",
      "  -0.4254902  -0.5        -0.49215686 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.49607843 -0.49607843 -0.43725491  0.38627452  0.5        -0.03333334\n",
      "  -0.5        -0.47254902 -0.5        -0.18627451  0.5         0.48039216\n",
      "   0.5        -0.09607843 -0.5        -0.48431373 -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.48431373 -0.5        -0.11568628  0.5         0.44901961 -0.37450981\n",
      "  -0.5        -0.48823529 -0.5        -0.46078432  0.37843138  0.5         0.5\n",
      "   0.28823531 -0.49215686 -0.49607843 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.49607843 -0.49215686  0.27254903  0.5         0.18627451 -0.48823529\n",
      "  -0.47647059 -0.48431373 -0.46862745 -0.48823529  0.05686275  0.5\n",
      "   0.48431373  0.5        -0.26862746 -0.5        -0.48823529 -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.48823529\n",
      "  -0.5        -0.2647059   0.48823529  0.48431373 -0.2764706  -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.38627452  0.46078432  0.48431373\n",
      "   0.5         0.11960784 -0.5        -0.48823529 -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.48823529\n",
      "  -0.5         0.13921569  0.5         0.41764706 -0.0882353  -0.11960784\n",
      "  -0.11568628 -0.11960784 -0.11960784 -0.11568628 -0.11568628  0.37843138\n",
      "   0.5         0.5         0.43725491 -0.40588236 -0.5        -0.49607843\n",
      "  -0.5        -0.5        -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.49215686 -0.5\n",
      "  -0.37843138  0.45294118  0.5         0.5         0.5         0.5         0.5\n",
      "   0.5         0.5         0.5         0.5         0.5         0.5\n",
      "   0.48823529  0.5        -0.06470589 -0.5        -0.48431373 -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.48431373 -0.5\n",
      "  -0.01372549  0.5         0.44509804  0.11568628  0.0882353   0.08431373\n",
      "   0.08431373  0.08431373  0.08431373  0.0882353   0.08431373  0.11176471\n",
      "   0.45686275  0.49215686  0.5         0.31176472 -0.48823529 -0.49607843\n",
      "  -0.49607843 -0.5        -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.49607843 -0.5        -0.46470588\n",
      "   0.35490197  0.5         0.13137256 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5         0.1509804\n",
      "   0.5         0.48039216  0.5        -0.24509804 -0.5        -0.48823529\n",
      "  -0.5        -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.48823529 -0.5        -0.16666667\n",
      "   0.5         0.49215686 -0.26078433 -0.48431373 -0.47254902 -0.48431373\n",
      "  -0.48431373 -0.48431373 -0.48431373 -0.48431373 -0.47254902 -0.48431373\n",
      "  -0.22941177  0.5         0.48039216  0.5         0.14705883 -0.5\n",
      "  -0.48823529 -0.5        -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.49215686 -0.5         0.22941177\n",
      "   0.49607843  0.28431374 -0.49215686 -0.49607843 -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.49607843 -0.47647059\n",
      "   0.33529413  0.5         0.49215686  0.44509804 -0.39019608 -0.5\n",
      "  -0.49215686 -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.48823529 -0.49607843 -0.30392158  0.48039216\n",
      "   0.5        -0.09607843 -0.5        -0.48431373 -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.48431373 -0.5\n",
      "  -0.02941176  0.5         0.47254902  0.5        -0.04117647 -0.5\n",
      "  -0.48431373 -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.48823529 -0.5         0.08431373  0.5\n",
      "   0.40196079 -0.4254902  -0.49607843 -0.49607843 -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.49215686 -0.5\n",
      "  -0.37843138  0.46078432  0.49607843  0.5         0.33529413 -0.48039216\n",
      "  -0.49607843 -0.49607843 -0.5       ]\n",
      " [-0.5        -0.48823529 -0.48823529 -0.4137255   0.42156863  0.5\n",
      "   0.07254902 -0.5        -0.48823529 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.49215686\n",
      "  -0.5         0.18235295  0.5         0.48039216  0.5        -0.22156863\n",
      "  -0.49607843 -0.48039216 -0.5       ]\n",
      " [-0.49215686 -0.5        -0.5         0.03333334  0.5         0.47647059\n",
      "  -0.31568629 -0.49215686 -0.48431373 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.48431373\n",
      "  -0.48823529 -0.19019608  0.5         0.47647059  0.49607843  0.24901961\n",
      "  -0.5        -0.5        -0.49215686]\n",
      " [-0.5        -0.46862745 -0.11568628  0.47254902  0.48039216  0.45686275\n",
      "  -0.30000001 -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.24901961  0.48823529  0.48431373  0.48431373  0.5         0.06470589\n",
      "  -0.4137255  -0.5       ]\n",
      " [ 0.17843138  0.39411765  0.5         0.5         0.5         0.5\n",
      "   0.47647059  0.23333333 -0.30000001 -0.5        -0.49215686 -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.49607843 -0.49607843 -0.40980393\n",
      "   0.17450981  0.46078432  0.5         0.5         0.5         0.5         0.5\n",
      "   0.44901961  0.19411765]\n",
      " [ 0.48039216  0.44509804  0.20196079  0.07254902  0.0372549   0.14705883\n",
      "   0.34705883  0.5        -0.13921569 -0.5        -0.48431373 -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.49215686 -0.5        -0.3392157\n",
      "   0.5         0.39803922  0.17843138  0.02156863 -0.04901961  0.03333334\n",
      "   0.19019608  0.4254902   0.5       ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2ce67a82d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.image as mpimg\n",
    "read_pickle = pickle.load( open( \"notMNIST_large/A.pickle\", \"rb\" ) )\n",
    "print (read_pickle.shape)\n",
    "print (read_pickle.size)\n",
    "#print (read_pickle)\n",
    "print (read_pickle[0])\n",
    "imgplot = plt.imshow(read_pickle[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:  (200000, 28, 28) (200000,)\n",
      "validation : (10000, 28, 28) (10000,)\n",
      "test : (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "def make_arrays(nb_rows, img_size):\n",
    "    if nb_rows:\n",
    "        dataset=np.ndarray((nb_rows, img_size , img_size), dtype=np.float32)\n",
    "        labels=np.ndarray(nb_rows,dtype=np.float32)\n",
    "    else:\n",
    "        dataset,labels=None, None\n",
    "    return dataset,labels\n",
    "def merge_datasets(pickle_files,train_size, valid_size=0):\n",
    "    num_classes= len(pickle_files)\n",
    "    valid_dataset, valid_labels= make_arrays(valid_size, image_size)#for validation \n",
    "    train_dataset, train_labels= make_arrays(train_size, image_size)\n",
    "    vsize_per_class= valid_size // num_classes\n",
    "    tsize_per_class= train_size // num_classes\n",
    "    \n",
    "    start_v,start_t =0 , 0\n",
    "    end_v, end_t =vsize_per_class , tsize_per_class\n",
    "    end_l=vsize_per_class+tsize_per_class\n",
    "    for label, pickle_file in enumerate(pickle_files):#label=value or index of pickle files,example A,B,C,D\n",
    "        try:\n",
    "            with open(pickle_file, 'rb') as f:\n",
    "                letter_set=pickle.load(f)\n",
    "                #shuffle the letters to have random validation and training set\n",
    "                np.random.shuffle(letter_set)\n",
    "                if valid_dataset is not None:\n",
    "                    valid_letter=letter_set[:vsize_per_class, : , :]\n",
    "                    valid_dataset[start_v:end_v, : , :] = valid_letter\n",
    "                    valid_labels[start_v:end_v]= label\n",
    "                    start_v +=vsize_per_class\n",
    "                    end_v += vsize_per_class\n",
    "                    \n",
    "                train_letter= letter_set[vsize_per_class:end_l, :, :]\n",
    "                train_dataset[start_t:end_t, : ,:]=train_letter\n",
    "                train_labels[start_t:end_t]=label\n",
    "                start_t +=tsize_per_class\n",
    "                end_t += tsize_per_class\n",
    "        except Exception as e:\n",
    "            print('unable to process data from', pickle_file, '.', e)\n",
    "            raise\n",
    "    return valid_dataset,valid_labels,train_dataset, train_labels\n",
    "\n",
    "train_size= 200000\n",
    "valid_size=10000\n",
    "test_size=10000\n",
    "\n",
    "valid_dataset, valid_labels,train_dataset,train_labels = merge_datasets(train_datasets, train_size , valid_size)\n",
    "_, _, test_dataset, test_labels=merge_datasets(test_datasets,test_size)\n",
    "\n",
    "print('training: ' ,train_dataset.shape , train_labels.shape)\n",
    "print('validation :' , valid_dataset.shape , valid_labels.shape)\n",
    "print('test :', test_dataset.shape , test_labels.shape)\n",
    "                    \n",
    "                \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "[ 68123  68900  37991 ..., 173740  61878 164379]\n",
      "10000\n",
      "[4625 4363 1278 ..., 5277  230 7092]\n",
      "10000\n",
      "[2276 9308 7388 ..., 3026 9803 2236]\n"
     ]
    }
   ],
   "source": [
    "def randomize(dataset, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    print (labels.shape[0])\n",
    "    print (permutation)\n",
    "    shuffled_dataset= dataset[permutation, : , :]\n",
    "    shuffled_labels= labels[permutation]\n",
    "    return shuffled_dataset, shuffled_labels\n",
    "train_dataset , train_labels = randomize(train_dataset, train_labels)\n",
    "test_dataset , test_labels = randomize(test_dataset, test_labels)\n",
    "valid_dataset , valid_labels = randomize(valid_dataset, valid_labels)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfiKnGH4ipxh+IqcYfiKn/g/QPD7AyUuuaAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2cafa11190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgplot = plt.imshow(train_dataset [0])\n",
    "print (train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_file = os.path.join(data_root, 'notMNIST.pickle')\n",
    "try:\n",
    "    f = open(pickle_file , 'wb')\n",
    "    save= {\n",
    "        'train_dataset' : train_dataset,\n",
    "        'train_labels'  : train_labels,\n",
    "        'valid_dataset' : valid_dataset,\n",
    "        'valid_labels'  : valid_labels,\n",
    "        'test_dataset'  : test_dataset,\n",
    "        'test_label'    : test_labels,\n",
    "    }\n",
    "    pickle.dump(save, f , pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "except Exception as e:\n",
    "    print('unable to save data to', pickle_file , ':', e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compressed pickcle size: 690800405\n"
     ]
    }
   ],
   "source": [
    "statinfo= os.stat(pickle_file)\n",
    "print('compressed pickcle size:', statinfo.st_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
