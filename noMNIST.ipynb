{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Dataset into folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./notMNIST_large already present - Skipping extraction of ./notMNIST_large.tar.gz\n",
      "['./notMNIST_large/A', './notMNIST_large/B', './notMNIST_large/C', './notMNIST_large/D', './notMNIST_large/E', './notMNIST_large/F', './notMNIST_large/G', './notMNIST_large/H', './notMNIST_large/I', './notMNIST_large/J']\n",
      "./notMNIST_small already present - Skipping extraction of ./notMNIST_small.tar.gz\n",
      "['./notMNIST_small/A', './notMNIST_small/B', './notMNIST_small/C', './notMNIST_small/D', './notMNIST_small/E', './notMNIST_small/F', './notMNIST_small/G', './notMNIST_small/H', './notMNIST_small/I', './notMNIST_small/J']\n"
     ]
    }
   ],
   "source": [
    "num_classes=10\n",
    "np.random.seed(133)\n",
    "data_root='.'\n",
    "train_filename= os.path.join(data_root, 'notMNIST_large.tar.gz') #join os root and extention(dataroot)\n",
    "test_filename= os.path.join(data_root, 'notMNIST_small.tar.gz')\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "    root=os.path.splitext(os.path.splitext(filename)[0])[0] #splits the os root and extension \n",
    "    if os.path.isdir(root)and not force:\n",
    "        print('%s already present - Skipping extraction of %s' %(root, filename))\n",
    "    else:\n",
    "        print('extracting data %s.this may take a while .please wait.' %root)\n",
    "        tar=tarfile.open(filename)\n",
    "        sys.stdout.flush()\n",
    "        tar.extractall(data_root)\n",
    "        tar.close()\n",
    "    data_folders = [\n",
    "        os.path.join(root, d)for d in sorted(os.listdir(root)) #listing all the classes directory\n",
    "        if os.path.isdir(os.path.join(root, d))]\n",
    "    if len(data_folders) !=num_classes: #checks lengths\n",
    "        raise Exception(\n",
    "            'Expected %d folders , one per class. found %d instead.' % (\n",
    "                num_classes,len(data_folders)))\n",
    "    print(data_folders)\n",
    "    return data_folders\n",
    "    \n",
    "    \n",
    "train_folders= maybe_extract(train_filename)\n",
    "test_folders=maybe_extract(test_filename)\n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert image into npArray and save into pickle file with seperate class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./notMNIST_large/A.pickle already present - skipping pickling.\n",
      "./notMNIST_large/B.pickle already present - skipping pickling.\n",
      "./notMNIST_large/C.pickle already present - skipping pickling.\n",
      "./notMNIST_large/D.pickle already present - skipping pickling.\n",
      "./notMNIST_large/E.pickle already present - skipping pickling.\n",
      "./notMNIST_large/F.pickle already present - skipping pickling.\n",
      "./notMNIST_large/G.pickle already present - skipping pickling.\n",
      "./notMNIST_large/H.pickle already present - skipping pickling.\n",
      "./notMNIST_large/I.pickle already present - skipping pickling.\n",
      "./notMNIST_large/J.pickle already present - skipping pickling.\n",
      "./notMNIST_small/A.pickle already present - skipping pickling.\n",
      "./notMNIST_small/B.pickle already present - skipping pickling.\n",
      "./notMNIST_small/C.pickle already present - skipping pickling.\n",
      "./notMNIST_small/D.pickle already present - skipping pickling.\n",
      "./notMNIST_small/E.pickle already present - skipping pickling.\n",
      "./notMNIST_small/F.pickle already present - skipping pickling.\n",
      "./notMNIST_small/G.pickle already present - skipping pickling.\n",
      "./notMNIST_small/H.pickle already present - skipping pickling.\n",
      "./notMNIST_small/I.pickle already present - skipping pickling.\n",
      "./notMNIST_small/J.pickle already present - skipping pickling.\n"
     ]
    }
   ],
   "source": [
    "image_size=28 #pixel width and height\n",
    "pixel_depth=255.0 #Nurmber of levels per pixel\n",
    "\n",
    "def load_letter(folder, min_num_images):\n",
    "    \"\"\"Load the data for a single letter label\"\"\"\n",
    "    image_files=os.listdir(folder)\n",
    "    dataset=np.ndarray(shape=(len(image_files),image_size, image_size),dtype=np.float32)\n",
    "    #print(folder)\n",
    "    num_images=0\n",
    "    for image in image_files:\n",
    "        image_file=os.path.join(folder,image)\n",
    "        try:\n",
    "            image_data=(ndimage.imread(image_file).astype(float) - pixel_depth /2)/pixel_depth\n",
    "            #print(image_data.shape)\n",
    "            if image_data.shape !=(image_size,image_size):\n",
    "                raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "            dataset[num_images,:,:]=image_data\n",
    "            num_images=num_images + 1\n",
    "        except IOError as e:\n",
    "            print('couldnot read :', image_file , ':', e , '-it\\'s ok , skipping.')\n",
    "    dataset=dataset[0:num_images, :, :]\n",
    "    if num_images < min_num_images:\n",
    "        raise Exception('many fewer images then expected: %d < %d' % (num_images, min_num_images))\n",
    "    print('Full dataset tensor:', dataset.shape)\n",
    "    print('mean:', np.mean(dataset))\n",
    "    print('standard deviation:', np.std(dataset))\n",
    "    return dataset\n",
    "\n",
    "def maybe_pickle(data_folders, min_num_images_per_class, force=False):\n",
    "    dataset_names=[]\n",
    "    for folder in data_folders:\n",
    "        set_filename=folder+ '.pickle'\n",
    "        dataset_names.append(set_filename)\n",
    "        if os.path.exists(set_filename)and not force:\n",
    "            print('%s already present - skipping pickling.' % set_filename)\n",
    "        else:\n",
    "            print('pickling %s.' % set_filename)\n",
    "            dataset=load_letter(folder,min_num_images_per_class)\n",
    "            try:\n",
    "                with open(set_filename, 'wb')as f:\n",
    "                    pickle.dump(dataset,f, pickle.HIGHEST_PROTOCOL)\n",
    "            except Exception as e:\n",
    "                print('Unable to save data to', set_filename, ':',e)\n",
    "    return dataset_names\n",
    "train_datasets=maybe_pickle(train_folders, 45000)#Not MNIST Large\n",
    "test_datasets=maybe_pickle(test_folders, 1800)#Not MNIST SMALL\n",
    "#print (train_dataset.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access images from pickle and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52909, 28, 28)\n",
      "41480656\n",
      "[[-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.48823529 -0.5\n",
      "  -0.20588236  0.31568629 -0.44901961 -0.49607843 -0.49607843 -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.49215686 -0.5\n",
      "   0.21372549  0.5        -0.14313726 -0.5        -0.48823529 -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.48823529 -0.5        -0.30784315\n",
      "   0.48039216  0.49607843  0.25294119 -0.5        -0.49607843 -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.48823529 -0.5         0.09607843\n",
      "   0.5         0.48823529  0.48431373 -0.31568629 -0.5        -0.49215686\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.49215686 -0.5        -0.4137255   0.43333334\n",
      "   0.49215686  0.48039216  0.5         0.06470589 -0.5        -0.48823529\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.48431373 -0.5        -0.06078431  0.5         0.5\n",
      "   0.49607843  0.5         0.40196079 -0.43725491 -0.49607843 -0.49607843\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.49607843 -0.49607843 -0.47647059  0.32745099  0.5\n",
      "   0.18627451  0.45686275  0.5         0.5        -0.12352941 -0.5\n",
      "  -0.48431373 -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.48431373 -0.5        -0.21372549  0.5         0.43725491\n",
      "  -0.39803922  0.28039217  0.5         0.5         0.26862746 -0.49607843\n",
      "  -0.49607843 -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.49215686 -0.5         0.18235295  0.49607843  0.15490197\n",
      "  -0.5        -0.0372549   0.5         0.48823529  0.49215686 -0.29607844\n",
      "  -0.5        -0.48823529 -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.49215686 -0.5        -0.34705883  0.46470588  0.5        -0.2254902\n",
      "  -0.49607843 -0.37058824  0.45686275  0.49215686  0.5         0.09215686\n",
      "  -0.5        -0.48823529 -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.48823529 -0.5         0.03333334  0.5         0.32352942 -0.48039216\n",
      "  -0.49215686 -0.5         0.18235295  0.5         0.49607843  0.41764706\n",
      "  -0.4254902  -0.5        -0.49215686 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.49607843 -0.49607843 -0.43725491  0.38627452  0.5        -0.03333334\n",
      "  -0.5        -0.47254902 -0.5        -0.18627451  0.5         0.48039216\n",
      "   0.5        -0.09607843 -0.5        -0.48431373 -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.48431373 -0.5        -0.11568628  0.5         0.44901961 -0.37450981\n",
      "  -0.5        -0.48823529 -0.5        -0.46078432  0.37843138  0.5         0.5\n",
      "   0.28823531 -0.49215686 -0.49607843 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.49607843 -0.49215686  0.27254903  0.5         0.18627451 -0.48823529\n",
      "  -0.47647059 -0.48431373 -0.46862745 -0.48823529  0.05686275  0.5\n",
      "   0.48431373  0.5        -0.26862746 -0.5        -0.48823529 -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.48823529\n",
      "  -0.5        -0.2647059   0.48823529  0.48431373 -0.2764706  -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.38627452  0.46078432  0.48431373\n",
      "   0.5         0.11960784 -0.5        -0.48823529 -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.48823529\n",
      "  -0.5         0.13921569  0.5         0.41764706 -0.0882353  -0.11960784\n",
      "  -0.11568628 -0.11960784 -0.11960784 -0.11568628 -0.11568628  0.37843138\n",
      "   0.5         0.5         0.43725491 -0.40588236 -0.5        -0.49607843\n",
      "  -0.5        -0.5        -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.49215686 -0.5\n",
      "  -0.37843138  0.45294118  0.5         0.5         0.5         0.5         0.5\n",
      "   0.5         0.5         0.5         0.5         0.5         0.5\n",
      "   0.48823529  0.5        -0.06470589 -0.5        -0.48431373 -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.48431373 -0.5\n",
      "  -0.01372549  0.5         0.44509804  0.11568628  0.0882353   0.08431373\n",
      "   0.08431373  0.08431373  0.08431373  0.0882353   0.08431373  0.11176471\n",
      "   0.45686275  0.49215686  0.5         0.31176472 -0.48823529 -0.49607843\n",
      "  -0.49607843 -0.5        -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.49607843 -0.5        -0.46470588\n",
      "   0.35490197  0.5         0.13137256 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5         0.1509804\n",
      "   0.5         0.48039216  0.5        -0.24509804 -0.5        -0.48823529\n",
      "  -0.5        -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.48823529 -0.5        -0.16666667\n",
      "   0.5         0.49215686 -0.26078433 -0.48431373 -0.47254902 -0.48431373\n",
      "  -0.48431373 -0.48431373 -0.48431373 -0.48431373 -0.47254902 -0.48431373\n",
      "  -0.22941177  0.5         0.48039216  0.5         0.14705883 -0.5\n",
      "  -0.48823529 -0.5        -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.49215686 -0.5         0.22941177\n",
      "   0.49607843  0.28431374 -0.49215686 -0.49607843 -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.49607843 -0.47647059\n",
      "   0.33529413  0.5         0.49215686  0.44509804 -0.39019608 -0.5\n",
      "  -0.49215686 -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.48823529 -0.49607843 -0.30392158  0.48039216\n",
      "   0.5        -0.09607843 -0.5        -0.48431373 -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.48431373 -0.5\n",
      "  -0.02941176  0.5         0.47254902  0.5        -0.04117647 -0.5\n",
      "  -0.48431373 -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.48823529 -0.5         0.08431373  0.5\n",
      "   0.40196079 -0.4254902  -0.49607843 -0.49607843 -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.49215686 -0.5\n",
      "  -0.37843138  0.46078432  0.49607843  0.5         0.33529413 -0.48039216\n",
      "  -0.49607843 -0.49607843 -0.5       ]\n",
      " [-0.5        -0.48823529 -0.48823529 -0.4137255   0.42156863  0.5\n",
      "   0.07254902 -0.5        -0.48823529 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.49215686\n",
      "  -0.5         0.18235295  0.5         0.48039216  0.5        -0.22156863\n",
      "  -0.49607843 -0.48039216 -0.5       ]\n",
      " [-0.49215686 -0.5        -0.5         0.03333334  0.5         0.47647059\n",
      "  -0.31568629 -0.49215686 -0.48431373 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.48431373\n",
      "  -0.48823529 -0.19019608  0.5         0.47647059  0.49607843  0.24901961\n",
      "  -0.5        -0.5        -0.49215686]\n",
      " [-0.5        -0.46862745 -0.11568628  0.47254902  0.48039216  0.45686275\n",
      "  -0.30000001 -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.24901961  0.48823529  0.48431373  0.48431373  0.5         0.06470589\n",
      "  -0.4137255  -0.5       ]\n",
      " [ 0.17843138  0.39411765  0.5         0.5         0.5         0.5\n",
      "   0.47647059  0.23333333 -0.30000001 -0.5        -0.49215686 -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.49607843 -0.49607843 -0.40980393\n",
      "   0.17450981  0.46078432  0.5         0.5         0.5         0.5         0.5\n",
      "   0.44901961  0.19411765]\n",
      " [ 0.48039216  0.44509804  0.20196079  0.07254902  0.0372549   0.14705883\n",
      "   0.34705883  0.5        -0.13921569 -0.5        -0.48431373 -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.49215686 -0.5        -0.3392157\n",
      "   0.5         0.39803922  0.17843138  0.02156863 -0.04901961  0.03333334\n",
      "   0.19019608  0.4254902   0.5       ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f991b285a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.image as mpimg\n",
    "read_pickle = pickle.load( open( \"notMNIST_large/A.pickle\", \"rb\" ) )\n",
    "print (read_pickle.shape)\n",
    "print (read_pickle.size)\n",
    "#print (read_pickle)\n",
    "print (read_pickle[0])\n",
    "imgplot = plt.imshow(read_pickle[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shuffle images from each class to have random validation and training set then merge each classes into a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:  (200000, 28, 28) (200000,)\n",
      "validation : (10000, 28, 28) (10000,)\n",
      "test : (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "#print (train_dataset.shape)\n",
    "def make_arrays(nb_rows, img_size):\n",
    "    if nb_rows:\n",
    "        dataset=np.ndarray((nb_rows, img_size , img_size), dtype=np.float32)\n",
    "        labels=np.ndarray(nb_rows,dtype=np.float32)\n",
    "    else:\n",
    "        dataset,labels=None, None\n",
    "    return dataset,labels\n",
    "def merge_datasets(pickle_files,train_size, valid_size=0):\n",
    "    num_classes= len(pickle_files)\n",
    "    valid_dataset, valid_labels= make_arrays(valid_size, image_size)#for validation \n",
    "    train_dataset, train_labels= make_arrays(train_size, image_size)\n",
    "    vsize_per_class= valid_size // num_classes\n",
    "    tsize_per_class= train_size // num_classes\n",
    "    \n",
    "    start_v,start_t =0 , 0\n",
    "    end_v, end_t =vsize_per_class , tsize_per_class\n",
    "    end_l=vsize_per_class+tsize_per_class\n",
    "    for label, pickle_file in enumerate(pickle_files):#label=value or index of pickle files,example A,B,C,D\n",
    "        try:\n",
    "            with open(pickle_file, 'rb') as f:\n",
    "                letter_set=pickle.load(f)\n",
    "                #shuffle the letters to have random validation and training set\n",
    "                np.random.shuffle(letter_set)\n",
    "                if valid_dataset is not None:\n",
    "                    valid_letter=letter_set[:vsize_per_class, : , :]\n",
    "                    valid_dataset[start_v:end_v, : , :] = valid_letter\n",
    "                    valid_labels[start_v:end_v]= label\n",
    "                    start_v +=vsize_per_class\n",
    "                    end_v += vsize_per_class\n",
    "                    \n",
    "                train_letter= letter_set[vsize_per_class:end_l, :, :]\n",
    "                train_dataset[start_t:end_t, : ,:]=train_letter\n",
    "                train_labels[start_t:end_t]=label\n",
    "                start_t +=tsize_per_class\n",
    "                end_t += tsize_per_class\n",
    "        except Exception as e:\n",
    "            print('unable to process data from', pickle_file, '.', e)\n",
    "            raise\n",
    "    return valid_dataset,valid_labels,train_dataset, train_labels\n",
    "\n",
    "train_size= 200000\n",
    "valid_size=10000\n",
    "test_size=10000\n",
    "\n",
    "valid_dataset, valid_labels,train_dataset,train_labels = merge_datasets(train_datasets, train_size , valid_size)\n",
    "_, _, test_dataset, test_labels=merge_datasets(test_datasets,test_size)\n",
    "\n",
    "print('training: ' ,train_dataset.shape , train_labels.shape)\n",
    "print('validation :' , valid_dataset.shape , valid_labels.shape)\n",
    "print('test :', test_dataset.shape , test_labels.shape)\n",
    "                    \n",
    "                \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# randomly shuffling whole dataset using permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "[ 82544 184777 127251 ...,  54720  86392  96194]\n",
      "10000\n",
      "[3480 6566 4543 ..., 6790 9016  268]\n",
      "10000\n",
      "[1927 9112 3615 ..., 8250 9495 8617]\n"
     ]
    }
   ],
   "source": [
    "def randomize(dataset, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    print (labels.shape[0])\n",
    "    print (permutation)\n",
    "    shuffled_dataset= dataset[permutation, : , :]\n",
    "    shuffled_labels= labels[permutation]\n",
    "    return shuffled_dataset, shuffled_labels\n",
    "train_dataset , train_labels = randomize(train_dataset, train_labels)\n",
    "test_dataset , test_labels = randomize(test_dataset, test_labels)\n",
    "valid_dataset , valid_labels = randomize(valid_dataset, valid_labels)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f991002e9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgplot = plt.imshow(train_dataset [0])\n",
    "print (train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving data into pickle to reuse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_file = os.path.join(data_root, 'notMNIST.pickle')\n",
    "try:\n",
    "    f = open(pickle_file , 'wb')\n",
    "    save= {\n",
    "        'train_dataset' : train_dataset,\n",
    "        'train_labels'  : train_labels,\n",
    "        'valid_dataset' : valid_dataset,\n",
    "        'valid_labels'  : valid_labels,\n",
    "        'test_dataset'  : test_dataset,\n",
    "        'test_labels'    : test_labels,\n",
    "    }\n",
    "    pickle.dump(save, f , pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "except Exception as e:\n",
    "    print('unable to save data to', pickle_file , ':', e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compressed pickcle size: 690800406\n"
     ]
    }
   ],
   "source": [
    "statinfo= os.stat(pickle_file)\n",
    "print('compressed pickcle size:', statinfo.st_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# removing duplicate data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.5        -0.5        -0.5        ..., -0.5        -0.5        -0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ..., -0.4254902  -0.4254902\n",
      "   -0.42941177]\n",
      "  [-0.5        -0.5        -0.5        ...,  0.46470588  0.46862745\n",
      "    0.26078433]\n",
      "  ..., \n",
      "  [-0.5        -0.0254902   0.5        ..., -0.5        -0.5        -0.5       ]\n",
      "  [-0.1         0.5         0.48431373 ..., -0.5        -0.5        -0.5       ]\n",
      "  [ 0.21764706  0.49215686  0.48823529 ..., -0.5        -0.5        -0.5       ]]\n",
      "\n",
      " [[-0.5        -0.5        -0.5        ..., -0.5        -0.5        -0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ..., -0.5        -0.5        -0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ..., -0.5        -0.5        -0.5       ]\n",
      "  ..., \n",
      "  [-0.49607843 -0.5        -0.43333334 ..., -0.5        -0.5        -0.5       ]\n",
      "  [-0.5        -0.49607843 -0.5        ..., -0.5        -0.5        -0.5       ]\n",
      "  [-0.5        -0.5        -0.49607843 ..., -0.5        -0.5        -0.5       ]]\n",
      "\n",
      " [[-0.5        -0.5        -0.5        ..., -0.02156863  0.1         0.00980392]\n",
      "  [-0.5        -0.5        -0.49607843 ..., -0.5        -0.5         0.20588236]\n",
      "  [-0.49607843 -0.5        -0.5        ..., -0.48039216 -0.48039216\n",
      "    0.08431373]\n",
      "  ..., \n",
      "  [-0.5        -0.5        -0.5        ..., -0.5        -0.5        -0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ..., -0.5        -0.5        -0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ..., -0.5        -0.5        -0.5       ]]\n",
      "\n",
      " ..., \n",
      " [[-0.5        -0.5        -0.5        ..., -0.08431373  0.49607843\n",
      "   -0.40588236]\n",
      "  [-0.5        -0.5        -0.5        ...,  0.41764706  0.46862745\n",
      "   -0.40196079]\n",
      "  [-0.5        -0.5        -0.5        ...,  0.5         0.44509804\n",
      "   -0.39803922]\n",
      "  ..., \n",
      "  [-0.5        -0.5        -0.5        ..., -0.5        -0.48823529\n",
      "   -0.49607843]\n",
      "  [-0.5        -0.5        -0.5        ..., -0.48823529 -0.5        -0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ..., -0.5        -0.5        -0.5       ]]\n",
      "\n",
      " [[-0.24509804  0.35490197  0.41764706 ...,  0.5         0.12745099 -0.5       ]\n",
      "  [-0.5        -0.47647059 -0.42156863 ...,  0.5         0.06862745 -0.5       ]\n",
      "  [-0.5        -0.5        -0.48431373 ...,  0.5        -0.06078431 -0.5       ]\n",
      "  ..., \n",
      "  [-0.5        -0.5        -0.48823529 ...,  0.5         0.2647059  -0.5       ]\n",
      "  [-0.47254902 -0.40980393 -0.31960785 ...,  0.5        -0.05294118 -0.5       ]\n",
      "  [ 0.24509804  0.41764706  0.44509804 ...,  0.44117647 -0.32745099 -0.5       ]]\n",
      "\n",
      " [[-0.5        -0.5        -0.5        ..., -0.01764706  0.17450981\n",
      "   -0.0882353 ]\n",
      "  [-0.5        -0.5        -0.5        ...,  0.5         0.48823529\n",
      "   -0.21764706]\n",
      "  [-0.5        -0.5        -0.49607843 ...,  0.22941177 -0.2372549  -0.5       ]\n",
      "  ..., \n",
      "  [-0.2647059   0.47254902  0.5        ..., -0.5        -0.5        -0.5       ]\n",
      "  [-0.02156863  0.5         0.48823529 ..., -0.5        -0.5        -0.5       ]\n",
      "  [-0.14313726  0.46470588  0.48823529 ..., -0.5        -0.5        -0.5       ]]]\n",
      "Time: 2.76s\n",
      "valid -> train overlap: 1053 samples\n",
      "test  -> train overlap: 1269 samples\n",
      "test  -> valid overlap: 195 samples\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import hashlib\n",
    "\n",
    "f=open(pickle_file, 'rb')\n",
    "read_pickle = pickle.load( f )\n",
    "train_dataset=read_pickle['train_dataset']\n",
    "print(train_dataset)\n",
    "train_labels=read_pickle['train_labels']\n",
    "valid_dataset=read_pickle['valid_dataset']\n",
    "valid_labels=read_pickle['valid_labels']\n",
    "test_dataset=read_pickle['test_dataset']\n",
    "test_labels=read_pickle['test_labels']\n",
    "\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "train_hashes = [hashlib.sha1(x).digest() for x in train_dataset]\n",
    "valid_hashes = [hashlib.sha1(x).digest() for x in valid_dataset]\n",
    "test_hashes  = [hashlib.sha1(x).digest() for x in test_dataset]\n",
    "\n",
    "valid_in_train = np.in1d(valid_hashes, train_hashes)\n",
    "test_in_train  = np.in1d(test_hashes,  train_hashes)\n",
    "test_in_valid  = np.in1d(test_hashes,  valid_hashes)\n",
    "\n",
    "valid_keep = ~valid_in_train\n",
    "test_keep  = ~(test_in_train | test_in_valid)\n",
    "\n",
    "valid_dataset_clean = valid_dataset[valid_keep]\n",
    "valid_labels_clean  = valid_labels [valid_keep]\n",
    "\n",
    "test_dataset_clean = test_dataset[test_keep]\n",
    "test_labels_clean  = test_labels [test_keep]\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"Time: %0.2fs\" % (t2 - t1))\n",
    "print(\"valid -> train overlap: %d samples\" % valid_in_train.sum())\n",
    "print(\"test  -> train overlap: %d samples\" % test_in_train.sum())\n",
    "print(\"test  -> valid overlap: %d samples\" % test_in_valid.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8693, 28, 28)\n",
      "6815312\n",
      "(8947, 28, 28)\n",
      "7014448\n",
      "(200000, 28, 28)\n",
      "156800000\n"
     ]
    }
   ],
   "source": [
    "print (test_dataset_clean.shape)\n",
    "print (test_dataset_clean.size)\n",
    "print (valid_dataset_clean.shape)\n",
    "print (valid_dataset_clean.size)\n",
    "print (train_dataset.shape)\n",
    "print (train_dataset.size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model with logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "(samples,width,height)=train_dataset.shape\n",
    "num_samples=20000\n",
    "train_x=np.reshape(train_dataset,(samples,width*height))[0:num_samples]\n",
    "train_y=train_labels [0:num_samples]\n",
    "(samples,width,height)=test_dataset_clean.shape\n",
    "\n",
    "logistic =LogisticRegression(C=1e-1, solver=\"newton-cg\")\n",
    "fit_model=logistic.fit(train_x,train_y,sample_weight=None) #fit(X, y[, sample_weight])\n",
    "\n",
    "#fit_score=logistic.score(test_x, test_y, sample_weight=None)\n",
    "\n",
    "#print(fit_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.725\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "num_samples=10\n",
    "test_x=np.reshape(test_dataset_clean,(samples,width*height))[0:num_samples]\n",
    "test_y=test_labels [0:num_samples]\n",
    "pred=logistic.predict(test_x)\n",
    "acc_score=accuracy_score(test_y,pred)\n",
    "pre_score=precision_score(test_y,pred, average='weighted')\n",
    "re_score=recall_score(test_y,pred,average='weighted')\n",
    "print(acc_score)\n",
    "print(pre_score)\n",
    "print(re_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
