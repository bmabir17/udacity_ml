{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Environment\n",
    "\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/1_notmnist.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Dataset into folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./notMNIST_large already present - Skipping extraction of ./notMNIST_large.tar.gz\n",
      "['./notMNIST_large/A', './notMNIST_large/B', './notMNIST_large/C', './notMNIST_large/D', './notMNIST_large/E', './notMNIST_large/F', './notMNIST_large/G', './notMNIST_large/H', './notMNIST_large/I', './notMNIST_large/J']\n",
      "./notMNIST_small already present - Skipping extraction of ./notMNIST_small.tar.gz\n",
      "['./notMNIST_small/A', './notMNIST_small/B', './notMNIST_small/C', './notMNIST_small/D', './notMNIST_small/E', './notMNIST_small/F', './notMNIST_small/G', './notMNIST_small/H', './notMNIST_small/I', './notMNIST_small/J']\n"
     ]
    }
   ],
   "source": [
    "num_classes=10\n",
    "np.random.seed(133)\n",
    "data_root='.'\n",
    "train_filename= os.path.join(data_root, 'notMNIST_large.tar.gz') #join os root and extention(dataroot)\n",
    "test_filename= os.path.join(data_root, 'notMNIST_small.tar.gz')\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "    root=os.path.splitext(os.path.splitext(filename)[0])[0] #splits the os root and extension \n",
    "    if os.path.isdir(root)and not force:\n",
    "        print('%s already present - Skipping extraction of %s' %(root, filename))\n",
    "    else:\n",
    "        print('extracting data %s.this may take a while .please wait.' %root)\n",
    "        tar=tarfile.open(filename)\n",
    "        sys.stdout.flush()\n",
    "        tar.extractall(data_root)\n",
    "        tar.close()\n",
    "    data_folders = [\n",
    "        os.path.join(root, d)for d in sorted(os.listdir(root)) #listing all the classes directory\n",
    "        if os.path.isdir(os.path.join(root, d))]\n",
    "    if len(data_folders) !=num_classes: #checks lengths\n",
    "        raise Exception(\n",
    "            'Expected %d folders , one per class. found %d instead.' % (\n",
    "                num_classes,len(data_folders)))\n",
    "    print(data_folders)\n",
    "    return data_folders\n",
    "    \n",
    "    \n",
    "train_folders= maybe_extract(train_filename)\n",
    "test_folders=maybe_extract(test_filename)\n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert image into npArray and save into pickle file with seperate class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./notMNIST_large/A.pickle already present - skipping pickling.\n",
      "./notMNIST_large/B.pickle already present - skipping pickling.\n",
      "./notMNIST_large/C.pickle already present - skipping pickling.\n",
      "./notMNIST_large/D.pickle already present - skipping pickling.\n",
      "./notMNIST_large/E.pickle already present - skipping pickling.\n",
      "./notMNIST_large/F.pickle already present - skipping pickling.\n",
      "./notMNIST_large/G.pickle already present - skipping pickling.\n",
      "./notMNIST_large/H.pickle already present - skipping pickling.\n",
      "./notMNIST_large/I.pickle already present - skipping pickling.\n",
      "./notMNIST_large/J.pickle already present - skipping pickling.\n",
      "./notMNIST_small/A.pickle already present - skipping pickling.\n",
      "./notMNIST_small/B.pickle already present - skipping pickling.\n",
      "./notMNIST_small/C.pickle already present - skipping pickling.\n",
      "./notMNIST_small/D.pickle already present - skipping pickling.\n",
      "./notMNIST_small/E.pickle already present - skipping pickling.\n",
      "./notMNIST_small/F.pickle already present - skipping pickling.\n",
      "./notMNIST_small/G.pickle already present - skipping pickling.\n",
      "./notMNIST_small/H.pickle already present - skipping pickling.\n",
      "./notMNIST_small/I.pickle already present - skipping pickling.\n",
      "./notMNIST_small/J.pickle already present - skipping pickling.\n"
     ]
    }
   ],
   "source": [
    "image_size=28 #pixel width and height\n",
    "pixel_depth=255.0 #Nurmber of levels per pixel\n",
    "\n",
    "def load_letter(folder, min_num_images):\n",
    "    \"\"\"Load the data for a single letter label\"\"\"\n",
    "    image_files=os.listdir(folder)\n",
    "    dataset=np.ndarray(shape=(len(image_files),image_size, image_size),dtype=np.float32)\n",
    "    #print(folder)\n",
    "    num_images=0\n",
    "    for image in image_files:\n",
    "        image_file=os.path.join(folder,image)\n",
    "        try:\n",
    "            image_data=(ndimage.imread(image_file).astype(float) - pixel_depth /2)/pixel_depth\n",
    "            #print(image_data.shape)\n",
    "            if image_data.shape !=(image_size,image_size):\n",
    "                raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "            dataset[num_images,:,:]=image_data\n",
    "            num_images=num_images + 1\n",
    "        except IOError as e:\n",
    "            print('couldnot read :', image_file , ':', e , '-it\\'s ok , skipping.')\n",
    "    dataset=dataset[0:num_images, :, :]\n",
    "    if num_images < min_num_images:\n",
    "        raise Exception('many fewer images then expected: %d < %d' % (num_images, min_num_images))\n",
    "    print('Full dataset tensor:', dataset.shape)\n",
    "    print('mean:', np.mean(dataset))\n",
    "    print('standard deviation:', np.std(dataset))\n",
    "    return dataset\n",
    "\n",
    "def maybe_pickle(data_folders, min_num_images_per_class, force=False):\n",
    "    dataset_names=[]\n",
    "    for folder in data_folders:\n",
    "        set_filename=folder+ '.pickle'\n",
    "        dataset_names.append(set_filename)\n",
    "        if os.path.exists(set_filename)and not force:\n",
    "            print('%s already present - skipping pickling.' % set_filename)\n",
    "        else:\n",
    "            print('pickling %s.' % set_filename)\n",
    "            dataset=load_letter(folder,min_num_images_per_class)\n",
    "            try:\n",
    "                with open(set_filename, 'wb')as f:\n",
    "                    pickle.dump(dataset,f, pickle.HIGHEST_PROTOCOL)\n",
    "            except Exception as e:\n",
    "                print('Unable to save data to', set_filename, ':',e)\n",
    "    return dataset_names\n",
    "train_datasets=maybe_pickle(train_folders, 45000)#Not MNIST Large\n",
    "test_datasets=maybe_pickle(test_folders, 1800)#Not MNIST SMALL\n",
    "#print (train_dataset.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access images from pickle and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52909, 28, 28)\n",
      "41480656\n",
      "[[-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.49607843 -0.5        -0.47647059  0.04117647 -0.05294118 -0.5\n",
      "  -0.48823529 -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.49215686 -0.5        -0.43333334 -0.07647059 -0.34705883  0.02156863\n",
      "  -0.35490197 -0.5        -0.49607843 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.49607843\n",
      "  -0.49607843 -0.5         0.0882353  -0.05686275 -0.43725491 -0.17843138\n",
      "   0.05686275 -0.5        -0.49215686 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.49607843 -0.5\n",
      "  -0.43333334 -0.00196078  0.06470589  0.09607843  0.14313726  0.08039216\n",
      "   0.05686275 -0.47254902 -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.49215686 -0.5\n",
      "   0.02156863 -0.19803922 -0.43725491 -0.27254903 -0.17450981 -0.06862745\n",
      "  -0.01764706 -0.11176471 -0.5        -0.49607843 -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.48823529 -0.5        -0.12352941\n",
      "  -0.07254902 -0.5        -0.49215686 -0.5        -0.5        -0.49215686\n",
      "  -0.5        -0.05294118 -0.27254903 -0.5        -0.49215686 -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.49215686 -0.5        -0.29215688  0.0372549\n",
      "  -0.5        -0.49215686 -0.49607843 -0.49215686 -0.48823529 -0.48431373\n",
      "  -0.5        -0.40196079 -0.01764706 -0.5        -0.49607843 -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.49607843 -0.5        -0.42941177  0.06862745 -0.40196079\n",
      "  -0.5        -0.49215686 -0.49215686 -0.49607843 -0.5        -0.5\n",
      "  -0.48823529 -0.5        -0.11568628 -0.25294119 -0.5        -0.49215686\n",
      "  -0.5        -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.49215686 -0.5         0.00196078 -0.26078433 -0.5\n",
      "  -0.48039216 -0.5        -0.5        -0.49607843 -0.49607843 -0.5\n",
      "  -0.49607843 -0.5        -0.42156863 -0.06078431 -0.48823529 -0.49607843\n",
      "  -0.49215686 -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.48823529 -0.5        -0.13137256 -0.11568628 -0.5        -0.48039216\n",
      "  -0.5        -0.4137255  -0.03333334 -0.12745099 -0.5        -0.49215686\n",
      "  -0.5        -0.49607843 -0.49607843 -0.07647059 -0.28823531 -0.47254902\n",
      "  -0.5        -0.49607843 -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.49215686 -0.5        -0.28431374  0.00196078 -0.5        -0.5\n",
      "  -0.44901961 -0.13529412 -0.03333334 -0.32745099  0.02156863 -0.3392157\n",
      "  -0.5        -0.48431373 -0.5        -0.24117647 -0.06078431  0.05294118\n",
      "  -0.05294118 -0.41764706 -0.5        -0.49607843]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.49607843\n",
      "  -0.5        -0.42941177  0.0372549  -0.41764706 -0.5        -0.44509804\n",
      "   0.04509804 -0.2764706  -0.49215686 -0.5        -0.28823531 -0.06078431\n",
      "  -0.5        -0.5        -0.44901961 -0.06470589 -0.0372549  -0.36666667\n",
      "  -0.39411765  0.0254902  -0.46470588 -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.49607843 -0.48823529 -0.49215686\n",
      "  -0.5        -0.01372549 -0.29215688 -0.5        -0.49607843 -0.48823529\n",
      "   0.01372549 -0.46078432 -0.5        -0.5        -0.48431373  0.11176471\n",
      "  -0.35882354 -0.5        -0.19019608 -0.03333334 -0.06862745 -0.5\n",
      "  -0.38235295 -0.05294118 -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.49607843 -0.49607843 -0.49215686 -0.5\n",
      "  -0.14313726 -0.14313726 -0.5        -0.48823529 -0.48823529 -0.5\n",
      "  -0.14705883 -0.12745099 -0.31176472 -0.07254902 -0.01372549 -0.10392157\n",
      "  -0.43333334 -0.5        -0.35490197 -0.00980392  0.00588235 -0.44901961\n",
      "  -0.04901961 -0.27254903 -0.5        -0.49215686]\n",
      " [-0.5        -0.49607843 -0.5        -0.39019608 -0.03333334 -0.17058824\n",
      "  -0.08039216 -0.49215686 -0.49607843 -0.5        -0.49607843 -0.5\n",
      "  -0.42156863 -0.06078431 -0.19411765 -0.34313726 -0.48431373 -0.5        -0.5\n",
      "  -0.48823529 -0.5        -0.12745099  0.01372549 -0.13529412 -0.3509804\n",
      "  -0.06470589 -0.48823529 -0.5       ]\n",
      " [-0.48823529 -0.5        -0.25686276 -0.0372549  -0.24117647  0.04117647\n",
      "  -0.12745099 -0.5        -0.49607843 -0.5        -0.5        -0.5\n",
      "  -0.49607843 -0.5        -0.5        -0.5        -0.5        -0.48823529\n",
      "  -0.49607843 -0.49607843 -0.5        -0.39411765 -0.01372549  0.03333334\n",
      "  -0.4137255  -0.25294119 -0.04117647 -0.5       ]\n",
      " [-0.49215686 -0.5        -0.2254902  -0.14313726 -0.5        -0.0372549\n",
      "  -0.02941176 -0.37058824 -0.5        -0.49607843 -0.5        -0.5        -0.5\n",
      "  -0.49215686 -0.49215686 -0.49607843 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.49215686 -0.5        -0.16666667  0.01372549 -0.07254902 -0.09215686\n",
      "  -0.26078433 -0.5       ]\n",
      " [-0.5        -0.5        -0.43725491 -0.0254902  -0.5        -0.17450981\n",
      "   0.01764706 -0.2372549  -0.5        -0.49215686 -0.5        -0.5\n",
      "  -0.49215686 -0.48823529 -0.48823529 -0.48823529 -0.49215686 -0.49607843\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.43725491 -0.0372549\n",
      "   0.05294118 -0.11568628 -0.5        -0.49215686]\n",
      " [-0.5        -0.2647059  -0.00588235 -0.04509804 -0.5        -0.33529413\n",
      "   0.00588235 -0.10784314 -0.5        -0.49215686 -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.48823529 -0.5        -0.18235295 -0.1627451  -0.5\n",
      "  -0.48431373 -0.5       ]\n",
      " [-0.5        -0.11568628 -0.10392157 -0.5        -0.48823529 -0.48431373\n",
      "  -0.07254902 -0.01372549 -0.42156863 -0.5        -0.49607843 -0.5\n",
      "  -0.13921569 -0.07254902 -0.13529412 -0.17843138 -0.2254902  -0.4254902\n",
      "  -0.5        -0.49607843 -0.5        -0.5        -0.5        -0.48039216\n",
      "   0.01764706 -0.42156863 -0.5        -0.49607843]\n",
      " [-0.5        -0.43725491 -0.01372549 -0.48823529 -0.49607843 -0.49607843\n",
      "  -0.10784314  0.00588235 -0.23333333 -0.5        -0.5        -0.36274511\n",
      "   0.00196078 -0.45294118 -0.33529413 -0.28039217 -0.1627451   0.04901961\n",
      "  -0.49607843 -0.5        -0.5        -0.5        -0.49215686 -0.5\n",
      "  -0.2254902  -0.09607843 -0.5        -0.48823529]\n",
      " [-0.5        -0.24509804 -0.05294118 -0.48039216 -0.47254902 -0.13921569\n",
      "  -0.06470589 -0.02156863 -0.40588236 -0.5        -0.5        -0.13137256\n",
      "  -0.23333333 -0.5        -0.49215686 -0.48823529 -0.5        -0.07647059\n",
      "  -0.23333333 -0.5        -0.49215686 -0.5        -0.5        -0.49607843\n",
      "  -0.5        -0.00588235 -0.37843138 -0.5       ]\n",
      " [-0.04509804 -0.19019608 -0.5        -0.4254902  -0.1        -0.05294118\n",
      "  -0.05294118 -0.4254902  -0.5        -0.5        -0.48039216 -0.00588235\n",
      "  -0.44901961 -0.5        -0.49215686 -0.48823529 -0.5        -0.37058824\n",
      "   0.00196078 -0.5        -0.49607843 -0.5        -0.5        -0.49215686\n",
      "  -0.5        -0.29215688 -0.06862745 -0.5       ]\n",
      " [ 0.02941176 -0.35882354 -0.37843138 -0.06470589 -0.04901961 -0.09215686\n",
      "  -0.47254902 -0.5        -0.48823529 -0.5        -0.28823531 -0.10392157\n",
      "  -0.5        -0.48823529 -0.5        -0.5        -0.49215686 -0.5\n",
      "  -0.04117647 -0.30784315 -0.5        -0.49215686 -0.5        -0.49607843\n",
      "  -0.48431373 -0.5        -0.08431373 -0.33529413]\n",
      " [-0.31176472  0.10784314 -0.11960784 -0.09607843 -0.15882353 -0.49607843\n",
      "  -0.48823529 -0.48823529 -0.49215686 -0.5        -0.10392157 -0.33137256\n",
      "  -0.5        -0.49215686 -0.5        -0.5        -0.49607843 -0.5\n",
      "  -0.31176472 -0.06862745 -0.5        -0.47647059 -0.49215686 -0.5        -0.5\n",
      "  -0.46862745 -0.05294118 -0.05294118]\n",
      " [-0.49215686 -0.30392158 -0.02156863  0.06470589 -0.46862745 -0.5\n",
      "  -0.49607843 -0.5        -0.5        -0.45294118 -0.05686275 -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.49607843 -0.5\n",
      "  -0.02156863 -0.39019608 -0.5        -0.49215686 -0.3392157  -0.1\n",
      "  -0.03333334 -0.22941177 -0.46862745]\n",
      " [-0.49607843 -0.5        -0.37843138 -0.22156863 -0.07647059 -0.07647059\n",
      "  -0.17058824 -0.31176472 -0.5        -0.26078433 -0.19019608 -0.5\n",
      "  -0.49215686 -0.5        -0.5        -0.5        -0.5        -0.49215686\n",
      "  -0.5        -0.25686276 -0.06470589 -0.28823531 -0.04117647 -0.10392157\n",
      "  -0.33137256 -0.49607843 -0.5        -0.5       ]\n",
      " [-0.5        -0.49215686 -0.49607843 -0.5        -0.5        -0.43725491\n",
      "  -0.2764706  -0.12745099 -0.06078431  0.0372549  -0.4137255  -0.5\n",
      "  -0.49607843 -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.48431373 -0.01764706 -0.13137256 -0.4254902  -0.5        -0.5\n",
      "  -0.49607843 -0.48823529 -0.49607843]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7c67f26950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.image as mpimg\n",
    "read_pickle = pickle.load( open( \"notMNIST_large/A.pickle\", \"rb\" ) )\n",
    "print (read_pickle.shape)\n",
    "print (read_pickle.size)\n",
    "#print (read_pickle)\n",
    "print (read_pickle[0])\n",
    "imgplot = plt.imshow(read_pickle[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shuffle images from each class to have random validation and training set then merge each classes into a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:  (200000, 28, 28) (200000,)\n",
      "validation : (10000, 28, 28) (10000,)\n",
      "test : (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "#print (train_dataset.shape)\n",
    "def make_arrays(nb_rows, img_size):\n",
    "    if nb_rows:\n",
    "        dataset=np.ndarray((nb_rows, img_size , img_size), dtype=np.float32)\n",
    "        labels=np.ndarray(nb_rows,dtype=np.float32)\n",
    "    else:\n",
    "        dataset,labels=None, None\n",
    "    return dataset,labels\n",
    "def merge_datasets(pickle_files,train_size, valid_size=0):\n",
    "    num_classes= len(pickle_files)\n",
    "    valid_dataset, valid_labels= make_arrays(valid_size, image_size)#for validation \n",
    "    train_dataset, train_labels= make_arrays(train_size, image_size)\n",
    "    vsize_per_class= valid_size // num_classes\n",
    "    tsize_per_class= train_size // num_classes\n",
    "    \n",
    "    start_v,start_t =0 , 0\n",
    "    end_v, end_t =vsize_per_class , tsize_per_class\n",
    "    end_l=vsize_per_class+tsize_per_class\n",
    "    for label, pickle_file in enumerate(pickle_files):#label=value or index of pickle files,example A,B,C,D\n",
    "        try:\n",
    "            with open(pickle_file, 'rb') as f:\n",
    "                letter_set=pickle.load(f)\n",
    "                #shuffle the letters to have random validation and training set\n",
    "                np.random.shuffle(letter_set)\n",
    "                if valid_dataset is not None:\n",
    "                    valid_letter=letter_set[:vsize_per_class, : , :]\n",
    "                    valid_dataset[start_v:end_v, : , :] = valid_letter\n",
    "                    valid_labels[start_v:end_v]= label\n",
    "                    start_v +=vsize_per_class\n",
    "                    end_v += vsize_per_class\n",
    "                    \n",
    "                train_letter= letter_set[vsize_per_class:end_l, :, :]\n",
    "                train_dataset[start_t:end_t, : ,:]=train_letter\n",
    "                train_labels[start_t:end_t]=label\n",
    "                start_t +=tsize_per_class\n",
    "                end_t += tsize_per_class\n",
    "        except Exception as e:\n",
    "            print('unable to process data from', pickle_file, '.', e)\n",
    "            raise\n",
    "    return valid_dataset,valid_labels,train_dataset, train_labels\n",
    "\n",
    "train_size= 200000\n",
    "valid_size=10000\n",
    "test_size=10000\n",
    "\n",
    "valid_dataset, valid_labels,train_dataset,train_labels = merge_datasets(train_datasets, train_size , valid_size)\n",
    "_, _, test_dataset, test_labels=merge_datasets(test_datasets,test_size)\n",
    "\n",
    "print('training: ' ,train_dataset.shape , train_labels.shape)\n",
    "print('validation :' , valid_dataset.shape , valid_labels.shape)\n",
    "print('test :', test_dataset.shape , test_labels.shape)\n",
    "                    \n",
    "                \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# randomly shuffling whole dataset using permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "[ 82544 184777 127251 ...,  54720  86392  96194]\n",
      "10000\n",
      "[3480 6566 4543 ..., 6790 9016  268]\n",
      "10000\n",
      "[1927 9112 3615 ..., 8250 9495 8617]\n"
     ]
    }
   ],
   "source": [
    "def randomize(dataset, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    print (labels.shape[0])\n",
    "    print (permutation)\n",
    "    shuffled_dataset= dataset[permutation, : , :]\n",
    "    shuffled_labels= labels[permutation]\n",
    "    return shuffled_dataset, shuffled_labels\n",
    "train_dataset , train_labels = randomize(train_dataset, train_labels)\n",
    "test_dataset , test_labels = randomize(test_dataset, test_labels)\n",
    "valid_dataset , valid_labels = randomize(valid_dataset, valid_labels)\n",
    "#print(train_labels[:,None])\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7c33970150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgplot = plt.imshow(train_dataset [0])\n",
    "print (train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving data into pickle to reuse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_file = os.path.join(data_root, 'notMNIST.pickle')\n",
    "try:\n",
    "    f = open(pickle_file , 'wb')\n",
    "    save= {\n",
    "        'train_dataset' : train_dataset,\n",
    "        'train_labels'  : train_labels,\n",
    "        'valid_dataset' : valid_dataset,\n",
    "        'valid_labels'  : valid_labels,\n",
    "        'test_dataset'  : test_dataset,\n",
    "        'test_labels'    : test_labels,\n",
    "    }\n",
    "    pickle.dump(save, f , pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "except Exception as e:\n",
    "    print('unable to save data to', pickle_file , ':', e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compressed pickcle size: 690800406\n"
     ]
    }
   ],
   "source": [
    "statinfo= os.stat(pickle_file)\n",
    "print('compressed pickcle size:', statinfo.st_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# removing duplicate data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.5        -0.48823529 -0.13529412 ..., -0.37058824 -0.5        -0.49607843]\n",
      "  [-0.5        -0.28431374  0.5        ..., -0.24117647 -0.5        -0.48823529]\n",
      "  [-0.5        -0.19019608  0.47254902 ..., -0.35882354 -0.5        -0.49215686]\n",
      "  ..., \n",
      "  [ 0.18627451  0.48823529 -0.12745099 ...,  0.37058824  0.5        -0.07254902]\n",
      "  [ 0.26078433  0.5         0.5        ...,  0.5         0.5        -0.04117647]\n",
      "  [ 0.00196078  0.05686275  0.0372549  ...,  0.45686275  0.5         0.00980392]]\n",
      "\n",
      " [[-0.5        -0.5        -0.5        ...,  0.5         0.5         0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ...,  0.5         0.5         0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ...,  0.5         0.5         0.5       ]\n",
      "  ..., \n",
      "  [ 0.5         0.5         0.49607843 ...,  0.49607843  0.5         0.49607843]\n",
      "  [-0.0254902   0.3392157   0.48431373 ...,  0.47647059  0.32352942\n",
      "   -0.05294118]\n",
      "  [-0.5        -0.37450981 -0.1509804  ..., -0.1627451  -0.38235295 -0.5       ]]\n",
      "\n",
      " [[-0.5        -0.5        -0.5        ..., -0.5        -0.5        -0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ..., -0.5        -0.49607843 -0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ..., -0.5        -0.48823529 -0.5       ]\n",
      "  ..., \n",
      "  [-0.5        -0.5        -0.49215686 ..., -0.12745099 -0.5        -0.48431373]\n",
      "  [-0.5        -0.5        -0.5        ..., -0.43333334 -0.5        -0.49607843]\n",
      "  [-0.5        -0.5        -0.5        ..., -0.5        -0.5        -0.5       ]]\n",
      "\n",
      " ..., \n",
      " [[-0.5        -0.5        -0.48431373 ..., -0.49215686 -0.49607843 -0.5       ]\n",
      "  [-0.5        -0.48431373 -0.5        ..., -0.5        -0.48823529 -0.5       ]\n",
      "  [-0.48431373 -0.5        -0.24117647 ..., -0.01372549 -0.5        -0.48039216]\n",
      "  ..., \n",
      "  [-0.48431373 -0.5        -0.00196078 ...,  0.22941177 -0.47647059\n",
      "   -0.49607843]\n",
      "  [-0.49607843 -0.48823529 -0.5        ..., -0.44901961 -0.5        -0.49215686]\n",
      "  [-0.5        -0.49607843 -0.48823529 ..., -0.5        -0.48823529 -0.5       ]]\n",
      "\n",
      " [[-0.5        -0.5        -0.5        ..., -0.10392157  0.00196078\n",
      "   -0.3509804 ]\n",
      "  [-0.5        -0.5        -0.5        ..., -0.5        -0.35882354\n",
      "   -0.46470588]\n",
      "  [-0.5        -0.5        -0.5        ..., -0.48431373  0.08431373\n",
      "    0.1627451 ]\n",
      "  ..., \n",
      "  [-0.07254902  0.1         0.18235295 ..., -0.5        -0.5        -0.5       ]\n",
      "  [-0.48823529  0.35882354  0.5        ..., -0.5        -0.5        -0.5       ]\n",
      "  [-0.36274511  0.44901961  0.48431373 ..., -0.5        -0.5        -0.5       ]]\n",
      "\n",
      " [[-0.5        -0.5        -0.5        ...,  0.0882353  -0.31176472 -0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ...,  0.5         0.37058824\n",
      "   -0.38627452]\n",
      "  [-0.5        -0.5        -0.5        ...,  0.31568629  0.5        -0.20588236]\n",
      "  ..., \n",
      "  [-0.5         0.31960785  0.5        ..., -0.5        -0.5        -0.5       ]\n",
      "  [-0.5        -0.25294119  0.1627451  ..., -0.5        -0.5        -0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ..., -0.5        -0.5        -0.5       ]]]\n",
      "Time: 3.03s\n",
      "valid -> train overlap: 1081 samples\n",
      "test  -> train overlap: 1278 samples\n",
      "test  -> valid overlap: 185 samples\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import hashlib\n",
    "\n",
    "f=open(pickle_file, 'rb')\n",
    "read_pickle = pickle.load( f )\n",
    "train_dataset=read_pickle['train_dataset']\n",
    "print(train_dataset)\n",
    "train_labels=read_pickle['train_labels']\n",
    "valid_dataset=read_pickle['valid_dataset']\n",
    "valid_labels=read_pickle['valid_labels']\n",
    "test_dataset=read_pickle['test_dataset']\n",
    "test_labels=read_pickle['test_labels']\n",
    "\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "train_hashes = [hashlib.sha1(x).digest() for x in train_dataset]\n",
    "valid_hashes = [hashlib.sha1(x).digest() for x in valid_dataset]\n",
    "test_hashes  = [hashlib.sha1(x).digest() for x in test_dataset]\n",
    "\n",
    "valid_in_train = np.in1d(valid_hashes, train_hashes)\n",
    "test_in_train  = np.in1d(test_hashes,  train_hashes)\n",
    "test_in_valid  = np.in1d(test_hashes,  valid_hashes)\n",
    "\n",
    "valid_keep = ~valid_in_train\n",
    "test_keep  = ~(test_in_train | test_in_valid)\n",
    "\n",
    "valid_dataset_clean = valid_dataset[valid_keep]\n",
    "valid_labels_clean  = valid_labels [valid_keep]\n",
    "\n",
    "test_dataset_clean = test_dataset[test_keep]\n",
    "test_labels_clean  = test_labels [test_keep]\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"Time: %0.2fs\" % (t2 - t1))\n",
    "print(\"valid -> train overlap: %d samples\" % valid_in_train.sum())\n",
    "print(\"test  -> train overlap: %d samples\" % test_in_train.sum())\n",
    "print(\"test  -> valid overlap: %d samples\" % test_in_valid.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8689, 28, 28)\n",
      "6812176\n",
      "(8919, 28, 28)\n",
      "6992496\n",
      "(200000, 28, 28)\n",
      "156800000\n"
     ]
    }
   ],
   "source": [
    "print (test_dataset_clean.shape)\n",
    "print (test_dataset_clean.size)\n",
    "print (valid_dataset_clean.shape)\n",
    "print (valid_dataset_clean.size)\n",
    "print (train_dataset.shape)\n",
    "print (train_dataset.size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model with logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "(samples,width,height)=train_dataset.shape\n",
    "num_samples=20000\n",
    "train_x=np.reshape(train_dataset,(samples,width*height))[0:num_samples]\n",
    "train_y=train_labels [0:num_samples]\n",
    "(samples,width,height)=test_dataset_clean.shape\n",
    "\n",
    "logistic =LogisticRegression(C=1e-1, solver=\"newton-cg\")\n",
    "fit_model=logistic.fit(train_x,train_y,sample_weight=None) #fit(X, y[, sample_weight])\n",
    "\n",
    "fit_score=logistic.score(test_x, test_y, sample_weight=None)\n",
    "\n",
    "print(fit_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13\n",
      "0.132617814\n",
      "0.13\n"
     ]
    }
   ],
   "source": [
    "num_samples=500\n",
    "test_x=np.reshape(test_dataset_clean,(samples,width*height))[0:num_samples]\n",
    "test_y=test_labels [0:num_samples]\n",
    "pred=logistic.predict(test_x)\n",
    "acc_score=accuracy_score(test_y,pred)\n",
    "pre_score=precision_score(test_y,pred, average='weighted')\n",
    "re_score=recall_score(test_y,pred,average='weighted')\n",
    "print(acc_score)\n",
    "print(pre_score)\n",
    "print(re_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
