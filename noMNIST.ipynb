{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Dataset into folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./notMNIST_large already present - Skipping extraction of ./notMNIST_large.tar.gz\n",
      "['./notMNIST_large/A', './notMNIST_large/B', './notMNIST_large/C', './notMNIST_large/D', './notMNIST_large/E', './notMNIST_large/F', './notMNIST_large/G', './notMNIST_large/H', './notMNIST_large/I', './notMNIST_large/J']\n",
      "./notMNIST_small already present - Skipping extraction of ./notMNIST_small.tar.gz\n",
      "['./notMNIST_small/A', './notMNIST_small/B', './notMNIST_small/C', './notMNIST_small/D', './notMNIST_small/E', './notMNIST_small/F', './notMNIST_small/G', './notMNIST_small/H', './notMNIST_small/I', './notMNIST_small/J']\n"
     ]
    }
   ],
   "source": [
    "num_classes=10\n",
    "np.random.seed(133)\n",
    "data_root='.'\n",
    "train_filename= os.path.join(data_root, 'notMNIST_large.tar.gz') #join os root and extention(dataroot)\n",
    "test_filename= os.path.join(data_root, 'notMNIST_small.tar.gz')\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "    root=os.path.splitext(os.path.splitext(filename)[0])[0] #splits the os root and extension \n",
    "    if os.path.isdir(root)and not force:\n",
    "        print('%s already present - Skipping extraction of %s' %(root, filename))\n",
    "    else:\n",
    "        print('extracting data %s.this may take a while .please wait.' %root)\n",
    "        tar=tarfile.open(filename)\n",
    "        sys.stdout.flush()\n",
    "        tar.extractall(data_root)\n",
    "        tar.close()\n",
    "    data_folders = [\n",
    "        os.path.join(root, d)for d in sorted(os.listdir(root)) #listing all the classes directory\n",
    "        if os.path.isdir(os.path.join(root, d))]\n",
    "    if len(data_folders) !=num_classes: #checks lengths\n",
    "        raise Exception(\n",
    "            'Expected %d folders , one per class. found %d instead.' % (\n",
    "                num_classes,len(data_folders)))\n",
    "    print(data_folders)\n",
    "    return data_folders\n",
    "    \n",
    "    \n",
    "train_folders= maybe_extract(train_filename)\n",
    "test_folders=maybe_extract(test_filename)\n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert image into npArray and save into pickle file with seperate class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./notMNIST_large/A.pickle already present - skipping pickling.\n",
      "./notMNIST_large/B.pickle already present - skipping pickling.\n",
      "./notMNIST_large/C.pickle already present - skipping pickling.\n",
      "./notMNIST_large/D.pickle already present - skipping pickling.\n",
      "./notMNIST_large/E.pickle already present - skipping pickling.\n",
      "./notMNIST_large/F.pickle already present - skipping pickling.\n",
      "./notMNIST_large/G.pickle already present - skipping pickling.\n",
      "./notMNIST_large/H.pickle already present - skipping pickling.\n",
      "./notMNIST_large/I.pickle already present - skipping pickling.\n",
      "./notMNIST_large/J.pickle already present - skipping pickling.\n",
      "./notMNIST_small/A.pickle already present - skipping pickling.\n",
      "./notMNIST_small/B.pickle already present - skipping pickling.\n",
      "./notMNIST_small/C.pickle already present - skipping pickling.\n",
      "./notMNIST_small/D.pickle already present - skipping pickling.\n",
      "./notMNIST_small/E.pickle already present - skipping pickling.\n",
      "./notMNIST_small/F.pickle already present - skipping pickling.\n",
      "./notMNIST_small/G.pickle already present - skipping pickling.\n",
      "./notMNIST_small/H.pickle already present - skipping pickling.\n",
      "./notMNIST_small/I.pickle already present - skipping pickling.\n",
      "./notMNIST_small/J.pickle already present - skipping pickling.\n"
     ]
    }
   ],
   "source": [
    "image_size=28 #pixel width and height\n",
    "pixel_depth=255.0 #Nurmber of levels per pixel\n",
    "\n",
    "def load_letter(folder, min_num_images):\n",
    "    \"\"\"Load the data for a single letter label\"\"\"\n",
    "    image_files=os.listdir(folder)\n",
    "    dataset=np.ndarray(shape=(len(image_files),image_size, image_size),dtype=np.float32)\n",
    "    #print(folder)\n",
    "    num_images=0\n",
    "    for image in image_files:\n",
    "        image_file=os.path.join(folder,image)\n",
    "        try:\n",
    "            image_data=(ndimage.imread(image_file).astype(float) - pixel_depth /2)/pixel_depth\n",
    "            #print(image_data.shape)\n",
    "            if image_data.shape !=(image_size,image_size):\n",
    "                raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "            dataset[num_images,:,:]=image_data\n",
    "            num_images=num_images + 1\n",
    "        except IOError as e:\n",
    "            print('couldnot read :', image_file , ':', e , '-it\\'s ok , skipping.')\n",
    "    dataset=dataset[0:num_images, :, :]\n",
    "    if num_images < min_num_images:\n",
    "        raise Exception('many fewer images then expected: %d < %d' % (num_images, min_num_images))\n",
    "    print('Full dataset tensor:', dataset.shape)\n",
    "    print('mean:', np.mean(dataset))\n",
    "    print('standard deviation:', np.std(dataset))\n",
    "    return dataset\n",
    "\n",
    "def maybe_pickle(data_folders, min_num_images_per_class, force=False):\n",
    "    dataset_names=[]\n",
    "    for folder in data_folders:\n",
    "        set_filename=folder+ '.pickle'\n",
    "        dataset_names.append(set_filename)\n",
    "        if os.path.exists(set_filename)and not force:\n",
    "            print('%s already present - skipping pickling.' % set_filename)\n",
    "        else:\n",
    "            print('pickling %s.' % set_filename)\n",
    "            dataset=load_letter(folder,min_num_images_per_class)\n",
    "            try:\n",
    "                with open(set_filename, 'wb')as f:\n",
    "                    pickle.dump(dataset,f, pickle.HIGHEST_PROTOCOL)\n",
    "            except Exception as e:\n",
    "                print('Unable to save data to', set_filename, ':',e)\n",
    "    return dataset_names\n",
    "train_datasets=maybe_pickle(train_folders, 45000)#Not MNIST Large\n",
    "test_datasets=maybe_pickle(test_folders, 1800)#Not MNIST SMALL\n",
    "#print (train_dataset.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access images from pickle and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52909, 28, 28)\n",
      "41480656\n",
      "[[-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.49607843 -0.5        -0.47647059  0.04117647 -0.05294118 -0.5\n",
      "  -0.48823529 -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.49215686 -0.5        -0.43333334 -0.07647059 -0.34705883  0.02156863\n",
      "  -0.35490197 -0.5        -0.49607843 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.49607843\n",
      "  -0.49607843 -0.5         0.0882353  -0.05686275 -0.43725491 -0.17843138\n",
      "   0.05686275 -0.5        -0.49215686 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.49607843 -0.5\n",
      "  -0.43333334 -0.00196078  0.06470589  0.09607843  0.14313726  0.08039216\n",
      "   0.05686275 -0.47254902 -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.49215686 -0.5\n",
      "   0.02156863 -0.19803922 -0.43725491 -0.27254903 -0.17450981 -0.06862745\n",
      "  -0.01764706 -0.11176471 -0.5        -0.49607843 -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.48823529 -0.5        -0.12352941\n",
      "  -0.07254902 -0.5        -0.49215686 -0.5        -0.5        -0.49215686\n",
      "  -0.5        -0.05294118 -0.27254903 -0.5        -0.49215686 -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.49215686 -0.5        -0.29215688  0.0372549\n",
      "  -0.5        -0.49215686 -0.49607843 -0.49215686 -0.48823529 -0.48431373\n",
      "  -0.5        -0.40196079 -0.01764706 -0.5        -0.49607843 -0.5        -0.5\n",
      "  -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.49607843 -0.5        -0.42941177  0.06862745 -0.40196079\n",
      "  -0.5        -0.49215686 -0.49215686 -0.49607843 -0.5        -0.5\n",
      "  -0.48823529 -0.5        -0.11568628 -0.25294119 -0.5        -0.49215686\n",
      "  -0.5        -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.49215686 -0.5         0.00196078 -0.26078433 -0.5\n",
      "  -0.48039216 -0.5        -0.5        -0.49607843 -0.49607843 -0.5\n",
      "  -0.49607843 -0.5        -0.42156863 -0.06078431 -0.48823529 -0.49607843\n",
      "  -0.49215686 -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.48823529 -0.5        -0.13137256 -0.11568628 -0.5        -0.48039216\n",
      "  -0.5        -0.4137255  -0.03333334 -0.12745099 -0.5        -0.49215686\n",
      "  -0.5        -0.49607843 -0.49607843 -0.07647059 -0.28823531 -0.47254902\n",
      "  -0.5        -0.49607843 -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.49215686 -0.5        -0.28431374  0.00196078 -0.5        -0.5\n",
      "  -0.44901961 -0.13529412 -0.03333334 -0.32745099  0.02156863 -0.3392157\n",
      "  -0.5        -0.48431373 -0.5        -0.24117647 -0.06078431  0.05294118\n",
      "  -0.05294118 -0.41764706 -0.5        -0.49607843]\n",
      " [-0.5        -0.5        -0.5        -0.5        -0.5        -0.49607843\n",
      "  -0.5        -0.42941177  0.0372549  -0.41764706 -0.5        -0.44509804\n",
      "   0.04509804 -0.2764706  -0.49215686 -0.5        -0.28823531 -0.06078431\n",
      "  -0.5        -0.5        -0.44901961 -0.06470589 -0.0372549  -0.36666667\n",
      "  -0.39411765  0.0254902  -0.46470588 -0.5       ]\n",
      " [-0.5        -0.5        -0.5        -0.49607843 -0.48823529 -0.49215686\n",
      "  -0.5        -0.01372549 -0.29215688 -0.5        -0.49607843 -0.48823529\n",
      "   0.01372549 -0.46078432 -0.5        -0.5        -0.48431373  0.11176471\n",
      "  -0.35882354 -0.5        -0.19019608 -0.03333334 -0.06862745 -0.5\n",
      "  -0.38235295 -0.05294118 -0.5        -0.5       ]\n",
      " [-0.5        -0.5        -0.49607843 -0.49607843 -0.49215686 -0.5\n",
      "  -0.14313726 -0.14313726 -0.5        -0.48823529 -0.48823529 -0.5\n",
      "  -0.14705883 -0.12745099 -0.31176472 -0.07254902 -0.01372549 -0.10392157\n",
      "  -0.43333334 -0.5        -0.35490197 -0.00980392  0.00588235 -0.44901961\n",
      "  -0.04901961 -0.27254903 -0.5        -0.49215686]\n",
      " [-0.5        -0.49607843 -0.5        -0.39019608 -0.03333334 -0.17058824\n",
      "  -0.08039216 -0.49215686 -0.49607843 -0.5        -0.49607843 -0.5\n",
      "  -0.42156863 -0.06078431 -0.19411765 -0.34313726 -0.48431373 -0.5        -0.5\n",
      "  -0.48823529 -0.5        -0.12745099  0.01372549 -0.13529412 -0.3509804\n",
      "  -0.06470589 -0.48823529 -0.5       ]\n",
      " [-0.48823529 -0.5        -0.25686276 -0.0372549  -0.24117647  0.04117647\n",
      "  -0.12745099 -0.5        -0.49607843 -0.5        -0.5        -0.5\n",
      "  -0.49607843 -0.5        -0.5        -0.5        -0.5        -0.48823529\n",
      "  -0.49607843 -0.49607843 -0.5        -0.39411765 -0.01372549  0.03333334\n",
      "  -0.4137255  -0.25294119 -0.04117647 -0.5       ]\n",
      " [-0.49215686 -0.5        -0.2254902  -0.14313726 -0.5        -0.0372549\n",
      "  -0.02941176 -0.37058824 -0.5        -0.49607843 -0.5        -0.5        -0.5\n",
      "  -0.49215686 -0.49215686 -0.49607843 -0.5        -0.5        -0.5        -0.5\n",
      "  -0.49215686 -0.5        -0.16666667  0.01372549 -0.07254902 -0.09215686\n",
      "  -0.26078433 -0.5       ]\n",
      " [-0.5        -0.5        -0.43725491 -0.0254902  -0.5        -0.17450981\n",
      "   0.01764706 -0.2372549  -0.5        -0.49215686 -0.5        -0.5\n",
      "  -0.49215686 -0.48823529 -0.48823529 -0.48823529 -0.49215686 -0.49607843\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.43725491 -0.0372549\n",
      "   0.05294118 -0.11568628 -0.5        -0.49215686]\n",
      " [-0.5        -0.2647059  -0.00588235 -0.04509804 -0.5        -0.33529413\n",
      "   0.00588235 -0.10784314 -0.5        -0.49215686 -0.5        -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.5        -0.48823529 -0.5        -0.18235295 -0.1627451  -0.5\n",
      "  -0.48431373 -0.5       ]\n",
      " [-0.5        -0.11568628 -0.10392157 -0.5        -0.48823529 -0.48431373\n",
      "  -0.07254902 -0.01372549 -0.42156863 -0.5        -0.49607843 -0.5\n",
      "  -0.13921569 -0.07254902 -0.13529412 -0.17843138 -0.2254902  -0.4254902\n",
      "  -0.5        -0.49607843 -0.5        -0.5        -0.5        -0.48039216\n",
      "   0.01764706 -0.42156863 -0.5        -0.49607843]\n",
      " [-0.5        -0.43725491 -0.01372549 -0.48823529 -0.49607843 -0.49607843\n",
      "  -0.10784314  0.00588235 -0.23333333 -0.5        -0.5        -0.36274511\n",
      "   0.00196078 -0.45294118 -0.33529413 -0.28039217 -0.1627451   0.04901961\n",
      "  -0.49607843 -0.5        -0.5        -0.5        -0.49215686 -0.5\n",
      "  -0.2254902  -0.09607843 -0.5        -0.48823529]\n",
      " [-0.5        -0.24509804 -0.05294118 -0.48039216 -0.47254902 -0.13921569\n",
      "  -0.06470589 -0.02156863 -0.40588236 -0.5        -0.5        -0.13137256\n",
      "  -0.23333333 -0.5        -0.49215686 -0.48823529 -0.5        -0.07647059\n",
      "  -0.23333333 -0.5        -0.49215686 -0.5        -0.5        -0.49607843\n",
      "  -0.5        -0.00588235 -0.37843138 -0.5       ]\n",
      " [-0.04509804 -0.19019608 -0.5        -0.4254902  -0.1        -0.05294118\n",
      "  -0.05294118 -0.4254902  -0.5        -0.5        -0.48039216 -0.00588235\n",
      "  -0.44901961 -0.5        -0.49215686 -0.48823529 -0.5        -0.37058824\n",
      "   0.00196078 -0.5        -0.49607843 -0.5        -0.5        -0.49215686\n",
      "  -0.5        -0.29215688 -0.06862745 -0.5       ]\n",
      " [ 0.02941176 -0.35882354 -0.37843138 -0.06470589 -0.04901961 -0.09215686\n",
      "  -0.47254902 -0.5        -0.48823529 -0.5        -0.28823531 -0.10392157\n",
      "  -0.5        -0.48823529 -0.5        -0.5        -0.49215686 -0.5\n",
      "  -0.04117647 -0.30784315 -0.5        -0.49215686 -0.5        -0.49607843\n",
      "  -0.48431373 -0.5        -0.08431373 -0.33529413]\n",
      " [-0.31176472  0.10784314 -0.11960784 -0.09607843 -0.15882353 -0.49607843\n",
      "  -0.48823529 -0.48823529 -0.49215686 -0.5        -0.10392157 -0.33137256\n",
      "  -0.5        -0.49215686 -0.5        -0.5        -0.49607843 -0.5\n",
      "  -0.31176472 -0.06862745 -0.5        -0.47647059 -0.49215686 -0.5        -0.5\n",
      "  -0.46862745 -0.05294118 -0.05294118]\n",
      " [-0.49215686 -0.30392158 -0.02156863  0.06470589 -0.46862745 -0.5\n",
      "  -0.49607843 -0.5        -0.5        -0.45294118 -0.05686275 -0.5        -0.5\n",
      "  -0.5        -0.5        -0.5        -0.5        -0.49607843 -0.5\n",
      "  -0.02156863 -0.39019608 -0.5        -0.49215686 -0.3392157  -0.1\n",
      "  -0.03333334 -0.22941177 -0.46862745]\n",
      " [-0.49607843 -0.5        -0.37843138 -0.22156863 -0.07647059 -0.07647059\n",
      "  -0.17058824 -0.31176472 -0.5        -0.26078433 -0.19019608 -0.5\n",
      "  -0.49215686 -0.5        -0.5        -0.5        -0.5        -0.49215686\n",
      "  -0.5        -0.25686276 -0.06470589 -0.28823531 -0.04117647 -0.10392157\n",
      "  -0.33137256 -0.49607843 -0.5        -0.5       ]\n",
      " [-0.5        -0.49215686 -0.49607843 -0.5        -0.5        -0.43725491\n",
      "  -0.2764706  -0.12745099 -0.06078431  0.0372549  -0.4137255  -0.5\n",
      "  -0.49607843 -0.5        -0.5        -0.5        -0.5        -0.5        -0.5\n",
      "  -0.48431373 -0.01764706 -0.13137256 -0.4254902  -0.5        -0.5\n",
      "  -0.49607843 -0.48823529 -0.49607843]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0b9cd9d8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.image as mpimg\n",
    "read_pickle = pickle.load( open( \"notMNIST_large/A.pickle\", \"rb\" ) )\n",
    "print (read_pickle.shape)\n",
    "print (read_pickle.size)\n",
    "#print (read_pickle)\n",
    "print (read_pickle[0])\n",
    "imgplot = plt.imshow(read_pickle[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shuffle images from each class to have random validation and training set then merge each classes into a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:  (200000, 28, 28) (200000,)\n",
      "validation : (10000, 28, 28) (10000,)\n",
      "test : (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "#print (train_dataset.shape)\n",
    "def make_arrays(nb_rows, img_size):\n",
    "    if nb_rows:\n",
    "        dataset=np.ndarray((nb_rows, img_size , img_size), dtype=np.float32)\n",
    "        labels=np.ndarray(nb_rows,dtype=np.float32)\n",
    "    else:\n",
    "        dataset,labels=None, None\n",
    "    return dataset,labels\n",
    "def merge_datasets(pickle_files,train_size, valid_size=0):\n",
    "    num_classes= len(pickle_files)\n",
    "    valid_dataset, valid_labels= make_arrays(valid_size, image_size)#for validation \n",
    "    train_dataset, train_labels= make_arrays(train_size, image_size)\n",
    "    vsize_per_class= valid_size // num_classes\n",
    "    tsize_per_class= train_size // num_classes\n",
    "    \n",
    "    start_v,start_t =0 , 0\n",
    "    end_v, end_t =vsize_per_class , tsize_per_class\n",
    "    end_l=vsize_per_class+tsize_per_class\n",
    "    for label, pickle_file in enumerate(pickle_files):#label=value or index of pickle files,example A,B,C,D\n",
    "        try:\n",
    "            with open(pickle_file, 'rb') as f:\n",
    "                letter_set=pickle.load(f)\n",
    "                #shuffle the letters to have random validation and training set\n",
    "                np.random.shuffle(letter_set)\n",
    "                if valid_dataset is not None:\n",
    "                    valid_letter=letter_set[:vsize_per_class, : , :]\n",
    "                    valid_dataset[start_v:end_v, : , :] = valid_letter\n",
    "                    valid_labels[start_v:end_v]= label\n",
    "                    start_v +=vsize_per_class\n",
    "                    end_v += vsize_per_class\n",
    "                    \n",
    "                train_letter= letter_set[vsize_per_class:end_l, :, :]\n",
    "                train_dataset[start_t:end_t, : ,:]=train_letter\n",
    "                train_labels[start_t:end_t]=label\n",
    "                start_t +=tsize_per_class\n",
    "                end_t += tsize_per_class\n",
    "        except Exception as e:\n",
    "            print('unable to process data from', pickle_file, '.', e)\n",
    "            raise\n",
    "    return valid_dataset,valid_labels,train_dataset, train_labels\n",
    "\n",
    "train_size= 200000\n",
    "valid_size=10000\n",
    "test_size=10000\n",
    "\n",
    "valid_dataset, valid_labels,train_dataset,train_labels = merge_datasets(train_datasets, train_size , valid_size)\n",
    "_, _, test_dataset, test_labels=merge_datasets(test_datasets,test_size)\n",
    "\n",
    "print('training: ' ,train_dataset.shape , train_labels.shape)\n",
    "print('validation :' , valid_dataset.shape , valid_labels.shape)\n",
    "print('test :', test_dataset.shape , test_labels.shape)\n",
    "                    \n",
    "                \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# randomly shuffling whole dataset using permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "[ 82544 184777 127251 ...,  54720  86392  96194]\n",
      "10000\n",
      "[3480 6566 4543 ..., 6790 9016  268]\n",
      "10000\n",
      "[1927 9112 3615 ..., 8250 9495 8617]\n"
     ]
    }
   ],
   "source": [
    "def randomize(dataset, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    print (labels.shape[0])\n",
    "    print (permutation)\n",
    "    shuffled_dataset= dataset[permutation, : , :]\n",
    "    shuffled_labels= labels[permutation]\n",
    "    return shuffled_dataset, shuffled_labels\n",
    "train_dataset , train_labels = randomize(train_dataset, train_labels)\n",
    "test_dataset , test_labels = randomize(test_dataset, test_labels)\n",
    "valid_dataset , valid_labels = randomize(valid_dataset, valid_labels)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f991002e9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgplot = plt.imshow(train_dataset [0])\n",
    "print (train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving data into pickle to reuse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_file = os.path.join(data_root, 'notMNIST.pickle')\n",
    "try:\n",
    "    f = open(pickle_file , 'wb')\n",
    "    save= {\n",
    "        'train_dataset' : train_dataset,\n",
    "        'train_labels'  : train_labels,\n",
    "        'valid_dataset' : valid_dataset,\n",
    "        'valid_labels'  : valid_labels,\n",
    "        'test_dataset'  : test_dataset,\n",
    "        'test_labels'    : test_labels,\n",
    "    }\n",
    "    pickle.dump(save, f , pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "except Exception as e:\n",
    "    print('unable to save data to', pickle_file , ':', e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compressed pickcle size: 690800406\n"
     ]
    }
   ],
   "source": [
    "statinfo= os.stat(pickle_file)\n",
    "print('compressed pickcle size:', statinfo.st_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# removing duplicate data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.5        -0.48823529 -0.13529412 ..., -0.37058824 -0.5        -0.49607843]\n",
      "  [-0.5        -0.28431374  0.5        ..., -0.24117647 -0.5        -0.48823529]\n",
      "  [-0.5        -0.19019608  0.47254902 ..., -0.35882354 -0.5        -0.49215686]\n",
      "  ..., \n",
      "  [ 0.18627451  0.48823529 -0.12745099 ...,  0.37058824  0.5        -0.07254902]\n",
      "  [ 0.26078433  0.5         0.5        ...,  0.5         0.5        -0.04117647]\n",
      "  [ 0.00196078  0.05686275  0.0372549  ...,  0.45686275  0.5         0.00980392]]\n",
      "\n",
      " [[-0.5        -0.5        -0.5        ...,  0.5         0.5         0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ...,  0.5         0.5         0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ...,  0.5         0.5         0.5       ]\n",
      "  ..., \n",
      "  [ 0.5         0.5         0.49607843 ...,  0.49607843  0.5         0.49607843]\n",
      "  [-0.0254902   0.3392157   0.48431373 ...,  0.47647059  0.32352942\n",
      "   -0.05294118]\n",
      "  [-0.5        -0.37450981 -0.1509804  ..., -0.1627451  -0.38235295 -0.5       ]]\n",
      "\n",
      " [[-0.5        -0.5        -0.5        ..., -0.5        -0.5        -0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ..., -0.5        -0.49607843 -0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ..., -0.5        -0.48823529 -0.5       ]\n",
      "  ..., \n",
      "  [-0.5        -0.5        -0.49215686 ..., -0.12745099 -0.5        -0.48431373]\n",
      "  [-0.5        -0.5        -0.5        ..., -0.43333334 -0.5        -0.49607843]\n",
      "  [-0.5        -0.5        -0.5        ..., -0.5        -0.5        -0.5       ]]\n",
      "\n",
      " ..., \n",
      " [[-0.5        -0.5        -0.48431373 ..., -0.49215686 -0.49607843 -0.5       ]\n",
      "  [-0.5        -0.48431373 -0.5        ..., -0.5        -0.48823529 -0.5       ]\n",
      "  [-0.48431373 -0.5        -0.24117647 ..., -0.01372549 -0.5        -0.48039216]\n",
      "  ..., \n",
      "  [-0.48431373 -0.5        -0.00196078 ...,  0.22941177 -0.47647059\n",
      "   -0.49607843]\n",
      "  [-0.49607843 -0.48823529 -0.5        ..., -0.44901961 -0.5        -0.49215686]\n",
      "  [-0.5        -0.49607843 -0.48823529 ..., -0.5        -0.48823529 -0.5       ]]\n",
      "\n",
      " [[-0.5        -0.5        -0.5        ..., -0.10392157  0.00196078\n",
      "   -0.3509804 ]\n",
      "  [-0.5        -0.5        -0.5        ..., -0.5        -0.35882354\n",
      "   -0.46470588]\n",
      "  [-0.5        -0.5        -0.5        ..., -0.48431373  0.08431373\n",
      "    0.1627451 ]\n",
      "  ..., \n",
      "  [-0.07254902  0.1         0.18235295 ..., -0.5        -0.5        -0.5       ]\n",
      "  [-0.48823529  0.35882354  0.5        ..., -0.5        -0.5        -0.5       ]\n",
      "  [-0.36274511  0.44901961  0.48431373 ..., -0.5        -0.5        -0.5       ]]\n",
      "\n",
      " [[-0.5        -0.5        -0.5        ...,  0.0882353  -0.31176472 -0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ...,  0.5         0.37058824\n",
      "   -0.38627452]\n",
      "  [-0.5        -0.5        -0.5        ...,  0.31568629  0.5        -0.20588236]\n",
      "  ..., \n",
      "  [-0.5         0.31960785  0.5        ..., -0.5        -0.5        -0.5       ]\n",
      "  [-0.5        -0.25294119  0.1627451  ..., -0.5        -0.5        -0.5       ]\n",
      "  [-0.5        -0.5        -0.5        ..., -0.5        -0.5        -0.5       ]]]\n",
      "Time: 2.04s\n",
      "valid -> train overlap: 1081 samples\n",
      "test  -> train overlap: 1278 samples\n",
      "test  -> valid overlap: 185 samples\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import hashlib\n",
    "\n",
    "f=open(pickle_file, 'rb')\n",
    "read_pickle = pickle.load( f )\n",
    "train_dataset=read_pickle['train_dataset']\n",
    "print(train_dataset)\n",
    "train_labels=read_pickle['train_labels']\n",
    "valid_dataset=read_pickle['valid_dataset']\n",
    "valid_labels=read_pickle['valid_labels']\n",
    "test_dataset=read_pickle['test_dataset']\n",
    "test_labels=read_pickle['test_labels']\n",
    "\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "train_hashes = [hashlib.sha1(x).digest() for x in train_dataset]\n",
    "valid_hashes = [hashlib.sha1(x).digest() for x in valid_dataset]\n",
    "test_hashes  = [hashlib.sha1(x).digest() for x in test_dataset]\n",
    "\n",
    "valid_in_train = np.in1d(valid_hashes, train_hashes)\n",
    "test_in_train  = np.in1d(test_hashes,  train_hashes)\n",
    "test_in_valid  = np.in1d(test_hashes,  valid_hashes)\n",
    "\n",
    "valid_keep = ~valid_in_train\n",
    "test_keep  = ~(test_in_train | test_in_valid)\n",
    "\n",
    "valid_dataset_clean = valid_dataset[valid_keep]\n",
    "valid_labels_clean  = valid_labels [valid_keep]\n",
    "\n",
    "test_dataset_clean = test_dataset[test_keep]\n",
    "test_labels_clean  = test_labels [test_keep]\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"Time: %0.2fs\" % (t2 - t1))\n",
    "print(\"valid -> train overlap: %d samples\" % valid_in_train.sum())\n",
    "print(\"test  -> train overlap: %d samples\" % test_in_train.sum())\n",
    "print(\"test  -> valid overlap: %d samples\" % test_in_valid.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8689, 28, 28)\n",
      "6812176\n",
      "(8919, 28, 28)\n",
      "6992496\n",
      "(200000, 28, 28)\n",
      "156800000\n"
     ]
    }
   ],
   "source": [
    "print (test_dataset_clean.shape)\n",
    "print (test_dataset_clean.size)\n",
    "print (valid_dataset_clean.shape)\n",
    "print (valid_dataset_clean.size)\n",
    "print (train_dataset.shape)\n",
    "print (train_dataset.size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train model with logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "(samples,width,height)=train_dataset.shape\n",
    "num_samples=20000\n",
    "train_x=np.reshape(train_dataset,(samples,width*height))[0:num_samples]\n",
    "train_y=train_labels [0:num_samples]\n",
    "(samples,width,height)=test_dataset_clean.shape\n",
    "\n",
    "logistic =LogisticRegression(C=1e-1, solver=\"newton-cg\")\n",
    "fit_model=logistic.fit(train_x,train_y,sample_weight=None) #fit(X, y[, sample_weight])\n",
    "\n",
    "#fit_score=logistic.score(test_x, test_y, sample_weight=None)\n",
    "\n",
    "#print(fit_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.725\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "num_samples=10\n",
    "test_x=np.reshape(test_dataset_clean,(samples,width*height))[0:num_samples]\n",
    "test_y=test_labels [0:num_samples]\n",
    "pred=logistic.predict(test_x)\n",
    "acc_score=accuracy_score(test_y,pred)\n",
    "pre_score=precision_score(test_y,pred, average='weighted')\n",
    "re_score=recall_score(test_y,pred,average='weighted')\n",
    "print(acc_score)\n",
    "print(pre_score)\n",
    "print(re_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
