{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "from PIL import Image\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set (139000, 28, 28) (139000,)\n",
      "validation set (10000, 28, 28) (10000,)\n",
      "test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file= 'banglaIsolated_clean.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save=pickle.load(f)\n",
    "    train_dataset=save['train_dataset']\n",
    "    train_labels=save['train_labels']\n",
    "    valid_dataset=save['valid_dataset_clean']\n",
    "    valid_labels=save['valid_labels']\n",
    "    test_dataset=save['test_dataset_clean']\n",
    "    test_labels=save['test_labels']\n",
    "    del save #hint to help gc to free up memory \n",
    "    print('training set', train_dataset.shape,train_labels.shape)\n",
    "    print('validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('test set', test_dataset.shape,test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set (139000, 28, 28, 1) (139000, 45)\n",
      "validation set (10000, 28, 28, 1) (10000, 45)\n",
      "test set (10000, 28, 28, 1) (10000, 45)\n"
     ]
    }
   ],
   "source": [
    "image_size=28\n",
    "num_labels=45\n",
    "num_channels=1 \n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset=dataset.reshape((-1,image_size,image_size,num_channels)).astype(np.float32)\n",
    "    # Map 1 to [0.0,1.0,0.0....], 2 to [0.0,0.0,1.0.....]\n",
    "    labels=(np.arange(num_labels) ==labels[:,None]).astype(np.float32)\n",
    "    return dataset,labels\n",
    "train_dataset, train_labels= reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels=reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels =reformat(test_dataset, test_labels)\n",
    "print( 'training set', train_dataset.shape,train_labels.shape)\n",
    "print('validation set', valid_dataset.shape,valid_labels.shape)\n",
    "print('test set', test_dataset.shape,test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return(100.0*np.sum(np.argmax(predictions, 1)==np.argmax(labels,1))/ predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-27a19bd07f88>:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at step 0: 1.904684\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 50: 1.906230\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 0.7%\n",
      "Minibatch loss at step 100: 3.500025\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 150: 2289.777344\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 200: 47.257565\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 250: 166.963043\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 300: 69549.968750\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 350: 637.163330\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.0%\n",
      "Minibatch loss at step 400: 590.563843\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 450: 628.617004\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.1%\n",
      "Minibatch loss at step 500: 101841.437500\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 550: 17086.392578\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 600: 2162849.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 650: 71885.867188\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 700: 68637.867188\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 750: 1072301.500000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 800: 8254260.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 850: 109056416.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 900: 59453336.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 950: 1867695360.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 1000: 4528155648.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 1050: 12837454848.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 1100: 37883531264.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 1150: 131327516672.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 1200: 336207642624.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 1250: 752606183424.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 1300: 1199708700672.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 1350: 1995493867520.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 1400: 3703101456384.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 1450: 4888495390720.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 1500: 7282267521024.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 1550: 8652369428480.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 1600: 15801058852864.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 1650: 14131119783936.000000\n",
      "Minibatch accuracy: 6.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 1700: 32614488473600.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 1750: 35866202341376.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 1800: 42550819815424.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 1850: 46398879825920.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 1900: 49327909109760.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 1950: 75165576724480.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 2000: 99217351639040.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 2050: 142014486151168.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 2100: 144675486826496.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 2150: 209166501150720.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 2200: 187033192497152.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 2250: 206662317113344.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 2300: 267320274452480.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 2350: 205498380976128.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 2400: 285352459763712.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 2450: 443542849716224.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 2500: 549087006949376.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 2550: 564261864603648.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 2600: 487286118547456.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 2650: 656961016168448.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 2700: 534883885645824.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 2750: 911046717997056.000000\n",
      "Minibatch accuracy: 62.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 2800: 907486928306176.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 2850: 929465081266176.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 2900: 843321324863488.000000\n",
      "Minibatch accuracy: 6.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 2950: 1317549803307008.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 3000: 1544788469874688.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 3050: 1427729270439936.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 3100: 1397997090897920.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 3150: 2003324681322496.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 3200: 2608743271366656.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 3250: 1893790264590336.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 3300: 1779255163748352.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 3350: 1198047170134016.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 3400: 1586971893825536.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 3450: 3030094058618880.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 3500: 3376422236192768.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 3550: 3861459335380992.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 3600: 3687865078775808.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 3650: 3658273022541824.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 3700: 3949012780580864.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 3750: 4923808490192896.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 3800: 4786164452032512.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 3850: 5546226560794624.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 3900: 3175914640769024.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 3950: 5347338973347840.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 4000: 5213625904005120.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 4050: 4487068566683648.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 4100: 6757749861908480.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 4150: 4124999333969920.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 4200: 4859239562477568.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 4250: 5317873350213632.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 4300: 9567683896934400.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 4350: 10663879809957888.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 4400: 11289801500131328.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 4450: 9837221012045824.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 4500: 7072883423576064.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 4550: 9478075846754304.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 4600: 8984104141848576.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 4650: 10018485811806208.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 4700: 17433746848350208.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 4750: 10384733779263488.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 4800: 13285998146355200.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 4850: 24109859045638144.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 4900: 16040961968701440.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 4950: 13981368383963136.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 5000: 16179648610172928.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 5050: 19250996903411712.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 5100: 16196047869050880.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 5150: 18142029905133568.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 5200: 21596145683791872.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 5250: 21996037203820544.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 5300: 24684804842717184.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 5350: 28922037040840704.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 5400: 25304467691798528.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 5450: 29086723266838528.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 5500: 17808240079273984.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 5550: 29185799572422656.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 5600: 22851128685232128.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 5650: 19911111901970432.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 5700: 22588938111680512.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 5750: 21788736312311808.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 5800: 29916502358491136.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 5850: 25880744928739328.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 5900: 29889585798447104.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 5950: 43930656375308288.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 6000: 44298773727281152.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 6050: 36400346049806336.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 6100: 46621006709653504.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 6150: 40705084396404736.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 6200: 47169577112567808.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 6250: 58203988046118912.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 6300: 50715987443449856.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 6350: 41512963449815040.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 6400: 43454898552963072.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 6450: 51025431247192064.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 6500: 61802887172325376.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 6550: 46705978342637568.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 6600: 60426255664676864.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 6650: 57001586181799936.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 6700: 49941093738872832.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 6750: 67947005392977920.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 6800: 60836768638828544.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 6850: 70055340414074880.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 6900: 56153948616130560.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 6950: 42915390531043328.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 7000: 66079111231045632.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 7050: 72011852636225536.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 7100: 85279796887552000.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 7150: 76329772237455360.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 7200: 87072129689845760.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 7250: 82322806393536512.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 7300: 110426065901453312.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 7350: 127005816485052416.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 7400: 113967987991511040.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 7450: 72600400594731008.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 7500: 86625246932631552.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 7550: 112115439747727360.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 7600: 95240135284621312.000000\n",
      "Minibatch accuracy: 8.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 7650: 114552309702197248.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 7700: 122865760069484544.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 7750: 116652909487194112.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 7800: 151627841790803968.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 7850: 121973137016356864.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 7900: 132815026040864768.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 7950: 124588033365245952.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 8000: 77412653751861248.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 8050: 129094716779134976.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 8100: 111887445703786496.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 8150: 148522477356580864.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 8200: 132253484836716544.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 8250: 148099285638971392.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 8300: 92704489672278016.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 8350: 162531561164505088.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 8400: 185693615417196544.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 8450: 137452499798851584.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 8500: 184228017956978688.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 8550: 153722806578708480.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 8600: 175791860374044672.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 8650: 188279323168342016.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 8700: 202392465443913728.000000\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 8750: 166243512419876864.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 8800: 239375123159711744.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 8850: 282141727433687040.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 8900: 276335240887140352.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 8950: 177083116521783296.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 9000: 262813721766658048.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 9050: 141651405856309248.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 9100: 261941499808186368.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 9150: 130951310882111488.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 9200: 174029119896420352.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 9250: 313177848309350400.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 9300: 207661685941469184.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 9350: 285604209808637952.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 9400: 318311261941006336.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 9450: 368536609500430336.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 9500: 353067786567680000.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 9550: 300560024667684864.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 9600: 186402233481428992.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 9650: 237377001294397440.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 9700: 241770460780429312.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 9750: 319843190876143616.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 9800: 405956597966176256.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 9850: 380809255210450944.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 9900: 284701734100533248.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 9950: 320248154752548864.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 10000: 343740423270825984.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 10050: 378651738518847488.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 10100: 340492191044468736.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 10150: 424927640311300096.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 10200: 374619966818746368.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 10250: 340282837158592512.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 10300: 348480795855290368.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 10350: 311002395834318848.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 10400: 490800893759848448.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 10450: 466995470586085376.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 10500: 454880089398575104.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 10550: 403251971160539136.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 10600: 471913895334772736.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 10650: 401399500226166784.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 10700: 474333198873001984.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 10750: 490104937259204608.000000\n",
      "Minibatch accuracy: 8.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 10800: 468376457190572032.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 10850: 362515855625420800.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 10900: 425892736642580480.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 10950: 460344593469145088.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 11000: 441437906913984512.000000\n",
      "Minibatch accuracy: 4.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 11050: 534679310447935488.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 11100: 651202941419520000.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 11150: 477610946114617344.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 11200: 572356137957982208.000000\n",
      "Minibatch accuracy: 2.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 11250: 468572788735606784.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 11300: 562429231586344960.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 11350: 385710087773093888.000000\n",
      "Minibatch accuracy: 0.0%\n",
      "Validation accuracy: 1.2%\n",
      "Minibatch loss at step 11400: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 11450: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 11500: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 11550: nan\n",
      "Minibatch accuracy: 58.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 11600: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 11650: nan\n",
      "Minibatch accuracy: 56.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 11700: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 11750: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 11800: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 11850: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 11900: nan\n",
      "Minibatch accuracy: 38.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 11950: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 12000: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 12050: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 12100: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 12150: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 12200: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 12250: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 12300: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 12350: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 12400: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 12450: nan\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 12500: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 12550: nan\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 12600: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 12650: nan\n",
      "Minibatch accuracy: 64.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 12700: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 12750: nan\n",
      "Minibatch accuracy: 38.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 12800: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 12850: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 12900: nan\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 12950: nan\n",
      "Minibatch accuracy: 36.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 13000: nan\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 13050: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 13100: nan\n",
      "Minibatch accuracy: 32.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 13150: nan\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 13200: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 13250: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 13300: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 13350: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 13400: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 13450: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 13500: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 13550: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 13600: nan\n",
      "Minibatch accuracy: 56.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 13650: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 13700: nan\n",
      "Minibatch accuracy: 36.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 13750: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 13800: nan\n",
      "Minibatch accuracy: 32.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 13850: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 13900: nan\n",
      "Minibatch accuracy: 28.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 13950: nan\n",
      "Minibatch accuracy: 38.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 14000: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 14050: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 14100: nan\n",
      "Minibatch accuracy: 60.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 14150: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 14200: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 14250: nan\n",
      "Minibatch accuracy: 60.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 14300: nan\n",
      "Minibatch accuracy: 32.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 14350: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 14400: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 14450: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 14500: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 14550: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 14600: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 14650: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 14700: nan\n",
      "Minibatch accuracy: 56.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 14750: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 14800: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 14850: nan\n",
      "Minibatch accuracy: 38.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 14900: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 14950: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 15000: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 15050: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 15100: nan\n",
      "Minibatch accuracy: 60.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 15150: nan\n",
      "Minibatch accuracy: 34.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 15200: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 15250: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 15300: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 15350: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 15400: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 15450: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 15500: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 15550: nan\n",
      "Minibatch accuracy: 58.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 15600: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 15650: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 15700: nan\n",
      "Minibatch accuracy: 38.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 15750: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 15800: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 15850: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 15900: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 15950: nan\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 16000: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 16050: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 16100: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 16150: nan\n",
      "Minibatch accuracy: 34.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 16200: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 16250: nan\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 16300: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 16350: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 16400: nan\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 16450: nan\n",
      "Minibatch accuracy: 38.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 16500: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 16550: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 16600: nan\n",
      "Minibatch accuracy: 62.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 16650: nan\n",
      "Minibatch accuracy: 60.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 16700: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 16750: nan\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 16800: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 16850: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 16900: nan\n",
      "Minibatch accuracy: 36.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 16950: nan\n",
      "Minibatch accuracy: 56.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 17000: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 17050: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 17100: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 17150: nan\n",
      "Minibatch accuracy: 60.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 17200: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 17250: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 17300: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 17350: nan\n",
      "Minibatch accuracy: 64.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 17400: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 17450: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 17500: nan\n",
      "Minibatch accuracy: 58.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 17550: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 17600: nan\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 17650: nan\n",
      "Minibatch accuracy: 38.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 17700: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 17750: nan\n",
      "Minibatch accuracy: 38.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 17800: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 17850: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 17900: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 17950: nan\n",
      "Minibatch accuracy: 38.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 18000: nan\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 18050: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 18100: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 18150: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 18200: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 18250: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 18300: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 18350: nan\n",
      "Minibatch accuracy: 58.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 18400: nan\n",
      "Minibatch accuracy: 36.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 18450: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 18500: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 18550: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 18600: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 18650: nan\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 18700: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 18750: nan\n",
      "Minibatch accuracy: 66.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 18800: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 18850: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 18900: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 18950: nan\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 19000: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 19050: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 19100: nan\n",
      "Minibatch accuracy: 56.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 19150: nan\n",
      "Minibatch accuracy: 56.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 19200: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 19250: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 19300: nan\n",
      "Minibatch accuracy: 56.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 19350: nan\n",
      "Minibatch accuracy: 36.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 19400: nan\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 19450: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 19500: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 19550: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 19600: nan\n",
      "Minibatch accuracy: 34.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 19650: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 19700: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 19750: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 19800: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 19850: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 19900: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 19950: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 20000: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 20050: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 20100: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 20150: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 20200: nan\n",
      "Minibatch accuracy: 60.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 20250: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 20300: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 20350: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 20400: nan\n",
      "Minibatch accuracy: 56.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 20450: nan\n",
      "Minibatch accuracy: 60.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 20500: nan\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 20550: nan\n",
      "Minibatch accuracy: 58.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 20600: nan\n",
      "Minibatch accuracy: 58.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 20650: nan\n",
      "Minibatch accuracy: 36.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 20700: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 20750: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 20800: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 20850: nan\n",
      "Minibatch accuracy: 64.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 20900: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 20950: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 21000: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 21050: nan\n",
      "Minibatch accuracy: 64.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 21100: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 21150: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 21200: nan\n",
      "Minibatch accuracy: 58.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 21250: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 21300: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 21350: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 21400: nan\n",
      "Minibatch accuracy: 56.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 21450: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 21500: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 21550: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 21600: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 21650: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 21700: nan\n",
      "Minibatch accuracy: 38.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 21750: nan\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 21800: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 21850: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 21900: nan\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 21950: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 22000: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 22050: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 22100: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 22150: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 22200: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 22250: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 22300: nan\n",
      "Minibatch accuracy: 38.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 22350: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 22400: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 22450: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 22500: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 22550: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 22600: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 22650: nan\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 22700: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 22750: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 22800: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 22850: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 22900: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 22950: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 23000: nan\n",
      "Minibatch accuracy: 60.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 23050: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 23100: nan\n",
      "Minibatch accuracy: 56.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 23150: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 23200: nan\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 23250: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 23300: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 23350: nan\n",
      "Minibatch accuracy: 56.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 23400: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 23450: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 23500: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 23550: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 23600: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 23650: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 23700: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 23750: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 23800: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 23850: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 23900: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 23950: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 24000: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 24050: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 24100: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 24150: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 24200: nan\n",
      "Minibatch accuracy: 60.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 24250: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 24300: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 24350: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 24400: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 24450: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 24500: nan\n",
      "Minibatch accuracy: 40.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 24550: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 24600: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 24650: nan\n",
      "Minibatch accuracy: 30.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 24700: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 24750: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 24800: nan\n",
      "Minibatch accuracy: 64.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 24850: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 24900: nan\n",
      "Minibatch accuracy: 42.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 24950: nan\n",
      "Minibatch accuracy: 56.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 25000: nan\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 25050: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 25100: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 25150: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 25200: nan\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 25250: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 25300: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 25350: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 25400: nan\n",
      "Minibatch accuracy: 38.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 25450: nan\n",
      "Minibatch accuracy: 48.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 25500: nan\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 25550: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 25600: nan\n",
      "Minibatch accuracy: 44.0%\n",
      "Validation accuracy: 47.6%\n",
      "Minibatch loss at step 25650: nan\n",
      "Minibatch accuracy: 46.0%\n",
      "Validation accuracy: 47.6%\n"
     ]
    }
   ],
   "source": [
    "def deeper_inception_conv_net():\n",
    "    \n",
    "    batch_size = 50\n",
    "    patch_size1 = 3\n",
    "    patch_size2 = 5\n",
    "    depth = 16\n",
    "    depth1 = 32\n",
    "    depth2 = 16\n",
    "    depth3 = 8\n",
    "    concat_depth = 48\n",
    "    num_hidden = 720\n",
    "    num_hidden2 = 360\n",
    "    keep_prob = 0.5\n",
    "    decay_step = 2000\n",
    "    base = 0.9\n",
    "\n",
    "    graph = tf.Graph()\n",
    "\n",
    "    with graph.as_default():\n",
    "\n",
    "      # Input data.\n",
    "      tf_train_dataset = tf.placeholder(\n",
    "        tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "      tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "      tf_valid_dataset = tf.constant(valid_dataset)\n",
    "      tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "      # Variables.\n",
    "      layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "          [patch_size1, patch_size1, num_channels, depth], stddev=0.3))\n",
    "      layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "      layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "          [patch_size2, patch_size2, depth, depth1], stddev=0.05))\n",
    "      layer2_biases = tf.Variable(tf.constant(0.0, shape=[depth1]))\n",
    "      layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "          [((image_size + 3) // 4) * ((image_size + 3) // 4) * concat_depth, num_hidden], stddev=0.05))\n",
    "      layer3_biases = tf.Variable(tf.constant(0.0, shape=[num_hidden]))\n",
    "      layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "          [num_hidden, num_hidden2], stddev=0.01))\n",
    "      layer4_biases = tf.Variable(tf.constant(0.0, shape=[num_hidden2]))\n",
    "      layer5_weights = tf.Variable(tf.truncated_normal(\n",
    "          [num_hidden2, num_labels], stddev=0.01))\n",
    "      layer5_biases = tf.Variable(tf.constant(0.0, shape=[num_labels]))\n",
    "        \n",
    "      inception1x1_weights = tf.Variable(tf.truncated_normal(\n",
    "          [1, 1, depth1, depth2], stddev=0.25))\n",
    "      inception1x1_biases = tf.Variable(tf.constant(0.0, shape=[depth2]))\n",
    "      inception3x3_weights = tf.Variable(tf.truncated_normal(\n",
    "          [patch_size1, patch_size1, depth2, depth3], stddev=0.05))\n",
    "      inception3x3_biases = tf.Variable(tf.constant(0.0, shape=[depth3]))\n",
    "      inception5x5_weights = tf.Variable(tf.truncated_normal(\n",
    "          [patch_size2, patch_size2, depth2, depth3], stddev=0.08))\n",
    "      inception5x5_biases = tf.Variable(tf.constant(0.0, shape=[depth3]))\n",
    "    \n",
    "      inception1x1_post_mxpool_wts = tf.Variable(tf.truncated_normal(\n",
    "          [1, 1, depth1, depth2], stddev=0.04))\n",
    "      post_maxpool_biases = tf.Variable(tf.constant(0.0, shape=[depth2]))\n",
    "        \n",
    "      global_step = tf.Variable(0, trainable = False)  # count the number of steps taken.\n",
    "      learning_rate = tf.train.exponential_decay(0.005, global_step, decay_step, base)\n",
    "\n",
    "        \n",
    "      # Model.\n",
    "      def model(data, useDropout):\n",
    "        conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "        max_pooled = tf.nn.max_pool(conv, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(max_pooled + layer1_biases)\n",
    "        conv = tf.nn.conv2d(hidden, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "        max_pooled = tf.nn.max_pool(conv, [1, 2, 2, 1], [1, 1, 1, 1], padding='SAME')\n",
    "        hidden = tf.nn.relu(max_pooled + layer2_biases)\n",
    "        \n",
    "        inception1x1_conv = tf.nn.conv2d(hidden, inception1x1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "        inception1x1_relu = tf.nn.relu(inception1x1_conv + inception1x1_biases)\n",
    "        \n",
    "        inception3x3_conv = tf.nn.conv2d(inception1x1_relu, inception3x3_weights, [1, 1, 1, 1], padding='SAME')\n",
    "        inception3x3_relu = tf.nn.relu(inception3x3_conv + inception3x3_biases)\n",
    "        \n",
    "        inception5x5_conv = tf.nn.conv2d(inception1x1_relu, inception5x5_weights, [1, 1, 1, 1], padding='SAME')\n",
    "        inception5x5_relu = tf.nn.relu(inception5x5_conv + inception5x5_biases)\n",
    "        \n",
    "        inception3x3_maxpool = tf.nn.max_pool(hidden, [1, 3, 3, 1], [1, 1, 1, 1], padding='SAME')\n",
    "        inception1x1_post_maxpool = tf.nn.conv2d(inception3x3_maxpool, inception1x1_post_mxpool_wts, [1, 1, 1, 1], padding='SAME')\n",
    "        inception1x1_post_maxpool = tf.nn.relu(inception1x1_post_maxpool + post_maxpool_biases)\n",
    "        \n",
    "        concat_filter = tf.concat([inception1x1_relu, inception3x3_relu, inception5x5_relu, inception1x1_post_maxpool],3)\n",
    "        concat_maxpooled = tf.nn.max_pool(concat_filter, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "        shape = concat_maxpooled.get_shape().as_list()\n",
    "        \n",
    "        reshape = tf.reshape(concat_maxpooled, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    \n",
    "        if useDropout == 1:\n",
    "            dropout_layer2 = tf.nn.dropout(tf.nn.relu(reshape), keep_prob)\n",
    "        else:\n",
    "            dropout_layer2 = tf.nn.relu(reshape)\n",
    "        hidden = tf.nn.relu(tf.matmul(dropout_layer2, layer3_weights) + layer3_biases)\n",
    "        \n",
    "        hidden = tf.nn.relu(tf.matmul(hidden, layer4_weights) + layer4_biases)\n",
    "        return tf.matmul(hidden, layer5_weights) + layer5_biases\n",
    "\n",
    "      # Training computation.\n",
    "      logits = model(tf_train_dataset, 1)\n",
    "      loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
    "\n",
    "      # Optimizer.\n",
    "      optimizer = tf.train.AdamOptimizer(0.001).minimize(loss, global_step=global_step)\n",
    "\n",
    "      # Predictions for the training, validation, and test data.\n",
    "      train_prediction = tf.nn.softmax(model(tf_train_dataset, 0))\n",
    "      valid_prediction = tf.nn.softmax(model(tf_valid_dataset, 0))\n",
    "      test_prediction = tf.nn.softmax(model(tf_test_dataset, 0))\n",
    "        \n",
    "        \n",
    "        \n",
    "    num_steps = 30001\n",
    "\n",
    "    with tf.Session(graph=graph) as session:\n",
    "      tf.initialize_all_variables().run()\n",
    "      print('Initialized')\n",
    "      for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 50 == 0):\n",
    "          print('Minibatch loss at step %d: %f' % (step, l))\n",
    "          print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "          #print(tf.Print(layer1_weights, [layer1_weights]).eval())\n",
    "          print('Validation accuracy: %.1f%%' % accuracy(\n",
    "            valid_prediction.eval(), valid_labels))\n",
    "      print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels)) \n",
    "    \n",
    "deeper_inception_conv_net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
