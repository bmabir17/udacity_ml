{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempted relative import in non-package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-895d0025ecc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnms_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnms_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_data_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRoIdatalayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempted relative import in non-package"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import timeline\n",
    "import cv2\n",
    "\n",
    "\n",
    "from .nms_wrapper import nms_wrapper\n",
    "from ..roi_data_layer.layer import RoIdatalayer\n",
    "from ..utils.timer import timer\n",
    "from ..gt_data_layer import roidb as gdl_roidb\n",
    "from ..roi_data_layer import roidb as rdl_roidb\n",
    "\n",
    "#obsolete, because it depends on sth outside of this project\n",
    "\n",
    "from ..fast_rcnn.config import cfg\n",
    "from ..fast_rcnn.bbox_transform import clip_boxes, bbox_transform_inv\n",
    "\n",
    "# <<< obsolete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_DBUG=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SolveWrapper(object):\n",
    "    \"\"\"A simple wrapper around Caffe's solver.\n",
    "    This wrapper gives us control over he snapshotting process, which we\n",
    "    use to unnormalize the learned bounding-box regression weights.\n",
    "    \"\"\"\n",
    "    def __init__(self, sess, network, imdb, roidb, output_dir, logdir, pretrained_model=None):\n",
    "        \"\"\"Initialize the SolverWrapper.\"\"\"\n",
    "        self.net = network\n",
    "        self.imdb = imdb\n",
    "        self.roidb = roidb\n",
    "        self.output_dir = output_dir\n",
    "        self.pretrained_model = pretrained_model\n",
    "\n",
    "        print 'Computing bounding-box regression targets...'\n",
    "        if cfg.TRAIN.BBOX_REG:\n",
    "            self.bbox_means, self.bbox_stds = rdl_roidb.add_bbox_regression_targets(roidb)\n",
    "        print 'done'\n",
    "\n",
    "        # For checkpoint\n",
    "        self.saver = tf.train.Saver(max_to_keep=100)\n",
    "        self.writer = tf.summary.FileWriter(logdir=logdir,\n",
    "                                             graph=tf.get_default_graph(),\n",
    "                                             flush_secs=5)\n",
    "        def snapshot(self, sess, iter):\n",
    "            \"\"\"Take a snapshot of the network after unnormalizing the learned\n",
    "            bounding-box regression weights. This enables easy use at test-time.\n",
    "            \"\"\"\n",
    "        net = self.net\n",
    "\n",
    "        if cfg.TRAIN.BBOX_REG and net.layers.has_key('bbox_pred') and cfg.TRAIN.BBOX_NORMALIZE_TARGETS:\n",
    "            # save original values\n",
    "            with tf.variable_scope('bbox_pred', reuse=True):\n",
    "                weights = tf.get_variable(\"weights\")\n",
    "                biases = tf.get_variable(\"biases\")\n",
    "\n",
    "            orig_0 = weights.eval()\n",
    "            orig_1 = biases.eval()\n",
    "\n",
    "            # scale and shift with bbox reg unnormalization; then save snapshot\n",
    "            weights_shape = weights.get_shape().as_list()\n",
    "            sess.run(weights.assign(orig_0 * np.tile(self.bbox_stds, (weights_shape[0],1))))\n",
    "            sess.run(biases.assign(orig_1 * self.bbox_stds + self.bbox_means))\n",
    "\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "        infix = ('_' + cfg.TRAIN.SNAPSHOT_INFIX\n",
    "                 if cfg.TRAIN.SNAPSHOT_INFIX != '' else '')\n",
    "        filename = (cfg.TRAIN.SNAPSHOT_PREFIX + infix +\n",
    "                    '_iter_{:d}'.format(iter+1) + '.ckpt')\n",
    "        filename = os.path.join(self.output_dir, filename)\n",
    "\n",
    "        self.saver.save(sess, filename)\n",
    "        print 'Wrote snapshot to: {:s}'.format(filename)\n",
    "\n",
    "        if cfg.TRAIN.BBOX_REG and net.layers.has_key('bbox_pred'):\n",
    "            # restore net to original state\n",
    "            sess.run(weights.assign(orig_0))\n",
    "            sess.run(biases.assign(orig_1))\n",
    "\n",
    "    def build_image_summary(self):\n",
    "        \"\"\"\n",
    "        A simple graph for write image summary\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        log_image_data = tf.placeholder(tf.uint8, [None, None, 3])\n",
    "        log_image_name = tf.placeholder(tf.string)\n",
    "        # import tensorflow.python.ops.gen_logging_ops as logging_ops\n",
    "        from tensorflow.python.ops import gen_logging_ops\n",
    "        from tensorflow.python.framework import ops as _ops\n",
    "        log_image = gen_logging_ops._image_summary(log_image_name, tf.expand_dims(log_image_data, 0), max_images=1)\n",
    "        _ops.add_to_collection(_ops.GraphKeys.SUMMARIES, log_image)\n",
    "        # log_image = tf.summary.image(log_image_name, tf.expand_dims(log_image_data, 0), max_outputs=1)\n",
    "        return log_image, log_image_data, log_image_name\n",
    "\n",
    "\n",
    "    def train_model(self, sess, max_iters, restore=False):\n",
    "        \"\"\"Network training loop.\"\"\"\n",
    "\n",
    "        data_layer = get_data_layer(self.roidb, self.imdb.num_classes)\n",
    "\n",
    "        loss, cross_entropy, loss_box, rpn_cross_entropy, rpn_loss_box = \\\n",
    "            self.net.build_loss(ohem=cfg.TRAIN.OHEM)\n",
    "\n",
    "        # scalar summary\n",
    "        tf.summary.scalar('rpn_rgs_loss', rpn_loss_box)\n",
    "        tf.summary.scalar('rpn_cls_loss', rpn_cross_entropy)\n",
    "        tf.summary.scalar('cls_loss', cross_entropy)\n",
    "        tf.summary.scalar('rgs_loss', loss_box)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        summary_op = tf.summary.merge_all()\n",
    "\n",
    "        # image writer\n",
    "        # NOTE: this image is independent to summary_op\n",
    "        log_image, log_image_data, log_image_name =\\\n",
    "            self.build_image_summary()\n",
    "\n",
    "        # optimizer\n",
    "        if cfg.TRAIN.SOLVER == 'Adam':\n",
    "            opt = tf.train.AdamOptimizer(cfg.TRAIN.LEARNING_RATE)\n",
    "        elif cfg.TRAIN.SOLVER == 'RMS':\n",
    "            opt = tf.train.RMSPropOptimizer(cfg.TRAIN.LEARNING_RATE)\n",
    "        else:\n",
    "            lr = tf.Variable(cfg.TRAIN.LEARNING_RATE, trainable=False)\n",
    "            # lr = tf.Variable(0.0, trainable=False)\n",
    "            momentum = cfg.TRAIN.MOMENTUM\n",
    "            opt = tf.train.MomentumOptimizer(lr, momentum)\n",
    "\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        with_clip = True\n",
    "        if with_clip:\n",
    "            tvars = tf.trainable_variables()\n",
    "            grads, norm = tf.clip_by_global_norm(tf.gradients(loss, tvars), 10.0)\n",
    "            train_op = opt.apply_gradients(zip(grads, tvars), global_step=global_step)\n",
    "        else:\n",
    "            train_op = opt.minimize(loss, global_step=global_step)\n",
    "\n",
    "        # intialize variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        restore_iter = 0\n",
    "\n",
    "        # load vgg16\n",
    "        if self.pretrained_model is not None and not restore:\n",
    "            try:\n",
    "                print ('Loading pretrained model '\n",
    "                   'weights from {:s}').format(self.pretrained_model)\n",
    "                self.net.load(self.pretrained_model, sess, True)\n",
    "            except:\n",
    "                raise 'Check your pretrained model {:s}'.format(self.pretrained_model)\n",
    "\n",
    "        # resuming a trainer\n",
    "        if restore:\n",
    "            try:\n",
    "                ckpt = tf.train.get_checkpoint_state(self.output_dir)\n",
    "                print 'Restoring from {}...'.format(ckpt.model_checkpoint_path),\n",
    "                self.saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "                stem = os.path.splitext(os.path.basename(ckpt.model_checkpoint_path))[0]\n",
    "                restore_iter = int(stem.split('_')[-1])\n",
    "                sess.run(global_step.assign(restore_iter))\n",
    "                print 'done'\n",
    "            except:\n",
    "                raise 'Check your pretrained {:s}'.format(ckpt.model_checkpoint_path)\n",
    "\n",
    "        last_snapshot_iter = -1\n",
    "        timer = Timer()\n",
    "        # for iter in range(max_iters):\n",
    "        for iter in range(restore_iter, max_iters):\n",
    "            timer.tic()\n",
    "\n",
    "            # learning rate\n",
    "            if iter != 0 and iter % cfg.TRAIN.STEPSIZE == 0:\n",
    "                sess.run(tf.assign(lr, lr.eval() * cfg.TRAIN.GAMMA))\n",
    "                # sess.run(tf.assign(lr, 0.0))\n",
    "\n",
    "            # get one batch\n",
    "            blobs = data_layer.forward()\n",
    "\n",
    "            if (iter + 1) % (cfg.TRAIN.DISPLAY) == 0:\n",
    "                print 'image: %s' %(blobs['im_name']),\n",
    "\n",
    "            feed_dict={\n",
    "                self.net.data: blobs['data'],\n",
    "                self.net.im_info: blobs['im_info'],\n",
    "                self.net.keep_prob: 0.5,\n",
    "                self.net.gt_boxes: blobs['gt_boxes'],\n",
    "                self.net.gt_ishard: blobs['gt_ishard'],\n",
    "                self.net.dontcare_areas: blobs['dontcare_areas']\n",
    "            }\n",
    "\n",
    "            res_fetches = [self.net.get_output('cls_prob'),  # FRCNN class prob\n",
    "                           self.net.get_output('bbox_pred'), # FRCNN rgs output\n",
    "                           self.net.get_output('rois')]  # RPN rgs output\n",
    "\n",
    "            fetch_list = [rpn_cross_entropy,\n",
    "                          rpn_loss_box,\n",
    "                          cross_entropy,\n",
    "                          loss_box,\n",
    "                          summary_op,\n",
    "                          train_op] + res_fetches\n",
    "\n",
    "            if _DEBUG:\n",
    "\n",
    "                # add profiling\n",
    "                # link libcupti.so in LD_LIBRARY_PATH\n",
    "                #\n",
    "                # run_metadata = tf.RunMetadata()\n",
    "                # rpn_loss_cls_value, rpn_loss_box_value,loss_cls_value, loss_box_value,\\\n",
    "                #     summary_str, _, \\\n",
    "                #     cls_prob, bbox_pred, rois, \\\n",
    "                #      =  sess.run(fetches=fetch_list,\n",
    "                #                  feed_dict=feed_dict,\n",
    "                #                  options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),\n",
    "                #                  run_metadata=run_metadata\n",
    "                #                  )\n",
    "                #\n",
    "                # # write profiling\n",
    "                # trace = timeline.Timeline(step_stats=run_metadata.step_stats)\n",
    "                # with open('timeline.ctf.json', 'w') as trace_file:\n",
    "                #     trace_file.write(trace.generate_chrome_trace_format())\n",
    "\n",
    "                fetch_list = [rpn_cross_entropy,\n",
    "                              rpn_loss_box,\n",
    "                              cross_entropy,\n",
    "                              loss_box,\n",
    "                              summary_op] + res_fetches\n",
    "\n",
    "                fetch_list += [self.net.get_output('rpn_cls_score_reshape'), self.net.get_output('rpn_cls_prob_reshape')]\n",
    "\n",
    "                fetch_list += []\n",
    "                rpn_loss_cls_value, rpn_loss_box_value, loss_cls_value, loss_box_value, \\\n",
    "                summary_str, \\\n",
    "                cls_prob, bbox_pred, rois, \\\n",
    "                rpn_cls_score_reshape_np, rpn_cls_prob_reshape_np\\\n",
    "                        =  sess.run(fetches=fetch_list, feed_dict=feed_dict)\n",
    "            else:\n",
    "                fetch_list = [rpn_cross_entropy,\n",
    "                              rpn_loss_box,\n",
    "                              cross_entropy,\n",
    "                              loss_box,\n",
    "                              summary_op,\n",
    "                              train_op] + res_fetches\n",
    "\n",
    "                fetch_list += []\n",
    "                rpn_loss_cls_value, rpn_loss_box_value, loss_cls_value, loss_box_value, \\\n",
    "                summary_str, _, \\\n",
    "                cls_prob, bbox_pred, rois =  sess.run(fetches=fetch_list, feed_dict=feed_dict)\n",
    "\n",
    "            self.writer.add_summary(summary=summary_str, global_step=global_step.eval())\n",
    "\n",
    "            _diff_time = timer.toc(average=False)\n",
    "\n",
    "            # image summary\n",
    "            if (iter) % cfg.TRAIN.LOG_IMAGE_ITERS == 0:\n",
    "                # plus mean\n",
    "                ori_im = np.squeeze(blobs['data']) + cfg.PIXEL_MEANS\n",
    "                ori_im = ori_im.astype(dtype=np.uint8, copy=False)\n",
    "                ori_im = _draw_gt_to_image(ori_im, blobs['gt_boxes'], blobs['gt_ishard'])\n",
    "                ori_im = _draw_dontcare_to_image(ori_im, blobs['dontcare_areas'])\n",
    "                # draw rects\n",
    "                # print 'rois:', rois.shape[0]\n",
    "                if cfg.TRAIN.BBOX_REG and cfg.TRAIN.BBOX_NORMALIZE_TARGETS:\n",
    "                    bbox_pred = bbox_pred * np.tile(self.bbox_stds, (bbox_pred.shape[0], 1)) + \\\n",
    "                                np.tile(self.bbox_means, (bbox_pred.shape[0], 1))\n",
    "                boxes, scores = _process_boxes_scores(cls_prob, bbox_pred, rois, blobs['im_info'][0][2], ori_im.shape)\n",
    "                res = nms_wrapper(scores, boxes, threshold=0.7)\n",
    "                image = cv2.cvtColor(_draw_boxes_to_image(ori_im, res), cv2.COLOR_BGR2RGB)\n",
    "                log_image_name_str = ('%06d_' % iter ) + blobs['im_name']\n",
    "                log_image_summary_op = \\\n",
    "                    sess.run(log_image, \\\n",
    "                             feed_dict={log_image_name: log_image_name_str,\\\n",
    "                                        log_image_data: image})\n",
    "                self.writer.add_summary(log_image_summary_op, global_step=global_step.eval())\n",
    "\n",
    "            if (iter) % (cfg.TRAIN.DISPLAY) == 0:\n",
    "                print 'iter: %d / %d, total loss: %.4f, rpn_loss_cls: %.4f, rpn_loss_box: %.4f, loss_cls: %.4f, loss_box: %.4f, lr: %f'%\\\n",
    "                        (iter, max_iters, rpn_loss_cls_value + rpn_loss_box_value + loss_cls_value + loss_box_value ,\\\n",
    "                         rpn_loss_cls_value, rpn_loss_box_value,loss_cls_value, loss_box_value, lr.eval())\n",
    "                print 'speed: {:.3f}s / iter'.format(_diff_time)\n",
    "\n",
    "            if (iter+1) % cfg.TRAIN.SNAPSHOT_ITERS == 0:\n",
    "                last_snapshot_iter = iter\n",
    "                self.snapshot(sess, iter)\n",
    "\n",
    "        if last_snapshot_iter != iter:\n",
    "            self.snapshot(sess, iter)\n",
    "\n",
    "def get_training_roidb(imdb):\n",
    "    \"\"\"Returns a roidb (Region of Interest database) for use in training.\"\"\"\n",
    "    if cfg.TRAIN.USE_FLIPPED:\n",
    "        print 'Appending horizontally-flipped training examples...'\n",
    "        imdb.append_flipped_images()\n",
    "        print 'done'\n",
    "\n",
    "    print 'Preparing training data...'\n",
    "    if cfg.TRAIN.HAS_RPN:\n",
    "        if cfg.IS_MULTISCALE:\n",
    "            # TODO: fix multiscale training (single scale is already a good trade-off)\n",
    "            print ('#### warning: multi-scale has not been tested.')\n",
    "            print ('#### warning: using single scale by setting IS_MULTISCALE: False.')\n",
    "            gdl_roidb.prepare_roidb(imdb)\n",
    "        else:\n",
    "            rdl_roidb.prepare_roidb(imdb)\n",
    "    else:\n",
    "        rdl_roidb.prepare_roidb(imdb)\n",
    "    print 'done'\n",
    "\n",
    "    return imdb.roidb\n",
    "\n",
    "\n",
    "def get_data_layer(roidb, num_classes):\n",
    "    \"\"\"return a data layer.\"\"\"\n",
    "    if cfg.TRAIN.HAS_RPN:\n",
    "        if cfg.IS_MULTISCALE:\n",
    "            # obsolete\n",
    "            # layer = GtDataLayer(roidb)\n",
    "            raise \"Calling caffe modules...\"\n",
    "        else:\n",
    "            layer = RoIDataLayer(roidb, num_classes)\n",
    "    else:\n",
    "        layer = RoIDataLayer(roidb, num_classes)\n",
    "\n",
    "    return layer\n",
    "\n",
    "def _process_boxes_scores(cls_prob, bbox_pred, rois, im_scale, im_shape):\n",
    "    \"\"\"\n",
    "    process the output tensors, to get the boxes and scores\n",
    "    \"\"\"\n",
    "    assert rois.shape[0] == bbox_pred.shape[0],\\\n",
    "        'rois and bbox_pred must have the same shape'\n",
    "    boxes = rois[:, 1:5]\n",
    "    scores = cls_prob\n",
    "    if cfg.TEST.BBOX_REG:\n",
    "        pred_boxes = bbox_transform_inv(boxes, deltas=bbox_pred)\n",
    "        pred_boxes = clip_boxes(pred_boxes, im_shape)\n",
    "    else:\n",
    "        # Simply repeat the boxes, once for each class\n",
    "        # boxes = np.tile(boxes, (1, scores.shape[1]))\n",
    "\n",
    "        pred_boxes = clip_boxes(boxes, im_shape)\n",
    "    return pred_boxes, scores\n",
    "\n",
    "def _draw_boxes_to_image(im, res):\n",
    "    colors = [(86, 0, 240), (173, 225, 61), (54, 137, 255),\\\n",
    "              (151, 0, 255), (243, 223, 48), (0, 117, 255),\\\n",
    "              (58, 184, 14), (86, 67, 140), (121, 82, 6),\\\n",
    "              (174, 29, 128), (115, 154, 81), (86, 255, 234)]\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    image = np.copy(im)\n",
    "    cnt = 0\n",
    "    for ind, r in enumerate(res):\n",
    "        if r['dets'] is None: continue\n",
    "        dets = r['dets']\n",
    "        for i in range(0, dets.shape[0]):\n",
    "            (x1, y1, x2, y2, score) = dets[i, :]\n",
    "            cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), colors[ind % len(colors)], 2)\n",
    "            text = '{:s} {:.2f}'.format(r['class'], score)\n",
    "            cv2.putText(image, text, (x1, y1), font, 0.6, colors[ind % len(colors)], 1)\n",
    "            cnt = (cnt + 1)\n",
    "    return image\n",
    "\n",
    "def _draw_gt_to_image(im, gt_boxes, gt_ishard):\n",
    "    image = np.copy(im)\n",
    "\n",
    "    for i in range(0, gt_boxes.shape[0]):\n",
    "        (x1, y1, x2, y2, score) = gt_boxes[i, :]\n",
    "        if gt_ishard[i] == 0:\n",
    "            cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (255, 255, 255), 2)\n",
    "        else:\n",
    "            cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
    "    return image\n",
    "\n",
    "def _draw_dontcare_to_image(im, dontcare):\n",
    "    image = np.copy(im)\n",
    "\n",
    "    for i in range(0, dontcare.shape[0]):\n",
    "        (x1, y1, x2, y2) = dontcare[i, :]\n",
    "        cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)\n",
    "    return image\n",
    "\n",
    "\n",
    "\n",
    "def train_net(network, imdb, roidb, output_dir, log_dir, pretrained_model=None, max_iters=40000, restore=False):\n",
    "    \"\"\"Train a Fast R-CNN network.\"\"\"\n",
    "\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allocator_type = 'BFC'\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.40\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sw = SolverWrapper(sess, network, imdb, roidb, output_dir, logdir= log_dir, pretrained_model=pretrained_model)\n",
    "        print 'Solving...'\n",
    "        sw.train_model(sess, max_iters, restore=restore)\n",
    "        print 'done solving'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
